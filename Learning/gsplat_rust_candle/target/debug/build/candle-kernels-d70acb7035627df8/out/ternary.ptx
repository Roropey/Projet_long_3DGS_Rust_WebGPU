//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33567101
// Cuda compilation tools, release 12.3, V12.3.107
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_75
.address_size 64

	// .globl	where_i64_f16

.visible .entry where_i64_f16(
	.param .u64 where_i64_f16_param_0,
	.param .u64 where_i64_f16_param_1,
	.param .u64 where_i64_f16_param_2,
	.param .u64 where_i64_f16_param_3,
	.param .u64 where_i64_f16_param_4,
	.param .u64 where_i64_f16_param_5,
	.param .u64 where_i64_f16_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<160>;


	ld.param.u64 	%rd51, [where_i64_f16_param_0];
	ld.param.u64 	%rd52, [where_i64_f16_param_1];
	ld.param.u64 	%rd56, [where_i64_f16_param_2];
	ld.param.u64 	%rd57, [where_i64_f16_param_3];
	ld.param.u64 	%rd53, [where_i64_f16_param_4];
	ld.param.u64 	%rd54, [where_i64_f16_param_5];
	ld.param.u64 	%rd55, [where_i64_f16_param_6];
	cvta.to.global.u64 	%rd1, %rd54;
	cvta.to.global.u64 	%rd2, %rd55;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB0_10;

	mov.u64 	%rd148, 1;
	mov.u32 	%r72, 0;

$L__BB0_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd148, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB0_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd148, %rd67, %rd148;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB0_2;

	mov.u64 	%rd149, 1;
	mov.u32 	%r73, 0;

$L__BB0_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd149, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB0_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd149, %rd78, %rd149;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB0_5;

	mov.u64 	%rd150, 1;
	mov.u32 	%r74, 0;

$L__BB0_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd150, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB0_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd150, %rd89, %rd150;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB0_8;

$L__BB0_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd151, %r75;
	@%p29 bra 	$L__BB0_28;
	bra.uni 	$L__BB0_11;

$L__BB0_28:
	setp.ge.u64 	%p26, %rd151, %rd51;
	@%p26 bra 	$L__BB0_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB0_30:
	shl.b64 	%rd141, %rd151, 3;
	add.s64 	%rd142, %rd4, %rd141;
	ld.global.u64 	%rd143, [%rd142];
	setp.eq.s64 	%p27, %rd143, 0;
	selp.b64 	%rd144, %rd1, %rd3, %p27;
	shl.b64 	%rd145, %rd151, 1;
	add.s64 	%rd146, %rd144, %rd145;
	ld.global.u16 	%rs3, [%rd146];
	add.s64 	%rd147, %rd2, %rd145;
	st.global.u16 	[%rd147], %rs3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd151, %r75;
	setp.lt.u64 	%p28, %rd151, %rd51;
	@%p28 bra 	$L__BB0_30;
	bra.uni 	$L__BB0_31;

$L__BB0_11:
	setp.ge.u64 	%p14, %rd151, %rd51;
	@%p14 bra 	$L__BB0_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB0_27;

$L__BB0_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB0_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB0_16;

	div.u64 	%rd152, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd152, %rd21;
	sub.s64 	%rd153, %rd19, %rd96;
	bra.uni 	$L__BB0_17;

$L__BB0_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd152, %r49;
	cvt.u64.u32 	%rd153, %r51;

$L__BB0_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd153;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd152;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB0_14;

$L__BB0_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB0_20;

	div.u64 	%rd154, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd154, %rd30;
	sub.s64 	%rd155, %rd28, %rd107;
	bra.uni 	$L__BB0_21;

$L__BB0_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd154, %r58;
	cvt.u64.u32 	%rd155, %r60;

$L__BB0_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd155;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd154;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB0_18;

$L__BB0_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB0_24;

	div.u64 	%rd156, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd156, %rd39;
	sub.s64 	%rd157, %rd37, %rd118;
	bra.uni 	$L__BB0_25;

$L__BB0_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd156, %r67;
	cvt.u64.u32 	%rd157, %r69;

$L__BB0_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd157;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd156;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB0_22;

	mul.wide.u32 	%rd124, %r78, 8;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u64 	%rd126, [%rd125];
	setp.eq.s64 	%p22, %rd126, 0;
	mul.wide.u32 	%rd128, %r81, 2;
	add.s64 	%rd129, %rd3, %rd128;
	mul.wide.u32 	%rd131, %r84, 2;
	add.s64 	%rd132, %rd1, %rd131;
	selp.b64 	%rd133, %rd132, %rd129, %p22;
	ld.global.u16 	%rs1, [%rd133];
	shl.b64 	%rd135, %rd151, 1;
	add.s64 	%rd136, %rd2, %rd135;
	st.global.u16 	[%rd136], %rs1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd151, %r75;
	setp.lt.u64 	%p23, %rd151, %rd51;
	@%p23 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_31;

$L__BB0_27:
	ld.global.u64 	%rd137, [%rd4];
	setp.eq.s64 	%p24, %rd137, 0;
	selp.b64 	%rd138, %rd1, %rd3, %p24;
	ld.global.u16 	%rs2, [%rd138];
	shl.b64 	%rd139, %rd151, 1;
	add.s64 	%rd140, %rd2, %rd139;
	st.global.u16 	[%rd140], %rs2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd151, %r75;
	setp.lt.u64 	%p25, %rd151, %rd51;
	@%p25 bra 	$L__BB0_27;

$L__BB0_31:
	ret;

}
	// .globl	where_u32_f16
.visible .entry where_u32_f16(
	.param .u64 where_u32_f16_param_0,
	.param .u64 where_u32_f16_param_1,
	.param .u64 where_u32_f16_param_2,
	.param .u64 where_u32_f16_param_3,
	.param .u64 where_u32_f16_param_4,
	.param .u64 where_u32_f16_param_5,
	.param .u64 where_u32_f16_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<157>;


	ld.param.u64 	%rd51, [where_u32_f16_param_0];
	ld.param.u64 	%rd52, [where_u32_f16_param_1];
	ld.param.u64 	%rd56, [where_u32_f16_param_2];
	ld.param.u64 	%rd57, [where_u32_f16_param_3];
	ld.param.u64 	%rd53, [where_u32_f16_param_4];
	ld.param.u64 	%rd54, [where_u32_f16_param_5];
	ld.param.u64 	%rd55, [where_u32_f16_param_6];
	cvta.to.global.u64 	%rd1, %rd54;
	cvta.to.global.u64 	%rd2, %rd55;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB1_10;

	mov.u64 	%rd145, 1;
	mov.u32 	%r75, 0;

$L__BB1_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd145, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB1_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd145, %rd67, %rd145;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd68, %r75;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB1_2;

	mov.u64 	%rd146, 1;
	mov.u32 	%r76, 0;

$L__BB1_5:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd146, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB1_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd146, %rd78, %rd146;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd79, %r76;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB1_5;

	mov.u64 	%rd147, 1;
	mov.u32 	%r77, 0;

$L__BB1_8:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd147, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB1_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd147, %rd89, %rd147;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd90, %r77;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB1_8;

$L__BB1_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd148, %r78;
	@%p29 bra 	$L__BB1_28;
	bra.uni 	$L__BB1_11;

$L__BB1_28:
	setp.ge.u64 	%p26, %rd148, %rd51;
	@%p26 bra 	$L__BB1_31;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB1_30:
	shl.b64 	%rd139, %rd148, 2;
	add.s64 	%rd140, %rd4, %rd139;
	ld.global.u32 	%r74, [%rd140];
	setp.eq.s32 	%p27, %r74, 0;
	selp.b64 	%rd141, %rd1, %rd3, %p27;
	shl.b64 	%rd142, %rd148, 1;
	add.s64 	%rd143, %rd141, %rd142;
	ld.global.u16 	%rs3, [%rd143];
	add.s64 	%rd144, %rd2, %rd142;
	st.global.u16 	[%rd144], %rs3;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p28, %rd148, %rd51;
	@%p28 bra 	$L__BB1_30;
	bra.uni 	$L__BB1_31;

$L__BB1_11:
	setp.ge.u64 	%p14, %rd148, %rd51;
	@%p14 bra 	$L__BB1_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB1_27;

$L__BB1_13:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB1_14:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r80;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB1_16;

	div.u64 	%rd149, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd149, %rd21;
	sub.s64 	%rd150, %rd19, %rd96;
	bra.uni 	$L__BB1_17;

$L__BB1_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd149, %r49;
	cvt.u64.u32 	%rd150, %r51;

$L__BB1_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd150;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd149;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd101, %r79;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p17 bra 	$L__BB1_14;

$L__BB1_18:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r83;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB1_20;

	div.u64 	%rd151, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd151, %rd30;
	sub.s64 	%rd152, %rd28, %rd107;
	bra.uni 	$L__BB1_21;

$L__BB1_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd151, %r58;
	cvt.u64.u32 	%rd152, %r60;

$L__BB1_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd152;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd151;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd112, %r82;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p19 bra 	$L__BB1_18;

$L__BB1_22:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r86;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB1_24;

	div.u64 	%rd153, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd153, %rd39;
	sub.s64 	%rd154, %rd37, %rd118;
	bra.uni 	$L__BB1_25;

$L__BB1_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd153, %r67;
	cvt.u64.u32 	%rd154, %r69;

$L__BB1_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd154;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd153;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd123, %r85;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB1_22;

	mul.wide.u32 	%rd124, %r81, 4;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u32 	%r71, [%rd125];
	setp.eq.s32 	%p22, %r71, 0;
	mul.wide.u32 	%rd127, %r84, 2;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r87, 2;
	add.s64 	%rd131, %rd1, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u16 	%rs1, [%rd132];
	shl.b64 	%rd134, %rd148, 1;
	add.s64 	%rd135, %rd2, %rd134;
	st.global.u16 	[%rd135], %rs1;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p23, %rd148, %rd51;
	@%p23 bra 	$L__BB1_13;
	bra.uni 	$L__BB1_31;

$L__BB1_27:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p24, %r72, 0;
	selp.b64 	%rd136, %rd1, %rd3, %p24;
	ld.global.u16 	%rs2, [%rd136];
	shl.b64 	%rd137, %rd148, 1;
	add.s64 	%rd138, %rd2, %rd137;
	st.global.u16 	[%rd138], %rs2;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p25, %rd148, %rd51;
	@%p25 bra 	$L__BB1_27;

$L__BB1_31:
	ret;

}
	// .globl	where_u8_f16
.visible .entry where_u8_f16(
	.param .u64 where_u8_f16_param_0,
	.param .u64 where_u8_f16_param_1,
	.param .u64 where_u8_f16_param_2,
	.param .u64 where_u8_f16_param_3,
	.param .u64 where_u8_f16_param_4,
	.param .u64 where_u8_f16_param_5,
	.param .u64 where_u8_f16_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd51, [where_u8_f16_param_0];
	ld.param.u64 	%rd52, [where_u8_f16_param_1];
	ld.param.u64 	%rd56, [where_u8_f16_param_2];
	ld.param.u64 	%rd57, [where_u8_f16_param_3];
	ld.param.u64 	%rd53, [where_u8_f16_param_4];
	ld.param.u64 	%rd54, [where_u8_f16_param_5];
	ld.param.u64 	%rd55, [where_u8_f16_param_6];
	cvta.to.global.u64 	%rd1, %rd54;
	cvta.to.global.u64 	%rd2, %rd55;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB2_10;

	mov.u64 	%rd144, 1;
	mov.u32 	%r72, 0;

$L__BB2_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd144, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB2_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd144, %rd67, %rd144;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB2_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r73, 0;

$L__BB2_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd145, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB2_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd145, %rd78, %rd145;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB2_5;

	mov.u64 	%rd146, 1;
	mov.u32 	%r74, 0;

$L__BB2_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd146, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB2_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd146, %rd89, %rd146;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB2_8;

$L__BB2_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r75;
	@%p29 bra 	$L__BB2_28;
	bra.uni 	$L__BB2_11;

$L__BB2_28:
	setp.ge.u64 	%p26, %rd147, %rd51;
	@%p26 bra 	$L__BB2_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB2_30:
	add.s64 	%rd139, %rd4, %rd147;
	ld.global.u8 	%rs5, [%rd139];
	setp.eq.s16 	%p27, %rs5, 0;
	selp.b64 	%rd140, %rd1, %rd3, %p27;
	shl.b64 	%rd141, %rd147, 1;
	add.s64 	%rd142, %rd140, %rd141;
	ld.global.u16 	%rs6, [%rd142];
	add.s64 	%rd143, %rd2, %rd141;
	st.global.u16 	[%rd143], %rs6;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p28, %rd147, %rd51;
	@%p28 bra 	$L__BB2_30;
	bra.uni 	$L__BB2_31;

$L__BB2_11:
	setp.ge.u64 	%p14, %rd147, %rd51;
	@%p14 bra 	$L__BB2_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB2_27;

$L__BB2_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB2_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB2_16;

	div.u64 	%rd148, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd148, %rd21;
	sub.s64 	%rd149, %rd19, %rd96;
	bra.uni 	$L__BB2_17;

$L__BB2_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB2_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd149;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd148;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB2_14;

$L__BB2_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB2_20;

	div.u64 	%rd150, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd150, %rd30;
	sub.s64 	%rd151, %rd28, %rd107;
	bra.uni 	$L__BB2_21;

$L__BB2_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB2_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd151;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd150;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB2_18;

$L__BB2_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB2_24;

	div.u64 	%rd152, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd152, %rd39;
	sub.s64 	%rd153, %rd37, %rd118;
	bra.uni 	$L__BB2_25;

$L__BB2_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB2_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd153;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd152;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB2_22;

	cvt.u64.u32 	%rd124, %r78;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u8 	%rs1, [%rd125];
	setp.eq.s16 	%p22, %rs1, 0;
	mul.wide.u32 	%rd127, %r81, 2;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r84, 2;
	add.s64 	%rd131, %rd1, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u16 	%rs2, [%rd132];
	shl.b64 	%rd134, %rd147, 1;
	add.s64 	%rd135, %rd2, %rd134;
	st.global.u16 	[%rd135], %rs2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p23, %rd147, %rd51;
	@%p23 bra 	$L__BB2_13;
	bra.uni 	$L__BB2_31;

$L__BB2_27:
	ld.global.u8 	%rs3, [%rd4];
	setp.eq.s16 	%p24, %rs3, 0;
	selp.b64 	%rd136, %rd1, %rd3, %p24;
	ld.global.u16 	%rs4, [%rd136];
	shl.b64 	%rd137, %rd147, 1;
	add.s64 	%rd138, %rd2, %rd137;
	st.global.u16 	[%rd138], %rs4;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p25, %rd147, %rd51;
	@%p25 bra 	$L__BB2_27;

$L__BB2_31:
	ret;

}
	// .globl	where_i64_f32
.visible .entry where_i64_f32(
	.param .u64 where_i64_f32_param_0,
	.param .u64 where_i64_f32_param_1,
	.param .u64 where_i64_f32_param_2,
	.param .u64 where_i64_f32_param_3,
	.param .u64 where_i64_f32_param_4,
	.param .u64 where_i64_f32_param_5,
	.param .u64 where_i64_f32_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<160>;


	ld.param.u64 	%rd51, [where_i64_f32_param_0];
	ld.param.u64 	%rd52, [where_i64_f32_param_1];
	ld.param.u64 	%rd56, [where_i64_f32_param_2];
	ld.param.u64 	%rd57, [where_i64_f32_param_3];
	ld.param.u64 	%rd53, [where_i64_f32_param_4];
	ld.param.u64 	%rd54, [where_i64_f32_param_5];
	ld.param.u64 	%rd55, [where_i64_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB3_10;

	mov.u64 	%rd148, 1;
	mov.u32 	%r72, 0;

$L__BB3_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd148, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB3_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd148, %rd67, %rd148;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB3_2;

	mov.u64 	%rd149, 1;
	mov.u32 	%r73, 0;

$L__BB3_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd149, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB3_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd149, %rd78, %rd149;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB3_5;

	mov.u64 	%rd150, 1;
	mov.u32 	%r74, 0;

$L__BB3_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd150, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB3_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd150, %rd89, %rd150;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB3_8;

$L__BB3_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd151, %r75;
	@%p29 bra 	$L__BB3_28;
	bra.uni 	$L__BB3_11;

$L__BB3_28:
	setp.ge.u64 	%p26, %rd151, %rd51;
	@%p26 bra 	$L__BB3_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB3_30:
	shl.b64 	%rd141, %rd151, 3;
	add.s64 	%rd142, %rd4, %rd141;
	ld.global.u64 	%rd143, [%rd142];
	setp.eq.s64 	%p27, %rd143, 0;
	selp.b64 	%rd144, %rd2, %rd3, %p27;
	shl.b64 	%rd145, %rd151, 2;
	add.s64 	%rd146, %rd144, %rd145;
	ld.global.f32 	%f3, [%rd146];
	add.s64 	%rd147, %rd1, %rd145;
	st.global.f32 	[%rd147], %f3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd151, %r75;
	setp.lt.u64 	%p28, %rd151, %rd51;
	@%p28 bra 	$L__BB3_30;
	bra.uni 	$L__BB3_31;

$L__BB3_11:
	setp.ge.u64 	%p14, %rd151, %rd51;
	@%p14 bra 	$L__BB3_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB3_27;

$L__BB3_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB3_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB3_16;

	div.u64 	%rd152, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd152, %rd21;
	sub.s64 	%rd153, %rd19, %rd96;
	bra.uni 	$L__BB3_17;

$L__BB3_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd152, %r49;
	cvt.u64.u32 	%rd153, %r51;

$L__BB3_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd153;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd152;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB3_14;

$L__BB3_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB3_20;

	div.u64 	%rd154, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd154, %rd30;
	sub.s64 	%rd155, %rd28, %rd107;
	bra.uni 	$L__BB3_21;

$L__BB3_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd154, %r58;
	cvt.u64.u32 	%rd155, %r60;

$L__BB3_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd155;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd154;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB3_18;

$L__BB3_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB3_24;

	div.u64 	%rd156, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd156, %rd39;
	sub.s64 	%rd157, %rd37, %rd118;
	bra.uni 	$L__BB3_25;

$L__BB3_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd156, %r67;
	cvt.u64.u32 	%rd157, %r69;

$L__BB3_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd157;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd156;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB3_22;

	mul.wide.u32 	%rd124, %r78, 8;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u64 	%rd126, [%rd125];
	setp.eq.s64 	%p22, %rd126, 0;
	mul.wide.u32 	%rd128, %r81, 4;
	add.s64 	%rd129, %rd3, %rd128;
	mul.wide.u32 	%rd131, %r84, 4;
	add.s64 	%rd132, %rd2, %rd131;
	selp.b64 	%rd133, %rd132, %rd129, %p22;
	ld.global.f32 	%f1, [%rd133];
	shl.b64 	%rd135, %rd151, 2;
	add.s64 	%rd136, %rd1, %rd135;
	st.global.f32 	[%rd136], %f1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd151, %r75;
	setp.lt.u64 	%p23, %rd151, %rd51;
	@%p23 bra 	$L__BB3_13;
	bra.uni 	$L__BB3_31;

$L__BB3_27:
	ld.global.u64 	%rd137, [%rd4];
	setp.eq.s64 	%p24, %rd137, 0;
	selp.b64 	%rd138, %rd2, %rd3, %p24;
	ld.global.f32 	%f2, [%rd138];
	shl.b64 	%rd139, %rd151, 2;
	add.s64 	%rd140, %rd1, %rd139;
	st.global.f32 	[%rd140], %f2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd151, %r75;
	setp.lt.u64 	%p25, %rd151, %rd51;
	@%p25 bra 	$L__BB3_27;

$L__BB3_31:
	ret;

}
	// .globl	where_i64_f64
.visible .entry where_i64_f64(
	.param .u64 where_i64_f64_param_0,
	.param .u64 where_i64_f64_param_1,
	.param .u64 where_i64_f64_param_2,
	.param .u64 where_i64_f64_param_3,
	.param .u64 where_i64_f64_param_4,
	.param .u64 where_i64_f64_param_5,
	.param .u64 where_i64_f64_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b32 	%r<87>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<159>;


	ld.param.u64 	%rd51, [where_i64_f64_param_0];
	ld.param.u64 	%rd52, [where_i64_f64_param_1];
	ld.param.u64 	%rd56, [where_i64_f64_param_2];
	ld.param.u64 	%rd57, [where_i64_f64_param_3];
	ld.param.u64 	%rd53, [where_i64_f64_param_4];
	ld.param.u64 	%rd54, [where_i64_f64_param_5];
	ld.param.u64 	%rd55, [where_i64_f64_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB4_10;

	mov.u64 	%rd147, 1;
	mov.u32 	%r72, 0;

$L__BB4_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd147, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB4_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd147, %rd67, %rd147;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB4_2;

	mov.u64 	%rd148, 1;
	mov.u32 	%r73, 0;

$L__BB4_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd148, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB4_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd148, %rd78, %rd148;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB4_5;

	mov.u64 	%rd149, 1;
	mov.u32 	%r74, 0;

$L__BB4_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd149, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB4_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd149, %rd89, %rd149;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB4_8;

$L__BB4_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd150, %r75;
	@%p29 bra 	$L__BB4_28;
	bra.uni 	$L__BB4_11;

$L__BB4_28:
	setp.ge.u64 	%p26, %rd150, %rd51;
	@%p26 bra 	$L__BB4_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB4_30:
	shl.b64 	%rd141, %rd150, 3;
	add.s64 	%rd142, %rd4, %rd141;
	ld.global.u64 	%rd143, [%rd142];
	setp.eq.s64 	%p27, %rd143, 0;
	selp.b64 	%rd144, %rd2, %rd3, %p27;
	add.s64 	%rd145, %rd144, %rd141;
	ld.global.f64 	%fd3, [%rd145];
	add.s64 	%rd146, %rd1, %rd141;
	st.global.f64 	[%rd146], %fd3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p28, %rd150, %rd51;
	@%p28 bra 	$L__BB4_30;
	bra.uni 	$L__BB4_31;

$L__BB4_11:
	setp.ge.u64 	%p14, %rd150, %rd51;
	@%p14 bra 	$L__BB4_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB4_27;

$L__BB4_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB4_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB4_16;

	div.u64 	%rd151, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd151, %rd21;
	sub.s64 	%rd152, %rd19, %rd96;
	bra.uni 	$L__BB4_17;

$L__BB4_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd151, %r49;
	cvt.u64.u32 	%rd152, %r51;

$L__BB4_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd152;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd151;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB4_14;

$L__BB4_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB4_20;

	div.u64 	%rd153, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd153, %rd30;
	sub.s64 	%rd154, %rd28, %rd107;
	bra.uni 	$L__BB4_21;

$L__BB4_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd153, %r58;
	cvt.u64.u32 	%rd154, %r60;

$L__BB4_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd154;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd153;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB4_18;

$L__BB4_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB4_24;

	div.u64 	%rd155, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd155, %rd39;
	sub.s64 	%rd156, %rd37, %rd118;
	bra.uni 	$L__BB4_25;

$L__BB4_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd155, %r67;
	cvt.u64.u32 	%rd156, %r69;

$L__BB4_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd156;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd155;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB4_22;

	mul.wide.u32 	%rd124, %r78, 8;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u64 	%rd126, [%rd125];
	setp.eq.s64 	%p22, %rd126, 0;
	mul.wide.u32 	%rd128, %r81, 8;
	add.s64 	%rd129, %rd3, %rd128;
	mul.wide.u32 	%rd131, %r84, 8;
	add.s64 	%rd132, %rd2, %rd131;
	selp.b64 	%rd133, %rd132, %rd129, %p22;
	ld.global.f64 	%fd1, [%rd133];
	shl.b64 	%rd135, %rd150, 3;
	add.s64 	%rd136, %rd1, %rd135;
	st.global.f64 	[%rd136], %fd1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p23, %rd150, %rd51;
	@%p23 bra 	$L__BB4_13;
	bra.uni 	$L__BB4_31;

$L__BB4_27:
	ld.global.u64 	%rd137, [%rd4];
	setp.eq.s64 	%p24, %rd137, 0;
	selp.b64 	%rd138, %rd2, %rd3, %p24;
	ld.global.f64 	%fd2, [%rd138];
	shl.b64 	%rd139, %rd150, 3;
	add.s64 	%rd140, %rd1, %rd139;
	st.global.f64 	[%rd140], %fd2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p25, %rd150, %rd51;
	@%p25 bra 	$L__BB4_27;

$L__BB4_31:
	ret;

}
	// .globl	where_i64_u8
.visible .entry where_i64_u8(
	.param .u64 where_i64_u8_param_0,
	.param .u64 where_i64_u8_param_1,
	.param .u64 where_i64_u8_param_2,
	.param .u64 where_i64_u8_param_3,
	.param .u64 where_i64_u8_param_4,
	.param .u64 where_i64_u8_param_5,
	.param .u64 where_i64_u8_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<157>;


	ld.param.u64 	%rd51, [where_i64_u8_param_0];
	ld.param.u64 	%rd52, [where_i64_u8_param_1];
	ld.param.u64 	%rd56, [where_i64_u8_param_2];
	ld.param.u64 	%rd57, [where_i64_u8_param_3];
	ld.param.u64 	%rd53, [where_i64_u8_param_4];
	ld.param.u64 	%rd54, [where_i64_u8_param_5];
	ld.param.u64 	%rd55, [where_i64_u8_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB5_10;

	mov.u64 	%rd145, 1;
	mov.u32 	%r72, 0;

$L__BB5_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd145, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB5_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd145, %rd67, %rd145;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB5_2;

	mov.u64 	%rd146, 1;
	mov.u32 	%r73, 0;

$L__BB5_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd146, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB5_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd146, %rd78, %rd146;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB5_5;

	mov.u64 	%rd147, 1;
	mov.u32 	%r74, 0;

$L__BB5_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd147, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB5_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd147, %rd89, %rd147;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB5_8;

$L__BB5_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd148, %r75;
	@%p29 bra 	$L__BB5_28;
	bra.uni 	$L__BB5_11;

$L__BB5_28:
	setp.ge.u64 	%p26, %rd148, %rd51;
	@%p26 bra 	$L__BB5_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB5_30:
	shl.b64 	%rd139, %rd148, 3;
	add.s64 	%rd140, %rd4, %rd139;
	ld.global.u64 	%rd141, [%rd140];
	setp.eq.s64 	%p27, %rd141, 0;
	selp.b64 	%rd142, %rd2, %rd3, %p27;
	add.s64 	%rd143, %rd142, %rd148;
	ld.global.u8 	%rs3, [%rd143];
	add.s64 	%rd144, %rd1, %rd148;
	st.global.u8 	[%rd144], %rs3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd148, %r75;
	setp.lt.u64 	%p28, %rd148, %rd51;
	@%p28 bra 	$L__BB5_30;
	bra.uni 	$L__BB5_31;

$L__BB5_11:
	setp.ge.u64 	%p14, %rd148, %rd51;
	@%p14 bra 	$L__BB5_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB5_27;

$L__BB5_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB5_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB5_16;

	div.u64 	%rd149, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd149, %rd21;
	sub.s64 	%rd150, %rd19, %rd96;
	bra.uni 	$L__BB5_17;

$L__BB5_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd149, %r49;
	cvt.u64.u32 	%rd150, %r51;

$L__BB5_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd150;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd149;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB5_14;

$L__BB5_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB5_20;

	div.u64 	%rd151, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd151, %rd30;
	sub.s64 	%rd152, %rd28, %rd107;
	bra.uni 	$L__BB5_21;

$L__BB5_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd151, %r58;
	cvt.u64.u32 	%rd152, %r60;

$L__BB5_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd152;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd151;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB5_18;

$L__BB5_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB5_24;

	div.u64 	%rd153, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd153, %rd39;
	sub.s64 	%rd154, %rd37, %rd118;
	bra.uni 	$L__BB5_25;

$L__BB5_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd153, %r67;
	cvt.u64.u32 	%rd154, %r69;

$L__BB5_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd154;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd153;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB5_22;

	mul.wide.u32 	%rd124, %r78, 8;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u64 	%rd126, [%rd125];
	setp.eq.s64 	%p22, %rd126, 0;
	cvt.u64.u32 	%rd127, %r81;
	add.s64 	%rd129, %rd3, %rd127;
	cvt.u64.u32 	%rd130, %r84;
	add.s64 	%rd132, %rd2, %rd130;
	selp.b64 	%rd133, %rd132, %rd129, %p22;
	ld.global.u8 	%rs1, [%rd133];
	add.s64 	%rd135, %rd1, %rd148;
	st.global.u8 	[%rd135], %rs1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd148, %r75;
	setp.lt.u64 	%p23, %rd148, %rd51;
	@%p23 bra 	$L__BB5_13;
	bra.uni 	$L__BB5_31;

$L__BB5_27:
	ld.global.u64 	%rd136, [%rd4];
	setp.eq.s64 	%p24, %rd136, 0;
	selp.b64 	%rd137, %rd2, %rd3, %p24;
	ld.global.u8 	%rs2, [%rd137];
	add.s64 	%rd138, %rd1, %rd148;
	st.global.u8 	[%rd138], %rs2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd148, %r75;
	setp.lt.u64 	%p25, %rd148, %rd51;
	@%p25 bra 	$L__BB5_27;

$L__BB5_31:
	ret;

}
	// .globl	where_i64_u32
.visible .entry where_i64_u32(
	.param .u64 where_i64_u32_param_0,
	.param .u64 where_i64_u32_param_1,
	.param .u64 where_i64_u32_param_2,
	.param .u64 where_i64_u32_param_3,
	.param .u64 where_i64_u32_param_4,
	.param .u64 where_i64_u32_param_5,
	.param .u64 where_i64_u32_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<160>;


	ld.param.u64 	%rd51, [where_i64_u32_param_0];
	ld.param.u64 	%rd52, [where_i64_u32_param_1];
	ld.param.u64 	%rd56, [where_i64_u32_param_2];
	ld.param.u64 	%rd57, [where_i64_u32_param_3];
	ld.param.u64 	%rd53, [where_i64_u32_param_4];
	ld.param.u64 	%rd54, [where_i64_u32_param_5];
	ld.param.u64 	%rd55, [where_i64_u32_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB6_10;

	mov.u64 	%rd148, 1;
	mov.u32 	%r75, 0;

$L__BB6_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd148, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB6_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd148, %rd67, %rd148;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd68, %r75;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB6_2;

	mov.u64 	%rd149, 1;
	mov.u32 	%r76, 0;

$L__BB6_5:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd149, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB6_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd149, %rd78, %rd149;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd79, %r76;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB6_5;

	mov.u64 	%rd150, 1;
	mov.u32 	%r77, 0;

$L__BB6_8:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd150, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB6_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd150, %rd89, %rd150;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd90, %r77;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB6_8;

$L__BB6_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd151, %r78;
	@%p29 bra 	$L__BB6_28;
	bra.uni 	$L__BB6_11;

$L__BB6_28:
	setp.ge.u64 	%p26, %rd151, %rd51;
	@%p26 bra 	$L__BB6_31;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB6_30:
	shl.b64 	%rd141, %rd151, 3;
	add.s64 	%rd142, %rd4, %rd141;
	ld.global.u64 	%rd143, [%rd142];
	setp.eq.s64 	%p27, %rd143, 0;
	selp.b64 	%rd144, %rd2, %rd3, %p27;
	shl.b64 	%rd145, %rd151, 2;
	add.s64 	%rd146, %rd144, %rd145;
	ld.global.u32 	%r74, [%rd146];
	add.s64 	%rd147, %rd1, %rd145;
	st.global.u32 	[%rd147], %r74;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd151, %r78;
	setp.lt.u64 	%p28, %rd151, %rd51;
	@%p28 bra 	$L__BB6_30;
	bra.uni 	$L__BB6_31;

$L__BB6_11:
	setp.ge.u64 	%p14, %rd151, %rd51;
	@%p14 bra 	$L__BB6_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB6_27;

$L__BB6_13:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB6_14:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r80;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB6_16;

	div.u64 	%rd152, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd152, %rd21;
	sub.s64 	%rd153, %rd19, %rd96;
	bra.uni 	$L__BB6_17;

$L__BB6_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd152, %r49;
	cvt.u64.u32 	%rd153, %r51;

$L__BB6_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd153;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd152;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd101, %r79;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p17 bra 	$L__BB6_14;

$L__BB6_18:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r83;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB6_20;

	div.u64 	%rd154, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd154, %rd30;
	sub.s64 	%rd155, %rd28, %rd107;
	bra.uni 	$L__BB6_21;

$L__BB6_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd154, %r58;
	cvt.u64.u32 	%rd155, %r60;

$L__BB6_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd155;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd154;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd112, %r82;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p19 bra 	$L__BB6_18;

$L__BB6_22:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r86;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB6_24;

	div.u64 	%rd156, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd156, %rd39;
	sub.s64 	%rd157, %rd37, %rd118;
	bra.uni 	$L__BB6_25;

$L__BB6_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd156, %r67;
	cvt.u64.u32 	%rd157, %r69;

$L__BB6_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd157;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd156;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd123, %r85;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB6_22;

	mul.wide.u32 	%rd124, %r81, 8;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u64 	%rd126, [%rd125];
	setp.eq.s64 	%p22, %rd126, 0;
	mul.wide.u32 	%rd128, %r84, 4;
	add.s64 	%rd129, %rd3, %rd128;
	mul.wide.u32 	%rd131, %r87, 4;
	add.s64 	%rd132, %rd2, %rd131;
	selp.b64 	%rd133, %rd132, %rd129, %p22;
	ld.global.u32 	%r71, [%rd133];
	shl.b64 	%rd135, %rd151, 2;
	add.s64 	%rd136, %rd1, %rd135;
	st.global.u32 	[%rd136], %r71;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd151, %r78;
	setp.lt.u64 	%p23, %rd151, %rd51;
	@%p23 bra 	$L__BB6_13;
	bra.uni 	$L__BB6_31;

$L__BB6_27:
	ld.global.u64 	%rd137, [%rd4];
	setp.eq.s64 	%p24, %rd137, 0;
	selp.b64 	%rd138, %rd2, %rd3, %p24;
	ld.global.u32 	%r72, [%rd138];
	shl.b64 	%rd139, %rd151, 2;
	add.s64 	%rd140, %rd1, %rd139;
	st.global.u32 	[%rd140], %r72;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd151, %r78;
	setp.lt.u64 	%p25, %rd151, %rd51;
	@%p25 bra 	$L__BB6_27;

$L__BB6_31:
	ret;

}
	// .globl	where_i64_i64
.visible .entry where_i64_i64(
	.param .u64 where_i64_i64_param_0,
	.param .u64 where_i64_i64_param_1,
	.param .u64 where_i64_i64_param_2,
	.param .u64 where_i64_i64_param_3,
	.param .u64 where_i64_i64_param_4,
	.param .u64 where_i64_i64_param_5,
	.param .u64 where_i64_i64_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<162>;


	ld.param.u64 	%rd51, [where_i64_i64_param_0];
	ld.param.u64 	%rd52, [where_i64_i64_param_1];
	ld.param.u64 	%rd56, [where_i64_i64_param_2];
	ld.param.u64 	%rd57, [where_i64_i64_param_3];
	ld.param.u64 	%rd53, [where_i64_i64_param_4];
	ld.param.u64 	%rd54, [where_i64_i64_param_5];
	ld.param.u64 	%rd55, [where_i64_i64_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB7_10;

	mov.u64 	%rd150, 1;
	mov.u32 	%r72, 0;

$L__BB7_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd150, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB7_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd150, %rd67, %rd150;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB7_2;

	mov.u64 	%rd151, 1;
	mov.u32 	%r73, 0;

$L__BB7_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd151, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB7_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd151, %rd78, %rd151;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB7_5;

	mov.u64 	%rd152, 1;
	mov.u32 	%r74, 0;

$L__BB7_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd152, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB7_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd152, %rd89, %rd152;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB7_8;

$L__BB7_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd153, %r75;
	@%p29 bra 	$L__BB7_28;
	bra.uni 	$L__BB7_11;

$L__BB7_28:
	setp.ge.u64 	%p26, %rd153, %rd51;
	@%p26 bra 	$L__BB7_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB7_30:
	shl.b64 	%rd143, %rd153, 3;
	add.s64 	%rd144, %rd4, %rd143;
	ld.global.u64 	%rd145, [%rd144];
	setp.eq.s64 	%p27, %rd145, 0;
	selp.b64 	%rd146, %rd2, %rd3, %p27;
	add.s64 	%rd147, %rd146, %rd143;
	ld.global.u64 	%rd148, [%rd147];
	add.s64 	%rd149, %rd1, %rd143;
	st.global.u64 	[%rd149], %rd148;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd153, %r75;
	setp.lt.u64 	%p28, %rd153, %rd51;
	@%p28 bra 	$L__BB7_30;
	bra.uni 	$L__BB7_31;

$L__BB7_11:
	setp.ge.u64 	%p14, %rd153, %rd51;
	@%p14 bra 	$L__BB7_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB7_27;

$L__BB7_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB7_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB7_16;

	div.u64 	%rd154, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd154, %rd21;
	sub.s64 	%rd155, %rd19, %rd96;
	bra.uni 	$L__BB7_17;

$L__BB7_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd154, %r49;
	cvt.u64.u32 	%rd155, %r51;

$L__BB7_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd155;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd154;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB7_14;

$L__BB7_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB7_20;

	div.u64 	%rd156, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd156, %rd30;
	sub.s64 	%rd157, %rd28, %rd107;
	bra.uni 	$L__BB7_21;

$L__BB7_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd156, %r58;
	cvt.u64.u32 	%rd157, %r60;

$L__BB7_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd157;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd156;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB7_18;

$L__BB7_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB7_24;

	div.u64 	%rd158, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd158, %rd39;
	sub.s64 	%rd159, %rd37, %rd118;
	bra.uni 	$L__BB7_25;

$L__BB7_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd158, %r67;
	cvt.u64.u32 	%rd159, %r69;

$L__BB7_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd159;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd158;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB7_22;

	mul.wide.u32 	%rd124, %r78, 8;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u64 	%rd126, [%rd125];
	setp.eq.s64 	%p22, %rd126, 0;
	mul.wide.u32 	%rd128, %r81, 8;
	add.s64 	%rd129, %rd3, %rd128;
	mul.wide.u32 	%rd131, %r84, 8;
	add.s64 	%rd132, %rd2, %rd131;
	selp.b64 	%rd133, %rd132, %rd129, %p22;
	ld.global.u64 	%rd134, [%rd133];
	shl.b64 	%rd136, %rd153, 3;
	add.s64 	%rd137, %rd1, %rd136;
	st.global.u64 	[%rd137], %rd134;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd153, %r75;
	setp.lt.u64 	%p23, %rd153, %rd51;
	@%p23 bra 	$L__BB7_13;
	bra.uni 	$L__BB7_31;

$L__BB7_27:
	ld.global.u64 	%rd138, [%rd4];
	setp.eq.s64 	%p24, %rd138, 0;
	selp.b64 	%rd139, %rd2, %rd3, %p24;
	ld.global.u64 	%rd140, [%rd139];
	shl.b64 	%rd141, %rd153, 3;
	add.s64 	%rd142, %rd1, %rd141;
	st.global.u64 	[%rd142], %rd140;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd153, %r75;
	setp.lt.u64 	%p25, %rd153, %rd51;
	@%p25 bra 	$L__BB7_27;

$L__BB7_31:
	ret;

}
	// .globl	where_u32_f32
.visible .entry where_u32_f32(
	.param .u64 where_u32_f32_param_0,
	.param .u64 where_u32_f32_param_1,
	.param .u64 where_u32_f32_param_2,
	.param .u64 where_u32_f32_param_3,
	.param .u64 where_u32_f32_param_4,
	.param .u64 where_u32_f32_param_5,
	.param .u64 where_u32_f32_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd51, [where_u32_f32_param_0];
	ld.param.u64 	%rd52, [where_u32_f32_param_1];
	ld.param.u64 	%rd56, [where_u32_f32_param_2];
	ld.param.u64 	%rd57, [where_u32_f32_param_3];
	ld.param.u64 	%rd53, [where_u32_f32_param_4];
	ld.param.u64 	%rd54, [where_u32_f32_param_5];
	ld.param.u64 	%rd55, [where_u32_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB8_10;

	mov.u64 	%rd144, 1;
	mov.u32 	%r75, 0;

$L__BB8_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd144, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB8_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd144, %rd67, %rd144;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd68, %r75;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB8_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r76, 0;

$L__BB8_5:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd145, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB8_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd145, %rd78, %rd145;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd79, %r76;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB8_5;

	mov.u64 	%rd146, 1;
	mov.u32 	%r77, 0;

$L__BB8_8:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd146, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB8_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd146, %rd89, %rd146;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd90, %r77;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB8_8;

$L__BB8_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r78;
	@%p29 bra 	$L__BB8_28;
	bra.uni 	$L__BB8_11;

$L__BB8_28:
	setp.ge.u64 	%p26, %rd147, %rd51;
	@%p26 bra 	$L__BB8_31;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB8_30:
	shl.b64 	%rd139, %rd147, 2;
	add.s64 	%rd140, %rd4, %rd139;
	ld.global.u32 	%r74, [%rd140];
	setp.eq.s32 	%p27, %r74, 0;
	selp.b64 	%rd141, %rd2, %rd3, %p27;
	add.s64 	%rd142, %rd141, %rd139;
	ld.global.f32 	%f3, [%rd142];
	add.s64 	%rd143, %rd1, %rd139;
	st.global.f32 	[%rd143], %f3;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd147, %r78;
	setp.lt.u64 	%p28, %rd147, %rd51;
	@%p28 bra 	$L__BB8_30;
	bra.uni 	$L__BB8_31;

$L__BB8_11:
	setp.ge.u64 	%p14, %rd147, %rd51;
	@%p14 bra 	$L__BB8_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB8_27;

$L__BB8_13:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB8_14:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r80;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB8_16;

	div.u64 	%rd148, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd148, %rd21;
	sub.s64 	%rd149, %rd19, %rd96;
	bra.uni 	$L__BB8_17;

$L__BB8_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB8_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd149;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd148;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd101, %r79;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p17 bra 	$L__BB8_14;

$L__BB8_18:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r83;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB8_20;

	div.u64 	%rd150, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd150, %rd30;
	sub.s64 	%rd151, %rd28, %rd107;
	bra.uni 	$L__BB8_21;

$L__BB8_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB8_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd151;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd150;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd112, %r82;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p19 bra 	$L__BB8_18;

$L__BB8_22:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r86;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB8_24;

	div.u64 	%rd152, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd152, %rd39;
	sub.s64 	%rd153, %rd37, %rd118;
	bra.uni 	$L__BB8_25;

$L__BB8_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB8_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd153;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd152;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd123, %r85;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB8_22;

	mul.wide.u32 	%rd124, %r81, 4;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u32 	%r71, [%rd125];
	setp.eq.s32 	%p22, %r71, 0;
	mul.wide.u32 	%rd127, %r84, 4;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r87, 4;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.f32 	%f1, [%rd132];
	shl.b64 	%rd134, %rd147, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f32 	[%rd135], %f1;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd147, %r78;
	setp.lt.u64 	%p23, %rd147, %rd51;
	@%p23 bra 	$L__BB8_13;
	bra.uni 	$L__BB8_31;

$L__BB8_27:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p24, %r72, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p24;
	ld.global.f32 	%f2, [%rd136];
	shl.b64 	%rd137, %rd147, 2;
	add.s64 	%rd138, %rd1, %rd137;
	st.global.f32 	[%rd138], %f2;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd147, %r78;
	setp.lt.u64 	%p25, %rd147, %rd51;
	@%p25 bra 	$L__BB8_27;

$L__BB8_31:
	ret;

}
	// .globl	where_u32_f64
.visible .entry where_u32_f64(
	.param .u64 where_u32_f64_param_0,
	.param .u64 where_u32_f64_param_1,
	.param .u64 where_u32_f64_param_2,
	.param .u64 where_u32_f64_param_3,
	.param .u64 where_u32_f64_param_4,
	.param .u64 where_u32_f64_param_5,
	.param .u64 where_u32_f64_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b32 	%r<90>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<157>;


	ld.param.u64 	%rd51, [where_u32_f64_param_0];
	ld.param.u64 	%rd52, [where_u32_f64_param_1];
	ld.param.u64 	%rd56, [where_u32_f64_param_2];
	ld.param.u64 	%rd57, [where_u32_f64_param_3];
	ld.param.u64 	%rd53, [where_u32_f64_param_4];
	ld.param.u64 	%rd54, [where_u32_f64_param_5];
	ld.param.u64 	%rd55, [where_u32_f64_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB9_10;

	mov.u64 	%rd145, 1;
	mov.u32 	%r75, 0;

$L__BB9_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd145, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB9_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd145, %rd67, %rd145;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd68, %r75;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB9_2;

	mov.u64 	%rd146, 1;
	mov.u32 	%r76, 0;

$L__BB9_5:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd146, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB9_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd146, %rd78, %rd146;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd79, %r76;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB9_5;

	mov.u64 	%rd147, 1;
	mov.u32 	%r77, 0;

$L__BB9_8:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd147, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB9_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd147, %rd89, %rd147;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd90, %r77;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB9_8;

$L__BB9_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd148, %r78;
	@%p29 bra 	$L__BB9_28;
	bra.uni 	$L__BB9_11;

$L__BB9_28:
	setp.ge.u64 	%p26, %rd148, %rd51;
	@%p26 bra 	$L__BB9_31;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB9_30:
	shl.b64 	%rd139, %rd148, 2;
	add.s64 	%rd140, %rd4, %rd139;
	ld.global.u32 	%r74, [%rd140];
	setp.eq.s32 	%p27, %r74, 0;
	selp.b64 	%rd141, %rd2, %rd3, %p27;
	shl.b64 	%rd142, %rd148, 3;
	add.s64 	%rd143, %rd141, %rd142;
	ld.global.f64 	%fd3, [%rd143];
	add.s64 	%rd144, %rd1, %rd142;
	st.global.f64 	[%rd144], %fd3;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p28, %rd148, %rd51;
	@%p28 bra 	$L__BB9_30;
	bra.uni 	$L__BB9_31;

$L__BB9_11:
	setp.ge.u64 	%p14, %rd148, %rd51;
	@%p14 bra 	$L__BB9_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB9_27;

$L__BB9_13:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB9_14:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r80;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB9_16;

	div.u64 	%rd149, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd149, %rd21;
	sub.s64 	%rd150, %rd19, %rd96;
	bra.uni 	$L__BB9_17;

$L__BB9_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd149, %r49;
	cvt.u64.u32 	%rd150, %r51;

$L__BB9_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd150;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd149;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd101, %r79;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p17 bra 	$L__BB9_14;

$L__BB9_18:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r83;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB9_20;

	div.u64 	%rd151, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd151, %rd30;
	sub.s64 	%rd152, %rd28, %rd107;
	bra.uni 	$L__BB9_21;

$L__BB9_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd151, %r58;
	cvt.u64.u32 	%rd152, %r60;

$L__BB9_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd152;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd151;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd112, %r82;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p19 bra 	$L__BB9_18;

$L__BB9_22:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r86;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB9_24;

	div.u64 	%rd153, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd153, %rd39;
	sub.s64 	%rd154, %rd37, %rd118;
	bra.uni 	$L__BB9_25;

$L__BB9_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd153, %r67;
	cvt.u64.u32 	%rd154, %r69;

$L__BB9_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd154;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd153;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd123, %r85;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB9_22;

	mul.wide.u32 	%rd124, %r81, 4;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u32 	%r71, [%rd125];
	setp.eq.s32 	%p22, %r71, 0;
	mul.wide.u32 	%rd127, %r84, 8;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r87, 8;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.f64 	%fd1, [%rd132];
	shl.b64 	%rd134, %rd148, 3;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f64 	[%rd135], %fd1;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p23, %rd148, %rd51;
	@%p23 bra 	$L__BB9_13;
	bra.uni 	$L__BB9_31;

$L__BB9_27:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p24, %r72, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p24;
	ld.global.f64 	%fd2, [%rd136];
	shl.b64 	%rd137, %rd148, 3;
	add.s64 	%rd138, %rd1, %rd137;
	st.global.f64 	[%rd138], %fd2;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd148, %r78;
	setp.lt.u64 	%p25, %rd148, %rd51;
	@%p25 bra 	$L__BB9_27;

$L__BB9_31:
	ret;

}
	// .globl	where_u32_u8
.visible .entry where_u32_u8(
	.param .u64 where_u32_u8_param_0,
	.param .u64 where_u32_u8_param_1,
	.param .u64 where_u32_u8_param_2,
	.param .u64 where_u32_u8_param_3,
	.param .u64 where_u32_u8_param_4,
	.param .u64 where_u32_u8_param_5,
	.param .u64 where_u32_u8_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<154>;


	ld.param.u64 	%rd51, [where_u32_u8_param_0];
	ld.param.u64 	%rd52, [where_u32_u8_param_1];
	ld.param.u64 	%rd56, [where_u32_u8_param_2];
	ld.param.u64 	%rd57, [where_u32_u8_param_3];
	ld.param.u64 	%rd53, [where_u32_u8_param_4];
	ld.param.u64 	%rd54, [where_u32_u8_param_5];
	ld.param.u64 	%rd55, [where_u32_u8_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB10_10;

	mov.u64 	%rd142, 1;
	mov.u32 	%r75, 0;

$L__BB10_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd142, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB10_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd142, %rd67, %rd142;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd68, %r75;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB10_2;

	mov.u64 	%rd143, 1;
	mov.u32 	%r76, 0;

$L__BB10_5:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd143, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB10_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd143, %rd78, %rd143;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd79, %r76;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB10_5;

	mov.u64 	%rd144, 1;
	mov.u32 	%r77, 0;

$L__BB10_8:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd144, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB10_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd144, %rd89, %rd144;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd90, %r77;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB10_8;

$L__BB10_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd145, %r78;
	@%p29 bra 	$L__BB10_28;
	bra.uni 	$L__BB10_11;

$L__BB10_28:
	setp.ge.u64 	%p26, %rd145, %rd51;
	@%p26 bra 	$L__BB10_31;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB10_30:
	shl.b64 	%rd137, %rd145, 2;
	add.s64 	%rd138, %rd4, %rd137;
	ld.global.u32 	%r74, [%rd138];
	setp.eq.s32 	%p27, %r74, 0;
	selp.b64 	%rd139, %rd2, %rd3, %p27;
	add.s64 	%rd140, %rd139, %rd145;
	ld.global.u8 	%rs3, [%rd140];
	add.s64 	%rd141, %rd1, %rd145;
	st.global.u8 	[%rd141], %rs3;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd145, %r78;
	setp.lt.u64 	%p28, %rd145, %rd51;
	@%p28 bra 	$L__BB10_30;
	bra.uni 	$L__BB10_31;

$L__BB10_11:
	setp.ge.u64 	%p14, %rd145, %rd51;
	@%p14 bra 	$L__BB10_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB10_27;

$L__BB10_13:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB10_14:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r80;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB10_16;

	div.u64 	%rd146, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd146, %rd21;
	sub.s64 	%rd147, %rd19, %rd96;
	bra.uni 	$L__BB10_17;

$L__BB10_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd146, %r49;
	cvt.u64.u32 	%rd147, %r51;

$L__BB10_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd147;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd146;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd101, %r79;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p17 bra 	$L__BB10_14;

$L__BB10_18:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r83;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB10_20;

	div.u64 	%rd148, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd148, %rd30;
	sub.s64 	%rd149, %rd28, %rd107;
	bra.uni 	$L__BB10_21;

$L__BB10_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd148, %r58;
	cvt.u64.u32 	%rd149, %r60;

$L__BB10_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd149;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd148;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd112, %r82;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p19 bra 	$L__BB10_18;

$L__BB10_22:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r86;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB10_24;

	div.u64 	%rd150, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd150, %rd39;
	sub.s64 	%rd151, %rd37, %rd118;
	bra.uni 	$L__BB10_25;

$L__BB10_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd150, %r67;
	cvt.u64.u32 	%rd151, %r69;

$L__BB10_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd151;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd150;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd123, %r85;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB10_22;

	mul.wide.u32 	%rd124, %r81, 4;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u32 	%r71, [%rd125];
	setp.eq.s32 	%p22, %r71, 0;
	cvt.u64.u32 	%rd126, %r84;
	add.s64 	%rd128, %rd3, %rd126;
	cvt.u64.u32 	%rd129, %r87;
	add.s64 	%rd131, %rd2, %rd129;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u8 	%rs1, [%rd132];
	add.s64 	%rd134, %rd1, %rd145;
	st.global.u8 	[%rd134], %rs1;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd145, %r78;
	setp.lt.u64 	%p23, %rd145, %rd51;
	@%p23 bra 	$L__BB10_13;
	bra.uni 	$L__BB10_31;

$L__BB10_27:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p24, %r72, 0;
	selp.b64 	%rd135, %rd2, %rd3, %p24;
	ld.global.u8 	%rs2, [%rd135];
	add.s64 	%rd136, %rd1, %rd145;
	st.global.u8 	[%rd136], %rs2;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd145, %r78;
	setp.lt.u64 	%p25, %rd145, %rd51;
	@%p25 bra 	$L__BB10_27;

$L__BB10_31:
	ret;

}
	// .globl	where_u32_u32
.visible .entry where_u32_u32(
	.param .u64 where_u32_u32_param_0,
	.param .u64 where_u32_u32_param_1,
	.param .u64 where_u32_u32_param_2,
	.param .u64 where_u32_u32_param_3,
	.param .u64 where_u32_u32_param_4,
	.param .u64 where_u32_u32_param_5,
	.param .u64 where_u32_u32_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b32 	%r<93>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd51, [where_u32_u32_param_0];
	ld.param.u64 	%rd52, [where_u32_u32_param_1];
	ld.param.u64 	%rd56, [where_u32_u32_param_2];
	ld.param.u64 	%rd57, [where_u32_u32_param_3];
	ld.param.u64 	%rd53, [where_u32_u32_param_4];
	ld.param.u64 	%rd54, [where_u32_u32_param_5];
	ld.param.u64 	%rd55, [where_u32_u32_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB11_10;

	mov.u64 	%rd144, 1;
	mov.u32 	%r78, 0;

$L__BB11_2:
	not.b32 	%r36, %r78;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd144, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB11_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd144, %rd67, %rd144;
	add.s32 	%r78, %r78, 1;
	cvt.u64.u32 	%rd68, %r78;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB11_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r79, 0;

$L__BB11_5:
	not.b32 	%r38, %r79;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd145, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB11_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd145, %rd78, %rd145;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd79, %r79;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB11_5;

	mov.u64 	%rd146, 1;
	mov.u32 	%r80, 0;

$L__BB11_8:
	not.b32 	%r40, %r80;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd146, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB11_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd146, %rd89, %rd146;
	add.s32 	%r80, %r80, 1;
	cvt.u64.u32 	%rd90, %r80;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB11_8;

$L__BB11_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r81, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r81;
	@%p29 bra 	$L__BB11_28;
	bra.uni 	$L__BB11_11;

$L__BB11_28:
	setp.ge.u64 	%p26, %rd147, %rd51;
	@%p26 bra 	$L__BB11_31;

	mov.u32 	%r75, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r75;

$L__BB11_30:
	shl.b64 	%rd139, %rd147, 2;
	add.s64 	%rd140, %rd4, %rd139;
	ld.global.u32 	%r76, [%rd140];
	setp.eq.s32 	%p27, %r76, 0;
	selp.b64 	%rd141, %rd2, %rd3, %p27;
	add.s64 	%rd142, %rd141, %rd139;
	ld.global.u32 	%r77, [%rd142];
	add.s64 	%rd143, %rd1, %rd139;
	st.global.u32 	[%rd143], %r77;
	add.s32 	%r81, %r81, %r32;
	cvt.u64.u32 	%rd147, %r81;
	setp.lt.u64 	%p28, %rd147, %rd51;
	@%p28 bra 	$L__BB11_30;
	bra.uni 	$L__BB11_31;

$L__BB11_11:
	setp.ge.u64 	%p14, %rd147, %rd51;
	@%p14 bra 	$L__BB11_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB11_27;

$L__BB11_13:
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r81;
	mov.u32 	%r84, %r82;

$L__BB11_14:
	not.b32 	%r46, %r82;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r83;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB11_16;

	div.u64 	%rd148, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd148, %rd21;
	sub.s64 	%rd149, %rd19, %rd96;
	bra.uni 	$L__BB11_17;

$L__BB11_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB11_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd149;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r84, %r84, %r54;
	cvt.u32.u64 	%r83, %rd148;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd101, %r82;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r81;
	mov.u32 	%r87, %r85;
	@%p17 bra 	$L__BB11_14;

$L__BB11_18:
	not.b32 	%r55, %r85;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r86;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB11_20;

	div.u64 	%rd150, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd150, %rd30;
	sub.s64 	%rd151, %rd28, %rd107;
	bra.uni 	$L__BB11_21;

$L__BB11_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB11_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd151;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r87, %r87, %r63;
	cvt.u32.u64 	%r86, %rd150;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd112, %r85;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r88, 0;
	mov.u32 	%r89, %r81;
	mov.u32 	%r90, %r88;
	@%p19 bra 	$L__BB11_18;

$L__BB11_22:
	not.b32 	%r64, %r88;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r89;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB11_24;

	div.u64 	%rd152, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd152, %rd39;
	sub.s64 	%rd153, %rd37, %rd118;
	bra.uni 	$L__BB11_25;

$L__BB11_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB11_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd153;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r90, %r90, %r70;
	cvt.u32.u64 	%r89, %rd152;
	add.s32 	%r88, %r88, 1;
	cvt.u64.u32 	%rd123, %r88;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB11_22;

	mul.wide.u32 	%rd124, %r84, 4;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u32 	%r71, [%rd125];
	setp.eq.s32 	%p22, %r71, 0;
	mul.wide.u32 	%rd127, %r87, 4;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r90, 4;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u32 	%r72, [%rd132];
	shl.b64 	%rd134, %rd147, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.u32 	[%rd135], %r72;
	add.s32 	%r81, %r81, %r9;
	cvt.u64.u32 	%rd147, %r81;
	setp.lt.u64 	%p23, %rd147, %rd51;
	@%p23 bra 	$L__BB11_13;
	bra.uni 	$L__BB11_31;

$L__BB11_27:
	ld.global.u32 	%r73, [%rd4];
	setp.eq.s32 	%p24, %r73, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p24;
	ld.global.u32 	%r74, [%rd136];
	shl.b64 	%rd137, %rd147, 2;
	add.s64 	%rd138, %rd1, %rd137;
	st.global.u32 	[%rd138], %r74;
	add.s32 	%r81, %r81, %r9;
	cvt.u64.u32 	%rd147, %r81;
	setp.lt.u64 	%p25, %rd147, %rd51;
	@%p25 bra 	$L__BB11_27;

$L__BB11_31:
	ret;

}
	// .globl	where_u32_i64
.visible .entry where_u32_i64(
	.param .u64 where_u32_i64_param_0,
	.param .u64 where_u32_i64_param_1,
	.param .u64 where_u32_i64_param_2,
	.param .u64 where_u32_i64_param_3,
	.param .u64 where_u32_i64_param_4,
	.param .u64 where_u32_i64_param_5,
	.param .u64 where_u32_i64_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<160>;


	ld.param.u64 	%rd51, [where_u32_i64_param_0];
	ld.param.u64 	%rd52, [where_u32_i64_param_1];
	ld.param.u64 	%rd56, [where_u32_i64_param_2];
	ld.param.u64 	%rd57, [where_u32_i64_param_3];
	ld.param.u64 	%rd53, [where_u32_i64_param_4];
	ld.param.u64 	%rd54, [where_u32_i64_param_5];
	ld.param.u64 	%rd55, [where_u32_i64_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB12_10;

	mov.u64 	%rd148, 1;
	mov.u32 	%r75, 0;

$L__BB12_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd148, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB12_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd148, %rd67, %rd148;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd68, %r75;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB12_2;

	mov.u64 	%rd149, 1;
	mov.u32 	%r76, 0;

$L__BB12_5:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd149, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB12_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd149, %rd78, %rd149;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd79, %r76;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB12_5;

	mov.u64 	%rd150, 1;
	mov.u32 	%r77, 0;

$L__BB12_8:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd150, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB12_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd150, %rd89, %rd150;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd90, %r77;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB12_8;

$L__BB12_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd151, %r78;
	@%p29 bra 	$L__BB12_28;
	bra.uni 	$L__BB12_11;

$L__BB12_28:
	setp.ge.u64 	%p26, %rd151, %rd51;
	@%p26 bra 	$L__BB12_31;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB12_30:
	shl.b64 	%rd141, %rd151, 2;
	add.s64 	%rd142, %rd4, %rd141;
	ld.global.u32 	%r74, [%rd142];
	setp.eq.s32 	%p27, %r74, 0;
	selp.b64 	%rd143, %rd2, %rd3, %p27;
	shl.b64 	%rd144, %rd151, 3;
	add.s64 	%rd145, %rd143, %rd144;
	ld.global.u64 	%rd146, [%rd145];
	add.s64 	%rd147, %rd1, %rd144;
	st.global.u64 	[%rd147], %rd146;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd151, %r78;
	setp.lt.u64 	%p28, %rd151, %rd51;
	@%p28 bra 	$L__BB12_30;
	bra.uni 	$L__BB12_31;

$L__BB12_11:
	setp.ge.u64 	%p14, %rd151, %rd51;
	@%p14 bra 	$L__BB12_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB12_27;

$L__BB12_13:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB12_14:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r80;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB12_16;

	div.u64 	%rd152, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd152, %rd21;
	sub.s64 	%rd153, %rd19, %rd96;
	bra.uni 	$L__BB12_17;

$L__BB12_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd152, %r49;
	cvt.u64.u32 	%rd153, %r51;

$L__BB12_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd153;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd152;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd101, %r79;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p17 bra 	$L__BB12_14;

$L__BB12_18:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r83;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB12_20;

	div.u64 	%rd154, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd154, %rd30;
	sub.s64 	%rd155, %rd28, %rd107;
	bra.uni 	$L__BB12_21;

$L__BB12_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd154, %r58;
	cvt.u64.u32 	%rd155, %r60;

$L__BB12_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd155;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd154;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd112, %r82;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p19 bra 	$L__BB12_18;

$L__BB12_22:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r86;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB12_24;

	div.u64 	%rd156, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd156, %rd39;
	sub.s64 	%rd157, %rd37, %rd118;
	bra.uni 	$L__BB12_25;

$L__BB12_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd156, %r67;
	cvt.u64.u32 	%rd157, %r69;

$L__BB12_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd157;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd156;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd123, %r85;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB12_22;

	mul.wide.u32 	%rd124, %r81, 4;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u32 	%r71, [%rd125];
	setp.eq.s32 	%p22, %r71, 0;
	mul.wide.u32 	%rd127, %r84, 8;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r87, 8;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u64 	%rd133, [%rd132];
	shl.b64 	%rd135, %rd151, 3;
	add.s64 	%rd136, %rd1, %rd135;
	st.global.u64 	[%rd136], %rd133;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd151, %r78;
	setp.lt.u64 	%p23, %rd151, %rd51;
	@%p23 bra 	$L__BB12_13;
	bra.uni 	$L__BB12_31;

$L__BB12_27:
	ld.global.u32 	%r72, [%rd4];
	setp.eq.s32 	%p24, %r72, 0;
	selp.b64 	%rd137, %rd2, %rd3, %p24;
	ld.global.u64 	%rd138, [%rd137];
	shl.b64 	%rd139, %rd151, 3;
	add.s64 	%rd140, %rd1, %rd139;
	st.global.u64 	[%rd140], %rd138;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd151, %r78;
	setp.lt.u64 	%p25, %rd151, %rd51;
	@%p25 bra 	$L__BB12_27;

$L__BB12_31:
	ret;

}
	// .globl	where_u8_f32
.visible .entry where_u8_f32(
	.param .u64 where_u8_f32_param_0,
	.param .u64 where_u8_f32_param_1,
	.param .u64 where_u8_f32_param_2,
	.param .u64 where_u8_f32_param_3,
	.param .u64 where_u8_f32_param_4,
	.param .u64 where_u8_f32_param_5,
	.param .u64 where_u8_f32_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd51, [where_u8_f32_param_0];
	ld.param.u64 	%rd52, [where_u8_f32_param_1];
	ld.param.u64 	%rd56, [where_u8_f32_param_2];
	ld.param.u64 	%rd57, [where_u8_f32_param_3];
	ld.param.u64 	%rd53, [where_u8_f32_param_4];
	ld.param.u64 	%rd54, [where_u8_f32_param_5];
	ld.param.u64 	%rd55, [where_u8_f32_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB13_10;

	mov.u64 	%rd144, 1;
	mov.u32 	%r72, 0;

$L__BB13_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd144, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB13_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd144, %rd67, %rd144;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB13_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r73, 0;

$L__BB13_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd145, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB13_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd145, %rd78, %rd145;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB13_5;

	mov.u64 	%rd146, 1;
	mov.u32 	%r74, 0;

$L__BB13_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd146, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB13_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd146, %rd89, %rd146;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB13_8;

$L__BB13_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r75;
	@%p29 bra 	$L__BB13_28;
	bra.uni 	$L__BB13_11;

$L__BB13_28:
	setp.ge.u64 	%p26, %rd147, %rd51;
	@%p26 bra 	$L__BB13_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB13_30:
	add.s64 	%rd139, %rd4, %rd147;
	ld.global.u8 	%rs3, [%rd139];
	setp.eq.s16 	%p27, %rs3, 0;
	selp.b64 	%rd140, %rd2, %rd3, %p27;
	shl.b64 	%rd141, %rd147, 2;
	add.s64 	%rd142, %rd140, %rd141;
	ld.global.f32 	%f3, [%rd142];
	add.s64 	%rd143, %rd1, %rd141;
	st.global.f32 	[%rd143], %f3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p28, %rd147, %rd51;
	@%p28 bra 	$L__BB13_30;
	bra.uni 	$L__BB13_31;

$L__BB13_11:
	setp.ge.u64 	%p14, %rd147, %rd51;
	@%p14 bra 	$L__BB13_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB13_27;

$L__BB13_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB13_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB13_16;

	div.u64 	%rd148, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd148, %rd21;
	sub.s64 	%rd149, %rd19, %rd96;
	bra.uni 	$L__BB13_17;

$L__BB13_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB13_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd149;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd148;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB13_14;

$L__BB13_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB13_20;

	div.u64 	%rd150, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd150, %rd30;
	sub.s64 	%rd151, %rd28, %rd107;
	bra.uni 	$L__BB13_21;

$L__BB13_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB13_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd151;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd150;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB13_18;

$L__BB13_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB13_24;

	div.u64 	%rd152, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd152, %rd39;
	sub.s64 	%rd153, %rd37, %rd118;
	bra.uni 	$L__BB13_25;

$L__BB13_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB13_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd153;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd152;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB13_22;

	cvt.u64.u32 	%rd124, %r78;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u8 	%rs1, [%rd125];
	setp.eq.s16 	%p22, %rs1, 0;
	mul.wide.u32 	%rd127, %r81, 4;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r84, 4;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.f32 	%f1, [%rd132];
	shl.b64 	%rd134, %rd147, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f32 	[%rd135], %f1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p23, %rd147, %rd51;
	@%p23 bra 	$L__BB13_13;
	bra.uni 	$L__BB13_31;

$L__BB13_27:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p24, %rs2, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p24;
	ld.global.f32 	%f2, [%rd136];
	shl.b64 	%rd137, %rd147, 2;
	add.s64 	%rd138, %rd1, %rd137;
	st.global.f32 	[%rd138], %f2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p25, %rd147, %rd51;
	@%p25 bra 	$L__BB13_27;

$L__BB13_31:
	ret;

}
	// .globl	where_u8_f64
.visible .entry where_u8_f64(
	.param .u64 where_u8_f64_param_0,
	.param .u64 where_u8_f64_param_1,
	.param .u64 where_u8_f64_param_2,
	.param .u64 where_u8_f64_param_3,
	.param .u64 where_u8_f64_param_4,
	.param .u64 where_u8_f64_param_5,
	.param .u64 where_u8_f64_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<87>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd51, [where_u8_f64_param_0];
	ld.param.u64 	%rd52, [where_u8_f64_param_1];
	ld.param.u64 	%rd56, [where_u8_f64_param_2];
	ld.param.u64 	%rd57, [where_u8_f64_param_3];
	ld.param.u64 	%rd53, [where_u8_f64_param_4];
	ld.param.u64 	%rd54, [where_u8_f64_param_5];
	ld.param.u64 	%rd55, [where_u8_f64_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB14_10;

	mov.u64 	%rd144, 1;
	mov.u32 	%r72, 0;

$L__BB14_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd144, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB14_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd144, %rd67, %rd144;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB14_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r73, 0;

$L__BB14_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd145, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB14_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd145, %rd78, %rd145;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB14_5;

	mov.u64 	%rd146, 1;
	mov.u32 	%r74, 0;

$L__BB14_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd146, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB14_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd146, %rd89, %rd146;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB14_8;

$L__BB14_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r75;
	@%p29 bra 	$L__BB14_28;
	bra.uni 	$L__BB14_11;

$L__BB14_28:
	setp.ge.u64 	%p26, %rd147, %rd51;
	@%p26 bra 	$L__BB14_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB14_30:
	add.s64 	%rd139, %rd4, %rd147;
	ld.global.u8 	%rs3, [%rd139];
	setp.eq.s16 	%p27, %rs3, 0;
	selp.b64 	%rd140, %rd2, %rd3, %p27;
	shl.b64 	%rd141, %rd147, 3;
	add.s64 	%rd142, %rd140, %rd141;
	ld.global.f64 	%fd3, [%rd142];
	add.s64 	%rd143, %rd1, %rd141;
	st.global.f64 	[%rd143], %fd3;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p28, %rd147, %rd51;
	@%p28 bra 	$L__BB14_30;
	bra.uni 	$L__BB14_31;

$L__BB14_11:
	setp.ge.u64 	%p14, %rd147, %rd51;
	@%p14 bra 	$L__BB14_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB14_27;

$L__BB14_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB14_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB14_16;

	div.u64 	%rd148, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd148, %rd21;
	sub.s64 	%rd149, %rd19, %rd96;
	bra.uni 	$L__BB14_17;

$L__BB14_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB14_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd149;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd148;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB14_14;

$L__BB14_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB14_20;

	div.u64 	%rd150, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd150, %rd30;
	sub.s64 	%rd151, %rd28, %rd107;
	bra.uni 	$L__BB14_21;

$L__BB14_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB14_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd151;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd150;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB14_18;

$L__BB14_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB14_24;

	div.u64 	%rd152, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd152, %rd39;
	sub.s64 	%rd153, %rd37, %rd118;
	bra.uni 	$L__BB14_25;

$L__BB14_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB14_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd153;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd152;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB14_22;

	cvt.u64.u32 	%rd124, %r78;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u8 	%rs1, [%rd125];
	setp.eq.s16 	%p22, %rs1, 0;
	mul.wide.u32 	%rd127, %r81, 8;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r84, 8;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.f64 	%fd1, [%rd132];
	shl.b64 	%rd134, %rd147, 3;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.f64 	[%rd135], %fd1;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p23, %rd147, %rd51;
	@%p23 bra 	$L__BB14_13;
	bra.uni 	$L__BB14_31;

$L__BB14_27:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p24, %rs2, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p24;
	ld.global.f64 	%fd2, [%rd136];
	shl.b64 	%rd137, %rd147, 3;
	add.s64 	%rd138, %rd1, %rd137;
	st.global.f64 	[%rd138], %fd2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd147, %r75;
	setp.lt.u64 	%p25, %rd147, %rd51;
	@%p25 bra 	$L__BB14_27;

$L__BB14_31:
	ret;

}
	// .globl	where_u8_u8
.visible .entry where_u8_u8(
	.param .u64 where_u8_u8_param_0,
	.param .u64 where_u8_u8_param_1,
	.param .u64 where_u8_u8_param_2,
	.param .u64 where_u8_u8_param_3,
	.param .u64 where_u8_u8_param_4,
	.param .u64 where_u8_u8_param_5,
	.param .u64 where_u8_u8_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<7>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<153>;


	ld.param.u64 	%rd51, [where_u8_u8_param_0];
	ld.param.u64 	%rd52, [where_u8_u8_param_1];
	ld.param.u64 	%rd56, [where_u8_u8_param_2];
	ld.param.u64 	%rd57, [where_u8_u8_param_3];
	ld.param.u64 	%rd53, [where_u8_u8_param_4];
	ld.param.u64 	%rd54, [where_u8_u8_param_5];
	ld.param.u64 	%rd55, [where_u8_u8_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB15_10;

	mov.u64 	%rd141, 1;
	mov.u32 	%r72, 0;

$L__BB15_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd141, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB15_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd141, %rd67, %rd141;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB15_2;

	mov.u64 	%rd142, 1;
	mov.u32 	%r73, 0;

$L__BB15_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd142, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB15_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd142, %rd78, %rd142;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB15_5;

	mov.u64 	%rd143, 1;
	mov.u32 	%r74, 0;

$L__BB15_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd143, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB15_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd143, %rd89, %rd143;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB15_8;

$L__BB15_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd144, %r75;
	@%p29 bra 	$L__BB15_28;
	bra.uni 	$L__BB15_11;

$L__BB15_28:
	setp.ge.u64 	%p26, %rd144, %rd51;
	@%p26 bra 	$L__BB15_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB15_30:
	add.s64 	%rd137, %rd4, %rd144;
	ld.global.u8 	%rs5, [%rd137];
	setp.eq.s16 	%p27, %rs5, 0;
	selp.b64 	%rd138, %rd2, %rd3, %p27;
	add.s64 	%rd139, %rd138, %rd144;
	ld.global.u8 	%rs6, [%rd139];
	add.s64 	%rd140, %rd1, %rd144;
	st.global.u8 	[%rd140], %rs6;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p28, %rd144, %rd51;
	@%p28 bra 	$L__BB15_30;
	bra.uni 	$L__BB15_31;

$L__BB15_11:
	setp.ge.u64 	%p14, %rd144, %rd51;
	@%p14 bra 	$L__BB15_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB15_27;

$L__BB15_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB15_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB15_16;

	div.u64 	%rd145, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd145, %rd21;
	sub.s64 	%rd146, %rd19, %rd96;
	bra.uni 	$L__BB15_17;

$L__BB15_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd145, %r49;
	cvt.u64.u32 	%rd146, %r51;

$L__BB15_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd146;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd145;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB15_14;

$L__BB15_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB15_20;

	div.u64 	%rd147, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd147, %rd30;
	sub.s64 	%rd148, %rd28, %rd107;
	bra.uni 	$L__BB15_21;

$L__BB15_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd147, %r58;
	cvt.u64.u32 	%rd148, %r60;

$L__BB15_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd148;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd147;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB15_18;

$L__BB15_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB15_24;

	div.u64 	%rd149, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd149, %rd39;
	sub.s64 	%rd150, %rd37, %rd118;
	bra.uni 	$L__BB15_25;

$L__BB15_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd149, %r67;
	cvt.u64.u32 	%rd150, %r69;

$L__BB15_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd150;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd149;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB15_22;

	cvt.u64.u32 	%rd124, %r78;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u8 	%rs1, [%rd125];
	setp.eq.s16 	%p22, %rs1, 0;
	cvt.u64.u32 	%rd126, %r81;
	add.s64 	%rd128, %rd3, %rd126;
	cvt.u64.u32 	%rd129, %r84;
	add.s64 	%rd131, %rd2, %rd129;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u8 	%rs2, [%rd132];
	add.s64 	%rd134, %rd1, %rd144;
	st.global.u8 	[%rd134], %rs2;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p23, %rd144, %rd51;
	@%p23 bra 	$L__BB15_13;
	bra.uni 	$L__BB15_31;

$L__BB15_27:
	ld.global.u8 	%rs3, [%rd4];
	setp.eq.s16 	%p24, %rs3, 0;
	selp.b64 	%rd135, %rd2, %rd3, %p24;
	ld.global.u8 	%rs4, [%rd135];
	add.s64 	%rd136, %rd1, %rd144;
	st.global.u8 	[%rd136], %rs4;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd144, %r75;
	setp.lt.u64 	%p25, %rd144, %rd51;
	@%p25 bra 	$L__BB15_27;

$L__BB15_31:
	ret;

}
	// .globl	where_u8_u32
.visible .entry where_u8_u32(
	.param .u64 where_u8_u32_param_0,
	.param .u64 where_u8_u32_param_1,
	.param .u64 where_u8_u32_param_2,
	.param .u64 where_u8_u32_param_3,
	.param .u64 where_u8_u32_param_4,
	.param .u64 where_u8_u32_param_5,
	.param .u64 where_u8_u32_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<90>;
	.reg .b64 	%rd<156>;


	ld.param.u64 	%rd51, [where_u8_u32_param_0];
	ld.param.u64 	%rd52, [where_u8_u32_param_1];
	ld.param.u64 	%rd56, [where_u8_u32_param_2];
	ld.param.u64 	%rd57, [where_u8_u32_param_3];
	ld.param.u64 	%rd53, [where_u8_u32_param_4];
	ld.param.u64 	%rd54, [where_u8_u32_param_5];
	ld.param.u64 	%rd55, [where_u8_u32_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB16_10;

	mov.u64 	%rd144, 1;
	mov.u32 	%r75, 0;

$L__BB16_2:
	not.b32 	%r36, %r75;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd144, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB16_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd144, %rd67, %rd144;
	add.s32 	%r75, %r75, 1;
	cvt.u64.u32 	%rd68, %r75;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB16_2;

	mov.u64 	%rd145, 1;
	mov.u32 	%r76, 0;

$L__BB16_5:
	not.b32 	%r38, %r76;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd145, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB16_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd145, %rd78, %rd145;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd79, %r76;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB16_5;

	mov.u64 	%rd146, 1;
	mov.u32 	%r77, 0;

$L__BB16_8:
	not.b32 	%r40, %r77;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd146, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB16_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd146, %rd89, %rd146;
	add.s32 	%r77, %r77, 1;
	cvt.u64.u32 	%rd90, %r77;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB16_8;

$L__BB16_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r78, %r41, %r7, %r42;
	cvt.u64.u32 	%rd147, %r78;
	@%p29 bra 	$L__BB16_28;
	bra.uni 	$L__BB16_11;

$L__BB16_28:
	setp.ge.u64 	%p26, %rd147, %rd51;
	@%p26 bra 	$L__BB16_31;

	mov.u32 	%r73, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r73;

$L__BB16_30:
	add.s64 	%rd139, %rd4, %rd147;
	ld.global.u8 	%rs3, [%rd139];
	setp.eq.s16 	%p27, %rs3, 0;
	selp.b64 	%rd140, %rd2, %rd3, %p27;
	shl.b64 	%rd141, %rd147, 2;
	add.s64 	%rd142, %rd140, %rd141;
	ld.global.u32 	%r74, [%rd142];
	add.s64 	%rd143, %rd1, %rd141;
	st.global.u32 	[%rd143], %r74;
	add.s32 	%r78, %r78, %r32;
	cvt.u64.u32 	%rd147, %r78;
	setp.lt.u64 	%p28, %rd147, %rd51;
	@%p28 bra 	$L__BB16_30;
	bra.uni 	$L__BB16_31;

$L__BB16_11:
	setp.ge.u64 	%p14, %rd147, %rd51;
	@%p14 bra 	$L__BB16_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB16_27;

$L__BB16_13:
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r78;
	mov.u32 	%r81, %r79;

$L__BB16_14:
	not.b32 	%r46, %r79;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r80;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB16_16;

	div.u64 	%rd148, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd148, %rd21;
	sub.s64 	%rd149, %rd19, %rd96;
	bra.uni 	$L__BB16_17;

$L__BB16_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd148, %r49;
	cvt.u64.u32 	%rd149, %r51;

$L__BB16_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd149;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r81, %r81, %r54;
	cvt.u32.u64 	%r80, %rd148;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd101, %r79;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r78;
	mov.u32 	%r84, %r82;
	@%p17 bra 	$L__BB16_14;

$L__BB16_18:
	not.b32 	%r55, %r82;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r83;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB16_20;

	div.u64 	%rd150, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd150, %rd30;
	sub.s64 	%rd151, %rd28, %rd107;
	bra.uni 	$L__BB16_21;

$L__BB16_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd150, %r58;
	cvt.u64.u32 	%rd151, %r60;

$L__BB16_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd151;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r84, %r84, %r63;
	cvt.u32.u64 	%r83, %rd150;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd112, %r82;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r85, 0;
	mov.u32 	%r86, %r78;
	mov.u32 	%r87, %r85;
	@%p19 bra 	$L__BB16_18;

$L__BB16_22:
	not.b32 	%r64, %r85;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r86;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB16_24;

	div.u64 	%rd152, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd152, %rd39;
	sub.s64 	%rd153, %rd37, %rd118;
	bra.uni 	$L__BB16_25;

$L__BB16_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd152, %r67;
	cvt.u64.u32 	%rd153, %r69;

$L__BB16_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd153;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r87, %r87, %r70;
	cvt.u32.u64 	%r86, %rd152;
	add.s32 	%r85, %r85, 1;
	cvt.u64.u32 	%rd123, %r85;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB16_22;

	cvt.u64.u32 	%rd124, %r81;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u8 	%rs1, [%rd125];
	setp.eq.s16 	%p22, %rs1, 0;
	mul.wide.u32 	%rd127, %r84, 4;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r87, 4;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u32 	%r71, [%rd132];
	shl.b64 	%rd134, %rd147, 2;
	add.s64 	%rd135, %rd1, %rd134;
	st.global.u32 	[%rd135], %r71;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd147, %r78;
	setp.lt.u64 	%p23, %rd147, %rd51;
	@%p23 bra 	$L__BB16_13;
	bra.uni 	$L__BB16_31;

$L__BB16_27:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p24, %rs2, 0;
	selp.b64 	%rd136, %rd2, %rd3, %p24;
	ld.global.u32 	%r72, [%rd136];
	shl.b64 	%rd137, %rd147, 2;
	add.s64 	%rd138, %rd1, %rd137;
	st.global.u32 	[%rd138], %r72;
	add.s32 	%r78, %r78, %r9;
	cvt.u64.u32 	%rd147, %r78;
	setp.lt.u64 	%p25, %rd147, %rd51;
	@%p25 bra 	$L__BB16_27;

$L__BB16_31:
	ret;

}
	// .globl	where_u8_i64
.visible .entry where_u8_i64(
	.param .u64 where_u8_i64_param_0,
	.param .u64 where_u8_i64_param_1,
	.param .u64 where_u8_i64_param_2,
	.param .u64 where_u8_i64_param_3,
	.param .u64 where_u8_i64_param_4,
	.param .u64 where_u8_i64_param_5,
	.param .u64 where_u8_i64_param_6
)
{
	.reg .pred 	%p<30>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<87>;
	.reg .b64 	%rd<159>;


	ld.param.u64 	%rd51, [where_u8_i64_param_0];
	ld.param.u64 	%rd52, [where_u8_i64_param_1];
	ld.param.u64 	%rd56, [where_u8_i64_param_2];
	ld.param.u64 	%rd57, [where_u8_i64_param_3];
	ld.param.u64 	%rd53, [where_u8_i64_param_4];
	ld.param.u64 	%rd54, [where_u8_i64_param_5];
	ld.param.u64 	%rd55, [where_u8_i64_param_6];
	cvta.to.global.u64 	%rd1, %rd55;
	cvta.to.global.u64 	%rd2, %rd54;
	cvta.to.global.u64 	%rd3, %rd53;
	cvta.to.global.u64 	%rd4, %rd57;
	cvta.to.global.u64 	%rd5, %rd56;
	shl.b64 	%rd6, %rd52, 1;
	mul.lo.s64 	%rd7, %rd52, 3;
	setp.eq.s64 	%p3, %rd52, 0;
	mov.pred 	%p2, -1;
	mov.pred 	%p29, %p2;
	@%p3 bra 	$L__BB17_10;

	mov.u64 	%rd147, 1;
	mov.u32 	%r72, 0;

$L__BB17_2:
	not.b32 	%r36, %r72;
	cvt.u64.u32 	%rd59, %r36;
	add.s64 	%rd60, %rd59, %rd52;
	and.b64  	%rd9, %rd60, 4294967295;
	add.s64 	%rd61, %rd9, %rd52;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd5, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p5, %rd147, %rd64;
	mov.pred 	%p4, 0;
	mov.pred 	%p29, %p4;
	@%p5 bra 	$L__BB17_10;

	shl.b64 	%rd65, %rd9, 3;
	add.s64 	%rd66, %rd5, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd147, %rd67, %rd147;
	add.s32 	%r72, %r72, 1;
	cvt.u64.u32 	%rd68, %r72;
	setp.lt.u64 	%p6, %rd68, %rd52;
	@%p6 bra 	$L__BB17_2;

	mov.u64 	%rd148, 1;
	mov.u32 	%r73, 0;

$L__BB17_5:
	not.b32 	%r38, %r73;
	cvt.u64.u32 	%rd70, %r38;
	add.s64 	%rd71, %rd70, %rd52;
	and.b64  	%rd12, %rd71, 4294967295;
	add.s64 	%rd72, %rd12, %rd7;
	shl.b64 	%rd73, %rd72, 3;
	add.s64 	%rd74, %rd5, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	setp.ne.s64 	%p8, %rd148, %rd75;
	mov.pred 	%p29, %p4;
	@%p8 bra 	$L__BB17_10;

	shl.b64 	%rd76, %rd12, 3;
	add.s64 	%rd77, %rd5, %rd76;
	ld.global.u64 	%rd78, [%rd77];
	mul.lo.s64 	%rd148, %rd78, %rd148;
	add.s32 	%r73, %r73, 1;
	cvt.u64.u32 	%rd79, %r73;
	setp.lt.u64 	%p9, %rd79, %rd52;
	@%p9 bra 	$L__BB17_5;

	mov.u64 	%rd149, 1;
	mov.u32 	%r74, 0;

$L__BB17_8:
	not.b32 	%r40, %r74;
	cvt.u64.u32 	%rd81, %r40;
	add.s64 	%rd82, %rd81, %rd52;
	and.b64  	%rd15, %rd82, 4294967295;
	add.s64 	%rd83, %rd15, %rd6;
	shl.b64 	%rd84, %rd83, 3;
	add.s64 	%rd85, %rd5, %rd84;
	ld.global.u64 	%rd86, [%rd85];
	setp.ne.s64 	%p11, %rd149, %rd86;
	mov.pred 	%p29, %p4;
	@%p11 bra 	$L__BB17_10;

	shl.b64 	%rd87, %rd15, 3;
	add.s64 	%rd88, %rd5, %rd87;
	ld.global.u64 	%rd89, [%rd88];
	mul.lo.s64 	%rd149, %rd89, %rd149;
	add.s32 	%r74, %r74, 1;
	cvt.u64.u32 	%rd90, %r74;
	setp.lt.u64 	%p13, %rd90, %rd52;
	mov.pred 	%p29, %p2;
	@%p13 bra 	$L__BB17_8;

$L__BB17_10:
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r41, %ctaid.x;
	mov.u32 	%r42, %tid.x;
	mad.lo.s32 	%r75, %r41, %r7, %r42;
	cvt.u64.u32 	%rd150, %r75;
	@%p29 bra 	$L__BB17_28;
	bra.uni 	$L__BB17_11;

$L__BB17_28:
	setp.ge.u64 	%p26, %rd150, %rd51;
	@%p26 bra 	$L__BB17_31;

	mov.u32 	%r71, %nctaid.x;
	mul.lo.s32 	%r32, %r7, %r71;

$L__BB17_30:
	add.s64 	%rd141, %rd4, %rd150;
	ld.global.u8 	%rs3, [%rd141];
	setp.eq.s16 	%p27, %rs3, 0;
	selp.b64 	%rd142, %rd2, %rd3, %p27;
	shl.b64 	%rd143, %rd150, 3;
	add.s64 	%rd144, %rd142, %rd143;
	ld.global.u64 	%rd145, [%rd144];
	add.s64 	%rd146, %rd1, %rd143;
	st.global.u64 	[%rd146], %rd145;
	add.s32 	%r75, %r75, %r32;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p28, %rd150, %rd51;
	@%p28 bra 	$L__BB17_30;
	bra.uni 	$L__BB17_31;

$L__BB17_11:
	setp.ge.u64 	%p14, %rd150, %rd51;
	@%p14 bra 	$L__BB17_31;

	mov.u32 	%r43, %nctaid.x;
	mul.lo.s32 	%r9, %r7, %r43;
	@%p3 bra 	$L__BB17_27;

$L__BB17_13:
	mov.u32 	%r76, 0;
	mov.u32 	%r77, %r75;
	mov.u32 	%r78, %r76;

$L__BB17_14:
	not.b32 	%r46, %r76;
	cvt.u64.u32 	%rd91, %r46;
	add.s64 	%rd92, %rd91, %rd52;
	cvt.u64.u32 	%rd19, %r77;
	shl.b64 	%rd93, %rd92, 3;
	and.b64  	%rd94, %rd93, 34359738360;
	add.s64 	%rd20, %rd5, %rd94;
	ld.global.u64 	%rd21, [%rd20];
	and.b64  	%rd95, %rd21, -4294967296;
	setp.eq.s64 	%p16, %rd95, 0;
	@%p16 bra 	$L__BB17_16;

	div.u64 	%rd151, %rd19, %rd21;
	mul.lo.s64 	%rd96, %rd151, %rd21;
	sub.s64 	%rd152, %rd19, %rd96;
	bra.uni 	$L__BB17_17;

$L__BB17_16:
	cvt.u32.u64 	%r47, %rd21;
	cvt.u32.u64 	%r48, %rd19;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd151, %r49;
	cvt.u64.u32 	%rd152, %r51;

$L__BB17_17:
	shl.b64 	%rd97, %rd52, 3;
	add.s64 	%rd98, %rd20, %rd97;
	ld.global.u64 	%rd99, [%rd98];
	mul.lo.s64 	%rd100, %rd99, %rd152;
	cvt.u32.u64 	%r54, %rd100;
	add.s32 	%r78, %r78, %r54;
	cvt.u32.u64 	%r77, %rd151;
	add.s32 	%r76, %r76, 1;
	cvt.u64.u32 	%rd101, %r76;
	setp.lt.u64 	%p17, %rd101, %rd52;
	mov.u32 	%r79, 0;
	mov.u32 	%r80, %r75;
	mov.u32 	%r81, %r79;
	@%p17 bra 	$L__BB17_14;

$L__BB17_18:
	not.b32 	%r55, %r79;
	cvt.u64.u32 	%rd102, %r55;
	add.s64 	%rd103, %rd102, %rd52;
	cvt.u64.u32 	%rd28, %r80;
	shl.b64 	%rd104, %rd103, 3;
	and.b64  	%rd105, %rd104, 34359738360;
	add.s64 	%rd29, %rd5, %rd105;
	ld.global.u64 	%rd30, [%rd29];
	and.b64  	%rd106, %rd30, -4294967296;
	setp.eq.s64 	%p18, %rd106, 0;
	@%p18 bra 	$L__BB17_20;

	div.u64 	%rd153, %rd28, %rd30;
	mul.lo.s64 	%rd107, %rd153, %rd30;
	sub.s64 	%rd154, %rd28, %rd107;
	bra.uni 	$L__BB17_21;

$L__BB17_20:
	cvt.u32.u64 	%r56, %rd30;
	cvt.u32.u64 	%r57, %rd28;
	div.u32 	%r58, %r57, %r56;
	mul.lo.s32 	%r59, %r58, %r56;
	sub.s32 	%r60, %r57, %r59;
	cvt.u64.u32 	%rd153, %r58;
	cvt.u64.u32 	%rd154, %r60;

$L__BB17_21:
	shl.b64 	%rd108, %rd6, 3;
	add.s64 	%rd109, %rd29, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	mul.lo.s64 	%rd111, %rd110, %rd154;
	cvt.u32.u64 	%r63, %rd111;
	add.s32 	%r81, %r81, %r63;
	cvt.u32.u64 	%r80, %rd153;
	add.s32 	%r79, %r79, 1;
	cvt.u64.u32 	%rd112, %r79;
	setp.lt.u64 	%p19, %rd112, %rd52;
	mov.u32 	%r82, 0;
	mov.u32 	%r83, %r75;
	mov.u32 	%r84, %r82;
	@%p19 bra 	$L__BB17_18;

$L__BB17_22:
	not.b32 	%r64, %r82;
	cvt.u64.u32 	%rd113, %r64;
	add.s64 	%rd114, %rd113, %rd52;
	cvt.u64.u32 	%rd37, %r83;
	shl.b64 	%rd115, %rd114, 3;
	and.b64  	%rd116, %rd115, 34359738360;
	add.s64 	%rd38, %rd5, %rd116;
	ld.global.u64 	%rd39, [%rd38];
	and.b64  	%rd117, %rd39, -4294967296;
	setp.eq.s64 	%p20, %rd117, 0;
	@%p20 bra 	$L__BB17_24;

	div.u64 	%rd155, %rd37, %rd39;
	mul.lo.s64 	%rd118, %rd155, %rd39;
	sub.s64 	%rd156, %rd37, %rd118;
	bra.uni 	$L__BB17_25;

$L__BB17_24:
	cvt.u32.u64 	%r65, %rd39;
	cvt.u32.u64 	%r66, %rd37;
	div.u32 	%r67, %r66, %r65;
	mul.lo.s32 	%r68, %r67, %r65;
	sub.s32 	%r69, %r66, %r68;
	cvt.u64.u32 	%rd155, %r67;
	cvt.u64.u32 	%rd156, %r69;

$L__BB17_25:
	shl.b64 	%rd119, %rd7, 3;
	add.s64 	%rd120, %rd38, %rd119;
	ld.global.u64 	%rd121, [%rd120];
	mul.lo.s64 	%rd122, %rd121, %rd156;
	cvt.u32.u64 	%r70, %rd122;
	add.s32 	%r84, %r84, %r70;
	cvt.u32.u64 	%r83, %rd155;
	add.s32 	%r82, %r82, 1;
	cvt.u64.u32 	%rd123, %r82;
	setp.lt.u64 	%p21, %rd123, %rd52;
	@%p21 bra 	$L__BB17_22;

	cvt.u64.u32 	%rd124, %r78;
	add.s64 	%rd125, %rd4, %rd124;
	ld.global.u8 	%rs1, [%rd125];
	setp.eq.s16 	%p22, %rs1, 0;
	mul.wide.u32 	%rd127, %r81, 8;
	add.s64 	%rd128, %rd3, %rd127;
	mul.wide.u32 	%rd130, %r84, 8;
	add.s64 	%rd131, %rd2, %rd130;
	selp.b64 	%rd132, %rd131, %rd128, %p22;
	ld.global.u64 	%rd133, [%rd132];
	shl.b64 	%rd135, %rd150, 3;
	add.s64 	%rd136, %rd1, %rd135;
	st.global.u64 	[%rd136], %rd133;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p23, %rd150, %rd51;
	@%p23 bra 	$L__BB17_13;
	bra.uni 	$L__BB17_31;

$L__BB17_27:
	ld.global.u8 	%rs2, [%rd4];
	setp.eq.s16 	%p24, %rs2, 0;
	selp.b64 	%rd137, %rd2, %rd3, %p24;
	ld.global.u64 	%rd138, [%rd137];
	shl.b64 	%rd139, %rd150, 3;
	add.s64 	%rd140, %rd1, %rd139;
	st.global.u64 	[%rd140], %rd138;
	add.s32 	%r75, %r75, %r9;
	cvt.u64.u32 	%rd150, %r75;
	setp.lt.u64 	%p25, %rd150, %rd51;
	@%p25 bra 	$L__BB17_27;

$L__BB17_31:
	ret;

}

