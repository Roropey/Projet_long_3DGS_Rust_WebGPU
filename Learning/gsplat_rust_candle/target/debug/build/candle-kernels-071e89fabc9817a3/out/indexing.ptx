//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33567101
// Cuda compilation tools, release 12.3, V12.3.107
// Based on NVVM 7.0.1
//

.version 8.3
.target sm_75
.address_size 64

	// .globl	is_i64_f16

.visible .entry is_i64_f16(
	.param .u64 is_i64_f16_param_0,
	.param .u64 is_i64_f16_param_1,
	.param .u64 is_i64_f16_param_2,
	.param .u64 is_i64_f16_param_3,
	.param .u64 is_i64_f16_param_4,
	.param .u64 is_i64_f16_param_5,
	.param .u64 is_i64_f16_param_6,
	.param .u64 is_i64_f16_param_7,
	.param .u64 is_i64_f16_param_8,
	.param .u64 is_i64_f16_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_i64_f16_param_0];
	ld.param.u64 	%rd50, [is_i64_f16_param_1];
	ld.param.u64 	%rd54, [is_i64_f16_param_2];
	ld.param.u64 	%rd55, [is_i64_f16_param_3];
	ld.param.u64 	%rd56, [is_i64_f16_param_4];
	ld.param.u64 	%rd57, [is_i64_f16_param_5];
	ld.param.u64 	%rd51, [is_i64_f16_param_7];
	ld.param.u64 	%rd52, [is_i64_f16_param_8];
	ld.param.u64 	%rd53, [is_i64_f16_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB0_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r52, 0;

$L__BB0_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs7, 0;
	@%p2 bra 	$L__BB0_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs7, %rs2;
	@%p3 bra 	$L__BB0_2;

$L__BB0_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r53;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB0_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs7, 0;
	@%p5 bra 	$L__BB0_16;

$L__BB0_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB0_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB0_9;

$L__BB0_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB0_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB0_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB0_12;

$L__BB0_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB0_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB0_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB0_15;

$L__BB0_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB0_15:
	shl.b64 	%rd74, %rd117, 3;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd76, %rd77;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 1;
	and.b64  	%rd82, %rd81, 8589934590;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.u16 	%rs5, [%rd83];
	shl.b64 	%rd84, %rd113, 1;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.u16 	[%rd85], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_32;

$L__BB0_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB0_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB0_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB0_20;

$L__BB0_19:
	cvt.u32.u64 	%r32, %rd113;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd119, %r33;

$L__BB0_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB0_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB0_23;

$L__BB0_22:
	cvt.u32.u64 	%r35, %rd113;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd120, %r36;
	cvt.u64.u32 	%rd121, %r38;

$L__BB0_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB0_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB0_26;

$L__BB0_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd120;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd122, %r41;

$L__BB0_26:
	shl.b64 	%rd91, %rd122, 3;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u64 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd93, %rd94;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB0_31;

$L__BB0_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB0_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB0_30;

$L__BB0_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd123, %r48;
	cvt.u64.u32 	%rd125, %r50;

$L__BB0_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB0_27;

$L__BB0_31:
	mul.wide.u32 	%rd108, %r56, 2;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.u16 	%rs6, [%rd109];
	shl.b64 	%rd110, %rd113, 1;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.u16 	[%rd111], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB0_17;

$L__BB0_32:
	ret;

}
	// .globl	is_u32_f16
.visible .entry is_u32_f16(
	.param .u64 is_u32_f16_param_0,
	.param .u64 is_u32_f16_param_1,
	.param .u64 is_u32_f16_param_2,
	.param .u64 is_u32_f16_param_3,
	.param .u64 is_u32_f16_param_4,
	.param .u64 is_u32_f16_param_5,
	.param .u64 is_u32_f16_param_6,
	.param .u64 is_u32_f16_param_7,
	.param .u64 is_u32_f16_param_8,
	.param .u64 is_u32_f16_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_u32_f16_param_0];
	ld.param.u64 	%rd50, [is_u32_f16_param_1];
	ld.param.u64 	%rd54, [is_u32_f16_param_2];
	ld.param.u64 	%rd55, [is_u32_f16_param_3];
	ld.param.u64 	%rd56, [is_u32_f16_param_4];
	ld.param.u64 	%rd57, [is_u32_f16_param_5];
	ld.param.u64 	%rd51, [is_u32_f16_param_7];
	ld.param.u64 	%rd52, [is_u32_f16_param_8];
	ld.param.u64 	%rd53, [is_u32_f16_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB1_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r52, 0;

$L__BB1_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs7, 0;
	@%p2 bra 	$L__BB1_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs7, %rs2;
	@%p3 bra 	$L__BB1_2;

$L__BB1_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r53;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB1_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs7, 0;
	@%p5 bra 	$L__BB1_16;

$L__BB1_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB1_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB1_9;

$L__BB1_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB1_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB1_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB1_12;

$L__BB1_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB1_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB1_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB1_15;

$L__BB1_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB1_15:
	shl.b64 	%rd74, %rd117, 2;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u32 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd77, %rd76;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 1;
	and.b64  	%rd82, %rd81, 8589934590;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.u16 	%rs5, [%rd83];
	shl.b64 	%rd84, %rd113, 1;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.u16 	[%rd85], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB1_6;
	bra.uni 	$L__BB1_32;

$L__BB1_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB1_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB1_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB1_20;

$L__BB1_19:
	cvt.u32.u64 	%r32, %rd113;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd119, %r33;

$L__BB1_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB1_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB1_23;

$L__BB1_22:
	cvt.u32.u64 	%r35, %rd113;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd120, %r36;
	cvt.u64.u32 	%rd121, %r38;

$L__BB1_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB1_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB1_26;

$L__BB1_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd120;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd122, %r41;

$L__BB1_26:
	shl.b64 	%rd91, %rd122, 2;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u32 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd94, %rd93;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB1_31;

$L__BB1_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB1_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB1_30;

$L__BB1_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd123, %r48;
	cvt.u64.u32 	%rd125, %r50;

$L__BB1_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB1_27;

$L__BB1_31:
	mul.wide.u32 	%rd108, %r56, 2;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.u16 	%rs6, [%rd109];
	shl.b64 	%rd110, %rd113, 1;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.u16 	[%rd111], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB1_17;

$L__BB1_32:
	ret;

}
	// .globl	is_u8_f16
.visible .entry is_u8_f16(
	.param .u64 is_u8_f16_param_0,
	.param .u64 is_u8_f16_param_1,
	.param .u64 is_u8_f16_param_2,
	.param .u64 is_u8_f16_param_3,
	.param .u64 is_u8_f16_param_4,
	.param .u64 is_u8_f16_param_5,
	.param .u64 is_u8_f16_param_6,
	.param .u64 is_u8_f16_param_7,
	.param .u64 is_u8_f16_param_8,
	.param .u64 is_u8_f16_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<124>;


	ld.param.u64 	%rd49, [is_u8_f16_param_0];
	ld.param.u64 	%rd50, [is_u8_f16_param_1];
	ld.param.u64 	%rd54, [is_u8_f16_param_2];
	ld.param.u64 	%rd55, [is_u8_f16_param_3];
	ld.param.u64 	%rd56, [is_u8_f16_param_4];
	ld.param.u64 	%rd57, [is_u8_f16_param_5];
	ld.param.u64 	%rd51, [is_u8_f16_param_7];
	ld.param.u64 	%rd52, [is_u8_f16_param_8];
	ld.param.u64 	%rd53, [is_u8_f16_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB2_4;

	mov.u64 	%rd110, 1;
	mov.u32 	%r52, 0;

$L__BB2_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd110, %rd64;
	mov.u16 	%rs7, 0;
	@%p2 bra 	$L__BB2_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd110, %rd67, %rd110;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs7, %rs2;
	@%p3 bra 	$L__BB2_2;

$L__BB2_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd111, %r53;
	setp.ge.u64 	%p4, %rd111, %rd49;
	@%p4 bra 	$L__BB2_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs7, 0;
	@%p5 bra 	$L__BB2_16;

$L__BB2_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB2_8;

	div.u64 	%rd112, %rd111, %rd9;
	bra.uni 	$L__BB2_9;

$L__BB2_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd111;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd112, %r22;

$L__BB2_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB2_11;

	div.u64 	%rd113, %rd111, %rd53;
	mul.lo.s64 	%rd71, %rd113, %rd53;
	sub.s64 	%rd114, %rd111, %rd71;
	bra.uni 	$L__BB2_12;

$L__BB2_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd111;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd113, %r25;
	cvt.u64.u32 	%rd114, %r27;

$L__BB2_12:
	or.b64  	%rd72, %rd113, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB2_14;

	rem.u64 	%rd115, %rd113, %rd52;
	bra.uni 	$L__BB2_15;

$L__BB2_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd113;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd115, %r30;

$L__BB2_15:
	add.s64 	%rd74, %rd3, %rd115;
	ld.global.u8 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd112, %rd51;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd53;
	add.s64 	%rd79, %rd78, %rd114;
	shl.b64 	%rd80, %rd79, 1;
	and.b64  	%rd81, %rd80, 8589934590;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u16 	%rs5, [%rd82];
	shl.b64 	%rd83, %rd111, 1;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.u16 	[%rd84], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd111, %r53;
	setp.lt.u64 	%p9, %rd111, %rd49;
	@%p9 bra 	$L__BB2_6;
	bra.uni 	$L__BB2_32;

$L__BB2_16:
	and.b64  	%rd85, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB2_17:
	setp.eq.s64 	%p10, %rd85, 0;
	@%p10 bra 	$L__BB2_19;

	div.u64 	%rd117, %rd111, %rd9;
	bra.uni 	$L__BB2_20;

$L__BB2_19:
	cvt.u32.u64 	%r32, %rd111;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd117, %r33;

$L__BB2_20:
	and.b64  	%rd86, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd86, 0;
	@%p11 bra 	$L__BB2_22;

	div.u64 	%rd118, %rd111, %rd53;
	mul.lo.s64 	%rd87, %rd118, %rd53;
	sub.s64 	%rd119, %rd111, %rd87;
	bra.uni 	$L__BB2_23;

$L__BB2_22:
	cvt.u32.u64 	%r35, %rd111;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd118, %r36;
	cvt.u64.u32 	%rd119, %r38;

$L__BB2_23:
	or.b64  	%rd88, %rd118, %rd52;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p12, %rd89, 0;
	@%p12 bra 	$L__BB2_25;

	rem.u64 	%rd120, %rd118, %rd52;
	bra.uni 	$L__BB2_26;

$L__BB2_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd118;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd120, %r41;

$L__BB2_26:
	add.s64 	%rd90, %rd3, %rd120;
	ld.global.u8 	%rd91, [%rd90];
	mul.lo.s64 	%rd92, %rd117, %rd51;
	add.s64 	%rd93, %rd92, %rd91;
	mul.lo.s64 	%rd94, %rd93, %rd53;
	add.s64 	%rd121, %rd94, %rd119;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB2_31;

$L__BB2_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd95, %r45;
	add.s64 	%rd96, %rd95, %rd50;
	and.b64  	%rd39, %rd121, 4294967295;
	shl.b64 	%rd97, %rd96, 3;
	and.b64  	%rd98, %rd97, 34359738360;
	add.s64 	%rd40, %rd4, %rd98;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd99, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB2_29;

	div.u64 	%rd121, %rd39, %rd41;
	mul.lo.s64 	%rd100, %rd121, %rd41;
	sub.s64 	%rd123, %rd39, %rd100;
	bra.uni 	$L__BB2_30;

$L__BB2_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd121, %r48;
	cvt.u64.u32 	%rd123, %r50;

$L__BB2_30:
	shl.b64 	%rd101, %rd50, 3;
	add.s64 	%rd102, %rd40, %rd101;
	ld.global.u64 	%rd103, [%rd102];
	mul.lo.s64 	%rd104, %rd103, %rd123;
	cvt.u32.u64 	%r51, %rd104;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd105, %r55;
	setp.lt.u64 	%p15, %rd105, %rd50;
	@%p15 bra 	$L__BB2_27;

$L__BB2_31:
	mul.wide.u32 	%rd106, %r56, 2;
	add.s64 	%rd107, %rd2, %rd106;
	ld.global.u16 	%rs6, [%rd107];
	shl.b64 	%rd108, %rd111, 1;
	add.s64 	%rd109, %rd1, %rd108;
	st.global.u16 	[%rd109], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd111, %r53;
	setp.lt.u64 	%p16, %rd111, %rd49;
	@%p16 bra 	$L__BB2_17;

$L__BB2_32:
	ret;

}
	// .globl	gather_i64_f16
.visible .entry gather_i64_f16(
	.param .u64 gather_i64_f16_param_0,
	.param .u64 gather_i64_f16_param_1,
	.param .u64 gather_i64_f16_param_2,
	.param .u64 gather_i64_f16_param_3,
	.param .u64 gather_i64_f16_param_4,
	.param .u64 gather_i64_f16_param_5,
	.param .u64 gather_i64_f16_param_6,
	.param .u64 gather_i64_f16_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_f16_param_0];
	ld.param.u64 	%rd16, [gather_i64_f16_param_1];
	ld.param.u64 	%rd17, [gather_i64_f16_param_2];
	ld.param.u64 	%rd18, [gather_i64_f16_param_3];
	ld.param.u64 	%rd19, [gather_i64_f16_param_5];
	ld.param.u64 	%rd20, [gather_i64_f16_param_6];
	ld.param.u64 	%rd21, [gather_i64_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB3_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB3_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB3_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB3_5;

$L__BB3_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB3_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB3_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB3_8;

$L__BB3_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB3_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 1;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u16 	%rs1, [%rd31];
	shl.b64 	%rd32, %rd34, 1;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u16 	[%rd33], %rs1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB3_2;

$L__BB3_9:
	ret;

}
	// .globl	gather_u32_f16
.visible .entry gather_u32_f16(
	.param .u64 gather_u32_f16_param_0,
	.param .u64 gather_u32_f16_param_1,
	.param .u64 gather_u32_f16_param_2,
	.param .u64 gather_u32_f16_param_3,
	.param .u64 gather_u32_f16_param_4,
	.param .u64 gather_u32_f16_param_5,
	.param .u64 gather_u32_f16_param_6,
	.param .u64 gather_u32_f16_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_f16_param_0];
	ld.param.u64 	%rd15, [gather_u32_f16_param_1];
	ld.param.u64 	%rd16, [gather_u32_f16_param_2];
	ld.param.u64 	%rd17, [gather_u32_f16_param_3];
	ld.param.u64 	%rd18, [gather_u32_f16_param_5];
	ld.param.u64 	%rd19, [gather_u32_f16_param_6];
	ld.param.u64 	%rd20, [gather_u32_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB4_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB4_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB4_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB4_5;

$L__BB4_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB4_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB4_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB4_8;

$L__BB4_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB4_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 1;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u16 	%rs1, [%rd31];
	shl.b64 	%rd32, %rd34, 1;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u16 	[%rd33], %rs1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB4_2;

$L__BB4_9:
	ret;

}
	// .globl	gather_u8_f16
.visible .entry gather_u8_f16(
	.param .u64 gather_u8_f16_param_0,
	.param .u64 gather_u8_f16_param_1,
	.param .u64 gather_u8_f16_param_2,
	.param .u64 gather_u8_f16_param_3,
	.param .u64 gather_u8_f16_param_4,
	.param .u64 gather_u8_f16_param_5,
	.param .u64 gather_u8_f16_param_6,
	.param .u64 gather_u8_f16_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_f16_param_0];
	ld.param.u64 	%rd15, [gather_u8_f16_param_1];
	ld.param.u64 	%rd16, [gather_u8_f16_param_2];
	ld.param.u64 	%rd17, [gather_u8_f16_param_3];
	ld.param.u64 	%rd18, [gather_u8_f16_param_5];
	ld.param.u64 	%rd19, [gather_u8_f16_param_6];
	ld.param.u64 	%rd20, [gather_u8_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB5_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB5_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB5_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB5_5;

$L__BB5_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB5_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB5_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB5_8;

$L__BB5_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB5_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 1;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u16 	%rs2, [%rd31];
	shl.b64 	%rd32, %rd34, 1;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u16 	[%rd33], %rs2;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB5_2;

$L__BB5_9:
	ret;

}
	// .globl	ia_u32_f16
.visible .entry ia_u32_f16(
	.param .u64 ia_u32_f16_param_0,
	.param .u64 ia_u32_f16_param_1,
	.param .u64 ia_u32_f16_param_2,
	.param .u64 ia_u32_f16_param_3,
	.param .u64 ia_u32_f16_param_4,
	.param .u64 ia_u32_f16_param_5,
	.param .u64 ia_u32_f16_param_6,
	.param .u64 ia_u32_f16_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_f16_param_0];
	ld.param.u64 	%rd19, [ia_u32_f16_param_1];
	ld.param.u64 	%rd20, [ia_u32_f16_param_2];
	ld.param.u64 	%rd21, [ia_u32_f16_param_3];
	ld.param.u64 	%rd24, [ia_u32_f16_param_4];
	ld.param.u64 	%rd22, [ia_u32_f16_param_6];
	ld.param.u64 	%rd23, [ia_u32_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB6_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB6_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB6_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB6_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB6_6;

$L__BB6_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB6_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB6_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd36, 1;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.u16 	%rs2, [%rd38];
	shl.b64 	%rd39, %rd33, 1;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u16 	%rs3, [%rd40];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd38], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB6_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB6_3;
	bra.uni 	$L__BB6_10;

$L__BB6_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB6_9;

$L__BB6_10:
	ret;

}
	// .globl	ia_u8_f16
.visible .entry ia_u8_f16(
	.param .u64 ia_u8_f16_param_0,
	.param .u64 ia_u8_f16_param_1,
	.param .u64 ia_u8_f16_param_2,
	.param .u64 ia_u8_f16_param_3,
	.param .u64 ia_u8_f16_param_4,
	.param .u64 ia_u8_f16_param_5,
	.param .u64 ia_u8_f16_param_6,
	.param .u64 ia_u8_f16_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_f16_param_0];
	ld.param.u64 	%rd19, [ia_u8_f16_param_1];
	ld.param.u64 	%rd20, [ia_u8_f16_param_2];
	ld.param.u64 	%rd21, [ia_u8_f16_param_3];
	ld.param.u64 	%rd24, [ia_u8_f16_param_4];
	ld.param.u64 	%rd22, [ia_u8_f16_param_6];
	ld.param.u64 	%rd23, [ia_u8_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB7_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB7_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB7_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB7_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB7_6;

$L__BB7_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB7_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB7_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd35, 1;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.u16 	%rs2, [%rd37];
	shl.b64 	%rd38, %rd32, 1;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u16 	%rs3, [%rd39];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd37], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB7_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB7_3;
	bra.uni 	$L__BB7_10;

$L__BB7_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB7_9;

$L__BB7_10:
	ret;

}
	// .globl	sa_u32_f16
.visible .entry sa_u32_f16(
	.param .u64 sa_u32_f16_param_0,
	.param .u64 sa_u32_f16_param_1,
	.param .u64 sa_u32_f16_param_2,
	.param .u64 sa_u32_f16_param_3,
	.param .u64 sa_u32_f16_param_4,
	.param .u64 sa_u32_f16_param_5,
	.param .u64 sa_u32_f16_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_u32_f16_param_0];
	ld.param.u64 	%rd19, [sa_u32_f16_param_1];
	ld.param.u64 	%rd20, [sa_u32_f16_param_2];
	ld.param.u64 	%rd24, [sa_u32_f16_param_3];
	ld.param.u64 	%rd21, [sa_u32_f16_param_4];
	ld.param.u64 	%rd22, [sa_u32_f16_param_5];
	ld.param.u64 	%rd23, [sa_u32_f16_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB8_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB8_9;

	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB8_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB8_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB8_6;

$L__BB8_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB8_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB8_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd36, 1;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.u16 	%rs2, [%rd38];
	shl.b64 	%rd39, %rd30, 1;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u16 	%rs3, [%rd40];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd38], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB8_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB8_3;
	bra.uni 	$L__BB8_10;

$L__BB8_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB8_9;

$L__BB8_10:
	ret;

}
	// .globl	sa_u8_f16
.visible .entry sa_u8_f16(
	.param .u64 sa_u8_f16_param_0,
	.param .u64 sa_u8_f16_param_1,
	.param .u64 sa_u8_f16_param_2,
	.param .u64 sa_u8_f16_param_3,
	.param .u64 sa_u8_f16_param_4,
	.param .u64 sa_u8_f16_param_5,
	.param .u64 sa_u8_f16_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_f16_param_0];
	ld.param.u64 	%rd19, [sa_u8_f16_param_1];
	ld.param.u64 	%rd20, [sa_u8_f16_param_2];
	ld.param.u64 	%rd24, [sa_u8_f16_param_3];
	ld.param.u64 	%rd21, [sa_u8_f16_param_4];
	ld.param.u64 	%rd22, [sa_u8_f16_param_5];
	ld.param.u64 	%rd23, [sa_u8_f16_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB9_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB9_9;

	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB9_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB9_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB9_6;

$L__BB9_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB9_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB9_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd35, 1;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.u16 	%rs2, [%rd37];
	shl.b64 	%rd38, %rd30, 1;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u16 	%rs3, [%rd39];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd37], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB9_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB9_3;
	bra.uni 	$L__BB9_10;

$L__BB9_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB9_9;

$L__BB9_10:
	ret;

}
	// .globl	is_i64_f32
.visible .entry is_i64_f32(
	.param .u64 is_i64_f32_param_0,
	.param .u64 is_i64_f32_param_1,
	.param .u64 is_i64_f32_param_2,
	.param .u64 is_i64_f32_param_3,
	.param .u64 is_i64_f32_param_4,
	.param .u64 is_i64_f32_param_5,
	.param .u64 is_i64_f32_param_6,
	.param .u64 is_i64_f32_param_7,
	.param .u64 is_i64_f32_param_8,
	.param .u64 is_i64_f32_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_i64_f32_param_0];
	ld.param.u64 	%rd50, [is_i64_f32_param_1];
	ld.param.u64 	%rd54, [is_i64_f32_param_2];
	ld.param.u64 	%rd55, [is_i64_f32_param_3];
	ld.param.u64 	%rd56, [is_i64_f32_param_4];
	ld.param.u64 	%rd57, [is_i64_f32_param_5];
	ld.param.u64 	%rd51, [is_i64_f32_param_7];
	ld.param.u64 	%rd52, [is_i64_f32_param_8];
	ld.param.u64 	%rd53, [is_i64_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB10_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r52, 0;

$L__BB10_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB10_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB10_2;

$L__BB10_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r53;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB10_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB10_16;

$L__BB10_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB10_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB10_9;

$L__BB10_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB10_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB10_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB10_12;

$L__BB10_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB10_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB10_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB10_15;

$L__BB10_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB10_15:
	shl.b64 	%rd74, %rd117, 3;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd76, %rd77;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 2;
	and.b64  	%rd82, %rd81, 17179869180;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.f32 	%f1, [%rd83];
	shl.b64 	%rd84, %rd113, 2;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.f32 	[%rd85], %f1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB10_6;
	bra.uni 	$L__BB10_32;

$L__BB10_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB10_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB10_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB10_20;

$L__BB10_19:
	cvt.u32.u64 	%r32, %rd113;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd119, %r33;

$L__BB10_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB10_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB10_23;

$L__BB10_22:
	cvt.u32.u64 	%r35, %rd113;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd120, %r36;
	cvt.u64.u32 	%rd121, %r38;

$L__BB10_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB10_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB10_26;

$L__BB10_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd120;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd122, %r41;

$L__BB10_26:
	shl.b64 	%rd91, %rd122, 3;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u64 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd93, %rd94;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB10_31;

$L__BB10_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB10_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB10_30;

$L__BB10_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd123, %r48;
	cvt.u64.u32 	%rd125, %r50;

$L__BB10_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB10_27;

$L__BB10_31:
	mul.wide.u32 	%rd108, %r56, 4;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.f32 	%f2, [%rd109];
	shl.b64 	%rd110, %rd113, 2;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.f32 	[%rd111], %f2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB10_17;

$L__BB10_32:
	ret;

}
	// .globl	is_i64_f64
.visible .entry is_i64_f64(
	.param .u64 is_i64_f64_param_0,
	.param .u64 is_i64_f64_param_1,
	.param .u64 is_i64_f64_param_2,
	.param .u64 is_i64_f64_param_3,
	.param .u64 is_i64_f64_param_4,
	.param .u64 is_i64_f64_param_5,
	.param .u64 is_i64_f64_param_6,
	.param .u64 is_i64_f64_param_7,
	.param .u64 is_i64_f64_param_8,
	.param .u64 is_i64_f64_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_i64_f64_param_0];
	ld.param.u64 	%rd50, [is_i64_f64_param_1];
	ld.param.u64 	%rd54, [is_i64_f64_param_2];
	ld.param.u64 	%rd55, [is_i64_f64_param_3];
	ld.param.u64 	%rd56, [is_i64_f64_param_4];
	ld.param.u64 	%rd57, [is_i64_f64_param_5];
	ld.param.u64 	%rd51, [is_i64_f64_param_7];
	ld.param.u64 	%rd52, [is_i64_f64_param_8];
	ld.param.u64 	%rd53, [is_i64_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB11_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r52, 0;

$L__BB11_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB11_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB11_2;

$L__BB11_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r53;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB11_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB11_16;

$L__BB11_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB11_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB11_9;

$L__BB11_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB11_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB11_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB11_12;

$L__BB11_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB11_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB11_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB11_15;

$L__BB11_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB11_15:
	shl.b64 	%rd74, %rd117, 3;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd76, %rd77;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 3;
	and.b64  	%rd82, %rd81, 34359738360;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.f64 	%fd1, [%rd83];
	shl.b64 	%rd84, %rd113, 3;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.f64 	[%rd85], %fd1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB11_6;
	bra.uni 	$L__BB11_32;

$L__BB11_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB11_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB11_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB11_20;

$L__BB11_19:
	cvt.u32.u64 	%r32, %rd113;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd119, %r33;

$L__BB11_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB11_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB11_23;

$L__BB11_22:
	cvt.u32.u64 	%r35, %rd113;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd120, %r36;
	cvt.u64.u32 	%rd121, %r38;

$L__BB11_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB11_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB11_26;

$L__BB11_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd120;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd122, %r41;

$L__BB11_26:
	shl.b64 	%rd91, %rd122, 3;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u64 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd93, %rd94;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB11_31;

$L__BB11_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB11_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB11_30;

$L__BB11_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd123, %r48;
	cvt.u64.u32 	%rd125, %r50;

$L__BB11_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB11_27;

$L__BB11_31:
	mul.wide.u32 	%rd108, %r56, 8;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.f64 	%fd2, [%rd109];
	shl.b64 	%rd110, %rd113, 3;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.f64 	[%rd111], %fd2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB11_17;

$L__BB11_32:
	ret;

}
	// .globl	is_i64_u8
.visible .entry is_i64_u8(
	.param .u64 is_i64_u8_param_0,
	.param .u64 is_i64_u8_param_1,
	.param .u64 is_i64_u8_param_2,
	.param .u64 is_i64_u8_param_3,
	.param .u64 is_i64_u8_param_4,
	.param .u64 is_i64_u8_param_5,
	.param .u64 is_i64_u8_param_6,
	.param .u64 is_i64_u8_param_7,
	.param .u64 is_i64_u8_param_8,
	.param .u64 is_i64_u8_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<123>;


	ld.param.u64 	%rd49, [is_i64_u8_param_0];
	ld.param.u64 	%rd50, [is_i64_u8_param_1];
	ld.param.u64 	%rd54, [is_i64_u8_param_2];
	ld.param.u64 	%rd55, [is_i64_u8_param_3];
	ld.param.u64 	%rd56, [is_i64_u8_param_4];
	ld.param.u64 	%rd57, [is_i64_u8_param_5];
	ld.param.u64 	%rd51, [is_i64_u8_param_7];
	ld.param.u64 	%rd52, [is_i64_u8_param_8];
	ld.param.u64 	%rd53, [is_i64_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB12_4;

	mov.u64 	%rd109, 1;
	mov.u32 	%r52, 0;

$L__BB12_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd109, %rd64;
	mov.u16 	%rs7, 0;
	@%p2 bra 	$L__BB12_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd109, %rd67, %rd109;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs7, %rs2;
	@%p3 bra 	$L__BB12_2;

$L__BB12_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd110, %r53;
	setp.ge.u64 	%p4, %rd110, %rd49;
	@%p4 bra 	$L__BB12_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs7, 0;
	@%p5 bra 	$L__BB12_16;

$L__BB12_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB12_8;

	div.u64 	%rd111, %rd110, %rd9;
	bra.uni 	$L__BB12_9;

$L__BB12_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd110;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd111, %r22;

$L__BB12_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB12_11;

	div.u64 	%rd112, %rd110, %rd53;
	mul.lo.s64 	%rd71, %rd112, %rd53;
	sub.s64 	%rd113, %rd110, %rd71;
	bra.uni 	$L__BB12_12;

$L__BB12_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd110;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd112, %r25;
	cvt.u64.u32 	%rd113, %r27;

$L__BB12_12:
	or.b64  	%rd72, %rd112, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB12_14;

	rem.u64 	%rd114, %rd112, %rd52;
	bra.uni 	$L__BB12_15;

$L__BB12_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd112;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd114, %r30;

$L__BB12_15:
	shl.b64 	%rd74, %rd114, 3;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd111, %rd51;
	add.s64 	%rd78, %rd76, %rd77;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd113;
	and.b64  	%rd81, %rd80, 4294967295;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u8 	%rs5, [%rd82];
	add.s64 	%rd83, %rd1, %rd110;
	st.global.u8 	[%rd83], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p9, %rd110, %rd49;
	@%p9 bra 	$L__BB12_6;
	bra.uni 	$L__BB12_32;

$L__BB12_16:
	and.b64  	%rd84, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB12_17:
	setp.eq.s64 	%p10, %rd84, 0;
	@%p10 bra 	$L__BB12_19;

	div.u64 	%rd116, %rd110, %rd9;
	bra.uni 	$L__BB12_20;

$L__BB12_19:
	cvt.u32.u64 	%r32, %rd110;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd116, %r33;

$L__BB12_20:
	and.b64  	%rd85, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB12_22;

	div.u64 	%rd117, %rd110, %rd53;
	mul.lo.s64 	%rd86, %rd117, %rd53;
	sub.s64 	%rd118, %rd110, %rd86;
	bra.uni 	$L__BB12_23;

$L__BB12_22:
	cvt.u32.u64 	%r35, %rd110;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd117, %r36;
	cvt.u64.u32 	%rd118, %r38;

$L__BB12_23:
	or.b64  	%rd87, %rd117, %rd52;
	and.b64  	%rd88, %rd87, -4294967296;
	setp.eq.s64 	%p12, %rd88, 0;
	@%p12 bra 	$L__BB12_25;

	rem.u64 	%rd119, %rd117, %rd52;
	bra.uni 	$L__BB12_26;

$L__BB12_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd117;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd119, %r41;

$L__BB12_26:
	shl.b64 	%rd89, %rd119, 3;
	add.s64 	%rd90, %rd3, %rd89;
	ld.global.u64 	%rd91, [%rd90];
	mul.lo.s64 	%rd92, %rd116, %rd51;
	add.s64 	%rd93, %rd91, %rd92;
	mul.lo.s64 	%rd94, %rd93, %rd53;
	add.s64 	%rd120, %rd94, %rd118;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB12_31;

$L__BB12_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd95, %r45;
	add.s64 	%rd96, %rd95, %rd50;
	and.b64  	%rd39, %rd120, 4294967295;
	shl.b64 	%rd97, %rd96, 3;
	and.b64  	%rd98, %rd97, 34359738360;
	add.s64 	%rd40, %rd4, %rd98;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd99, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB12_29;

	div.u64 	%rd120, %rd39, %rd41;
	mul.lo.s64 	%rd100, %rd120, %rd41;
	sub.s64 	%rd122, %rd39, %rd100;
	bra.uni 	$L__BB12_30;

$L__BB12_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd120, %r48;
	cvt.u64.u32 	%rd122, %r50;

$L__BB12_30:
	shl.b64 	%rd101, %rd50, 3;
	add.s64 	%rd102, %rd40, %rd101;
	ld.global.u64 	%rd103, [%rd102];
	mul.lo.s64 	%rd104, %rd103, %rd122;
	cvt.u32.u64 	%r51, %rd104;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd105, %r55;
	setp.lt.u64 	%p15, %rd105, %rd50;
	@%p15 bra 	$L__BB12_27;

$L__BB12_31:
	cvt.u64.u32 	%rd106, %r56;
	add.s64 	%rd107, %rd2, %rd106;
	ld.global.u8 	%rs6, [%rd107];
	add.s64 	%rd108, %rd1, %rd110;
	st.global.u8 	[%rd108], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p16, %rd110, %rd49;
	@%p16 bra 	$L__BB12_17;

$L__BB12_32:
	ret;

}
	// .globl	is_i64_u32
.visible .entry is_i64_u32(
	.param .u64 is_i64_u32_param_0,
	.param .u64 is_i64_u32_param_1,
	.param .u64 is_i64_u32_param_2,
	.param .u64 is_i64_u32_param_3,
	.param .u64 is_i64_u32_param_4,
	.param .u64 is_i64_u32_param_5,
	.param .u64 is_i64_u32_param_6,
	.param .u64 is_i64_u32_param_7,
	.param .u64 is_i64_u32_param_8,
	.param .u64 is_i64_u32_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_i64_u32_param_0];
	ld.param.u64 	%rd50, [is_i64_u32_param_1];
	ld.param.u64 	%rd54, [is_i64_u32_param_2];
	ld.param.u64 	%rd55, [is_i64_u32_param_3];
	ld.param.u64 	%rd56, [is_i64_u32_param_4];
	ld.param.u64 	%rd57, [is_i64_u32_param_5];
	ld.param.u64 	%rd51, [is_i64_u32_param_7];
	ld.param.u64 	%rd52, [is_i64_u32_param_8];
	ld.param.u64 	%rd53, [is_i64_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB13_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r54, 0;

$L__BB13_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB13_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd68, %r54;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB13_2;

$L__BB13_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r55;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB13_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB13_16;

$L__BB13_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB13_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB13_9;

$L__BB13_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB13_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB13_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB13_12;

$L__BB13_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB13_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB13_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB13_15;

$L__BB13_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB13_15:
	shl.b64 	%rd74, %rd117, 3;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd76, %rd77;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 2;
	and.b64  	%rd82, %rd81, 17179869180;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.u32 	%r31, [%rd83];
	shl.b64 	%rd84, %rd113, 2;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.u32 	[%rd85], %r31;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd113, %r55;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB13_6;
	bra.uni 	$L__BB13_32;

$L__BB13_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r32, %rd9;
	cvt.u32.u64 	%r35, %rd53;

$L__BB13_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB13_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB13_20;

$L__BB13_19:
	cvt.u32.u64 	%r33, %rd113;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd119, %r34;

$L__BB13_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB13_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB13_23;

$L__BB13_22:
	cvt.u32.u64 	%r36, %rd113;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd120, %r37;
	cvt.u64.u32 	%rd121, %r39;

$L__BB13_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB13_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB13_26;

$L__BB13_25:
	cvt.u32.u64 	%r40, %rd52;
	cvt.u32.u64 	%r41, %rd120;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd122, %r42;

$L__BB13_26:
	shl.b64 	%rd91, %rd122, 3;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u64 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd93, %rd94;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB13_31;

$L__BB13_27:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd97, %r46;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB13_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB13_30;

$L__BB13_29:
	cvt.u32.u64 	%r47, %rd41;
	cvt.u32.u64 	%r48, %rd39;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd123, %r49;
	cvt.u64.u32 	%rd125, %r51;

$L__BB13_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r52, %rd106;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd107, %r57;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB13_27;

$L__BB13_31:
	mul.wide.u32 	%rd108, %r58, 4;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.u32 	%r53, [%rd109];
	shl.b64 	%rd110, %rd113, 2;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.u32 	[%rd111], %r53;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd113, %r55;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB13_17;

$L__BB13_32:
	ret;

}
	// .globl	is_i64_i64
.visible .entry is_i64_i64(
	.param .u64 is_i64_i64_param_0,
	.param .u64 is_i64_i64_param_1,
	.param .u64 is_i64_i64_param_2,
	.param .u64 is_i64_i64_param_3,
	.param .u64 is_i64_i64_param_4,
	.param .u64 is_i64_i64_param_5,
	.param .u64 is_i64_i64_param_6,
	.param .u64 is_i64_i64_param_7,
	.param .u64 is_i64_i64_param_8,
	.param .u64 is_i64_i64_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<128>;


	ld.param.u64 	%rd49, [is_i64_i64_param_0];
	ld.param.u64 	%rd50, [is_i64_i64_param_1];
	ld.param.u64 	%rd54, [is_i64_i64_param_2];
	ld.param.u64 	%rd55, [is_i64_i64_param_3];
	ld.param.u64 	%rd56, [is_i64_i64_param_4];
	ld.param.u64 	%rd57, [is_i64_i64_param_5];
	ld.param.u64 	%rd51, [is_i64_i64_param_7];
	ld.param.u64 	%rd52, [is_i64_i64_param_8];
	ld.param.u64 	%rd53, [is_i64_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB14_4;

	mov.u64 	%rd114, 1;
	mov.u32 	%r52, 0;

$L__BB14_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd114, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB14_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd114, %rd67, %rd114;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB14_2;

$L__BB14_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd115, %r53;
	setp.ge.u64 	%p4, %rd115, %rd49;
	@%p4 bra 	$L__BB14_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB14_16;

$L__BB14_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB14_8;

	div.u64 	%rd116, %rd115, %rd9;
	bra.uni 	$L__BB14_9;

$L__BB14_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd115;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd116, %r22;

$L__BB14_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB14_11;

	div.u64 	%rd117, %rd115, %rd53;
	mul.lo.s64 	%rd71, %rd117, %rd53;
	sub.s64 	%rd118, %rd115, %rd71;
	bra.uni 	$L__BB14_12;

$L__BB14_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd115;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd117, %r25;
	cvt.u64.u32 	%rd118, %r27;

$L__BB14_12:
	or.b64  	%rd72, %rd117, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB14_14;

	rem.u64 	%rd119, %rd117, %rd52;
	bra.uni 	$L__BB14_15;

$L__BB14_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd117;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd119, %r30;

$L__BB14_15:
	shl.b64 	%rd74, %rd119, 3;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u64 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd116, %rd51;
	add.s64 	%rd78, %rd76, %rd77;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd118;
	shl.b64 	%rd81, %rd80, 3;
	and.b64  	%rd82, %rd81, 34359738360;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.u64 	%rd84, [%rd83];
	shl.b64 	%rd85, %rd115, 3;
	add.s64 	%rd86, %rd1, %rd85;
	st.global.u64 	[%rd86], %rd84;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd115, %r53;
	setp.lt.u64 	%p9, %rd115, %rd49;
	@%p9 bra 	$L__BB14_6;
	bra.uni 	$L__BB14_32;

$L__BB14_16:
	and.b64  	%rd87, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB14_17:
	setp.eq.s64 	%p10, %rd87, 0;
	@%p10 bra 	$L__BB14_19;

	div.u64 	%rd121, %rd115, %rd9;
	bra.uni 	$L__BB14_20;

$L__BB14_19:
	cvt.u32.u64 	%r32, %rd115;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd121, %r33;

$L__BB14_20:
	and.b64  	%rd88, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd88, 0;
	@%p11 bra 	$L__BB14_22;

	div.u64 	%rd122, %rd115, %rd53;
	mul.lo.s64 	%rd89, %rd122, %rd53;
	sub.s64 	%rd123, %rd115, %rd89;
	bra.uni 	$L__BB14_23;

$L__BB14_22:
	cvt.u32.u64 	%r35, %rd115;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd122, %r36;
	cvt.u64.u32 	%rd123, %r38;

$L__BB14_23:
	or.b64  	%rd90, %rd122, %rd52;
	and.b64  	%rd91, %rd90, -4294967296;
	setp.eq.s64 	%p12, %rd91, 0;
	@%p12 bra 	$L__BB14_25;

	rem.u64 	%rd124, %rd122, %rd52;
	bra.uni 	$L__BB14_26;

$L__BB14_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd122;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd124, %r41;

$L__BB14_26:
	shl.b64 	%rd92, %rd124, 3;
	add.s64 	%rd93, %rd3, %rd92;
	ld.global.u64 	%rd94, [%rd93];
	mul.lo.s64 	%rd95, %rd121, %rd51;
	add.s64 	%rd96, %rd94, %rd95;
	mul.lo.s64 	%rd97, %rd96, %rd53;
	add.s64 	%rd125, %rd97, %rd123;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB14_31;

$L__BB14_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd98, %r45;
	add.s64 	%rd99, %rd98, %rd50;
	and.b64  	%rd39, %rd125, 4294967295;
	shl.b64 	%rd100, %rd99, 3;
	and.b64  	%rd101, %rd100, 34359738360;
	add.s64 	%rd40, %rd4, %rd101;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd102, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd102, 0;
	@%p14 bra 	$L__BB14_29;

	div.u64 	%rd125, %rd39, %rd41;
	mul.lo.s64 	%rd103, %rd125, %rd41;
	sub.s64 	%rd127, %rd39, %rd103;
	bra.uni 	$L__BB14_30;

$L__BB14_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd125, %r48;
	cvt.u64.u32 	%rd127, %r50;

$L__BB14_30:
	shl.b64 	%rd104, %rd50, 3;
	add.s64 	%rd105, %rd40, %rd104;
	ld.global.u64 	%rd106, [%rd105];
	mul.lo.s64 	%rd107, %rd106, %rd127;
	cvt.u32.u64 	%r51, %rd107;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd108, %r55;
	setp.lt.u64 	%p15, %rd108, %rd50;
	@%p15 bra 	$L__BB14_27;

$L__BB14_31:
	mul.wide.u32 	%rd109, %r56, 8;
	add.s64 	%rd110, %rd2, %rd109;
	ld.global.u64 	%rd111, [%rd110];
	shl.b64 	%rd112, %rd115, 3;
	add.s64 	%rd113, %rd1, %rd112;
	st.global.u64 	[%rd113], %rd111;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd115, %r53;
	setp.lt.u64 	%p16, %rd115, %rd49;
	@%p16 bra 	$L__BB14_17;

$L__BB14_32:
	ret;

}
	// .globl	is_u32_f32
.visible .entry is_u32_f32(
	.param .u64 is_u32_f32_param_0,
	.param .u64 is_u32_f32_param_1,
	.param .u64 is_u32_f32_param_2,
	.param .u64 is_u32_f32_param_3,
	.param .u64 is_u32_f32_param_4,
	.param .u64 is_u32_f32_param_5,
	.param .u64 is_u32_f32_param_6,
	.param .u64 is_u32_f32_param_7,
	.param .u64 is_u32_f32_param_8,
	.param .u64 is_u32_f32_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_u32_f32_param_0];
	ld.param.u64 	%rd50, [is_u32_f32_param_1];
	ld.param.u64 	%rd54, [is_u32_f32_param_2];
	ld.param.u64 	%rd55, [is_u32_f32_param_3];
	ld.param.u64 	%rd56, [is_u32_f32_param_4];
	ld.param.u64 	%rd57, [is_u32_f32_param_5];
	ld.param.u64 	%rd51, [is_u32_f32_param_7];
	ld.param.u64 	%rd52, [is_u32_f32_param_8];
	ld.param.u64 	%rd53, [is_u32_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB15_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r52, 0;

$L__BB15_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB15_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB15_2;

$L__BB15_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r53;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB15_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB15_16;

$L__BB15_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB15_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB15_9;

$L__BB15_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB15_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB15_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB15_12;

$L__BB15_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB15_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB15_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB15_15;

$L__BB15_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB15_15:
	shl.b64 	%rd74, %rd117, 2;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u32 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd77, %rd76;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 2;
	and.b64  	%rd82, %rd81, 17179869180;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.f32 	%f1, [%rd83];
	shl.b64 	%rd84, %rd113, 2;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.f32 	[%rd85], %f1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB15_6;
	bra.uni 	$L__BB15_32;

$L__BB15_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB15_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB15_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB15_20;

$L__BB15_19:
	cvt.u32.u64 	%r32, %rd113;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd119, %r33;

$L__BB15_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB15_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB15_23;

$L__BB15_22:
	cvt.u32.u64 	%r35, %rd113;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd120, %r36;
	cvt.u64.u32 	%rd121, %r38;

$L__BB15_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB15_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB15_26;

$L__BB15_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd120;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd122, %r41;

$L__BB15_26:
	shl.b64 	%rd91, %rd122, 2;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u32 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd94, %rd93;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB15_31;

$L__BB15_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB15_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB15_30;

$L__BB15_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd123, %r48;
	cvt.u64.u32 	%rd125, %r50;

$L__BB15_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB15_27;

$L__BB15_31:
	mul.wide.u32 	%rd108, %r56, 4;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.f32 	%f2, [%rd109];
	shl.b64 	%rd110, %rd113, 2;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.f32 	[%rd111], %f2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB15_17;

$L__BB15_32:
	ret;

}
	// .globl	is_u32_f64
.visible .entry is_u32_f64(
	.param .u64 is_u32_f64_param_0,
	.param .u64 is_u32_f64_param_1,
	.param .u64 is_u32_f64_param_2,
	.param .u64 is_u32_f64_param_3,
	.param .u64 is_u32_f64_param_4,
	.param .u64 is_u32_f64_param_5,
	.param .u64 is_u32_f64_param_6,
	.param .u64 is_u32_f64_param_7,
	.param .u64 is_u32_f64_param_8,
	.param .u64 is_u32_f64_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_u32_f64_param_0];
	ld.param.u64 	%rd50, [is_u32_f64_param_1];
	ld.param.u64 	%rd54, [is_u32_f64_param_2];
	ld.param.u64 	%rd55, [is_u32_f64_param_3];
	ld.param.u64 	%rd56, [is_u32_f64_param_4];
	ld.param.u64 	%rd57, [is_u32_f64_param_5];
	ld.param.u64 	%rd51, [is_u32_f64_param_7];
	ld.param.u64 	%rd52, [is_u32_f64_param_8];
	ld.param.u64 	%rd53, [is_u32_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB16_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r52, 0;

$L__BB16_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB16_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB16_2;

$L__BB16_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r53;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB16_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB16_16;

$L__BB16_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB16_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB16_9;

$L__BB16_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB16_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB16_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB16_12;

$L__BB16_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB16_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB16_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB16_15;

$L__BB16_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB16_15:
	shl.b64 	%rd74, %rd117, 2;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u32 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd77, %rd76;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 3;
	and.b64  	%rd82, %rd81, 34359738360;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.f64 	%fd1, [%rd83];
	shl.b64 	%rd84, %rd113, 3;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.f64 	[%rd85], %fd1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB16_6;
	bra.uni 	$L__BB16_32;

$L__BB16_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB16_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB16_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB16_20;

$L__BB16_19:
	cvt.u32.u64 	%r32, %rd113;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd119, %r33;

$L__BB16_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB16_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB16_23;

$L__BB16_22:
	cvt.u32.u64 	%r35, %rd113;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd120, %r36;
	cvt.u64.u32 	%rd121, %r38;

$L__BB16_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB16_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB16_26;

$L__BB16_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd120;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd122, %r41;

$L__BB16_26:
	shl.b64 	%rd91, %rd122, 2;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u32 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd94, %rd93;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB16_31;

$L__BB16_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB16_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB16_30;

$L__BB16_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd123, %r48;
	cvt.u64.u32 	%rd125, %r50;

$L__BB16_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB16_27;

$L__BB16_31:
	mul.wide.u32 	%rd108, %r56, 8;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.f64 	%fd2, [%rd109];
	shl.b64 	%rd110, %rd113, 3;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.f64 	[%rd111], %fd2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB16_17;

$L__BB16_32:
	ret;

}
	// .globl	is_u32_u8
.visible .entry is_u32_u8(
	.param .u64 is_u32_u8_param_0,
	.param .u64 is_u32_u8_param_1,
	.param .u64 is_u32_u8_param_2,
	.param .u64 is_u32_u8_param_3,
	.param .u64 is_u32_u8_param_4,
	.param .u64 is_u32_u8_param_5,
	.param .u64 is_u32_u8_param_6,
	.param .u64 is_u32_u8_param_7,
	.param .u64 is_u32_u8_param_8,
	.param .u64 is_u32_u8_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<123>;


	ld.param.u64 	%rd49, [is_u32_u8_param_0];
	ld.param.u64 	%rd50, [is_u32_u8_param_1];
	ld.param.u64 	%rd54, [is_u32_u8_param_2];
	ld.param.u64 	%rd55, [is_u32_u8_param_3];
	ld.param.u64 	%rd56, [is_u32_u8_param_4];
	ld.param.u64 	%rd57, [is_u32_u8_param_5];
	ld.param.u64 	%rd51, [is_u32_u8_param_7];
	ld.param.u64 	%rd52, [is_u32_u8_param_8];
	ld.param.u64 	%rd53, [is_u32_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB17_4;

	mov.u64 	%rd109, 1;
	mov.u32 	%r52, 0;

$L__BB17_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd109, %rd64;
	mov.u16 	%rs7, 0;
	@%p2 bra 	$L__BB17_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd109, %rd67, %rd109;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs7, %rs2;
	@%p3 bra 	$L__BB17_2;

$L__BB17_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd110, %r53;
	setp.ge.u64 	%p4, %rd110, %rd49;
	@%p4 bra 	$L__BB17_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs7, 0;
	@%p5 bra 	$L__BB17_16;

$L__BB17_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB17_8;

	div.u64 	%rd111, %rd110, %rd9;
	bra.uni 	$L__BB17_9;

$L__BB17_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd110;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd111, %r22;

$L__BB17_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB17_11;

	div.u64 	%rd112, %rd110, %rd53;
	mul.lo.s64 	%rd71, %rd112, %rd53;
	sub.s64 	%rd113, %rd110, %rd71;
	bra.uni 	$L__BB17_12;

$L__BB17_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd110;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd112, %r25;
	cvt.u64.u32 	%rd113, %r27;

$L__BB17_12:
	or.b64  	%rd72, %rd112, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB17_14;

	rem.u64 	%rd114, %rd112, %rd52;
	bra.uni 	$L__BB17_15;

$L__BB17_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd112;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd114, %r30;

$L__BB17_15:
	shl.b64 	%rd74, %rd114, 2;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u32 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd111, %rd51;
	add.s64 	%rd78, %rd77, %rd76;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd113;
	and.b64  	%rd81, %rd80, 4294967295;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u8 	%rs5, [%rd82];
	add.s64 	%rd83, %rd1, %rd110;
	st.global.u8 	[%rd83], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p9, %rd110, %rd49;
	@%p9 bra 	$L__BB17_6;
	bra.uni 	$L__BB17_32;

$L__BB17_16:
	and.b64  	%rd84, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB17_17:
	setp.eq.s64 	%p10, %rd84, 0;
	@%p10 bra 	$L__BB17_19;

	div.u64 	%rd116, %rd110, %rd9;
	bra.uni 	$L__BB17_20;

$L__BB17_19:
	cvt.u32.u64 	%r32, %rd110;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd116, %r33;

$L__BB17_20:
	and.b64  	%rd85, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB17_22;

	div.u64 	%rd117, %rd110, %rd53;
	mul.lo.s64 	%rd86, %rd117, %rd53;
	sub.s64 	%rd118, %rd110, %rd86;
	bra.uni 	$L__BB17_23;

$L__BB17_22:
	cvt.u32.u64 	%r35, %rd110;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd117, %r36;
	cvt.u64.u32 	%rd118, %r38;

$L__BB17_23:
	or.b64  	%rd87, %rd117, %rd52;
	and.b64  	%rd88, %rd87, -4294967296;
	setp.eq.s64 	%p12, %rd88, 0;
	@%p12 bra 	$L__BB17_25;

	rem.u64 	%rd119, %rd117, %rd52;
	bra.uni 	$L__BB17_26;

$L__BB17_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd117;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd119, %r41;

$L__BB17_26:
	shl.b64 	%rd89, %rd119, 2;
	add.s64 	%rd90, %rd3, %rd89;
	ld.global.u32 	%rd91, [%rd90];
	mul.lo.s64 	%rd92, %rd116, %rd51;
	add.s64 	%rd93, %rd92, %rd91;
	mul.lo.s64 	%rd94, %rd93, %rd53;
	add.s64 	%rd120, %rd94, %rd118;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB17_31;

$L__BB17_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd95, %r45;
	add.s64 	%rd96, %rd95, %rd50;
	and.b64  	%rd39, %rd120, 4294967295;
	shl.b64 	%rd97, %rd96, 3;
	and.b64  	%rd98, %rd97, 34359738360;
	add.s64 	%rd40, %rd4, %rd98;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd99, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB17_29;

	div.u64 	%rd120, %rd39, %rd41;
	mul.lo.s64 	%rd100, %rd120, %rd41;
	sub.s64 	%rd122, %rd39, %rd100;
	bra.uni 	$L__BB17_30;

$L__BB17_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd120, %r48;
	cvt.u64.u32 	%rd122, %r50;

$L__BB17_30:
	shl.b64 	%rd101, %rd50, 3;
	add.s64 	%rd102, %rd40, %rd101;
	ld.global.u64 	%rd103, [%rd102];
	mul.lo.s64 	%rd104, %rd103, %rd122;
	cvt.u32.u64 	%r51, %rd104;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd105, %r55;
	setp.lt.u64 	%p15, %rd105, %rd50;
	@%p15 bra 	$L__BB17_27;

$L__BB17_31:
	cvt.u64.u32 	%rd106, %r56;
	add.s64 	%rd107, %rd2, %rd106;
	ld.global.u8 	%rs6, [%rd107];
	add.s64 	%rd108, %rd1, %rd110;
	st.global.u8 	[%rd108], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p16, %rd110, %rd49;
	@%p16 bra 	$L__BB17_17;

$L__BB17_32:
	ret;

}
	// .globl	is_u32_i64
.visible .entry is_u32_i64(
	.param .u64 is_u32_i64_param_0,
	.param .u64 is_u32_i64_param_1,
	.param .u64 is_u32_i64_param_2,
	.param .u64 is_u32_i64_param_3,
	.param .u64 is_u32_i64_param_4,
	.param .u64 is_u32_i64_param_5,
	.param .u64 is_u32_i64_param_6,
	.param .u64 is_u32_i64_param_7,
	.param .u64 is_u32_i64_param_8,
	.param .u64 is_u32_i64_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<128>;


	ld.param.u64 	%rd49, [is_u32_i64_param_0];
	ld.param.u64 	%rd50, [is_u32_i64_param_1];
	ld.param.u64 	%rd54, [is_u32_i64_param_2];
	ld.param.u64 	%rd55, [is_u32_i64_param_3];
	ld.param.u64 	%rd56, [is_u32_i64_param_4];
	ld.param.u64 	%rd57, [is_u32_i64_param_5];
	ld.param.u64 	%rd51, [is_u32_i64_param_7];
	ld.param.u64 	%rd52, [is_u32_i64_param_8];
	ld.param.u64 	%rd53, [is_u32_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB18_4;

	mov.u64 	%rd114, 1;
	mov.u32 	%r52, 0;

$L__BB18_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd114, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB18_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd114, %rd67, %rd114;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB18_2;

$L__BB18_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd115, %r53;
	setp.ge.u64 	%p4, %rd115, %rd49;
	@%p4 bra 	$L__BB18_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB18_16;

$L__BB18_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB18_8;

	div.u64 	%rd116, %rd115, %rd9;
	bra.uni 	$L__BB18_9;

$L__BB18_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd115;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd116, %r22;

$L__BB18_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB18_11;

	div.u64 	%rd117, %rd115, %rd53;
	mul.lo.s64 	%rd71, %rd117, %rd53;
	sub.s64 	%rd118, %rd115, %rd71;
	bra.uni 	$L__BB18_12;

$L__BB18_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd115;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd117, %r25;
	cvt.u64.u32 	%rd118, %r27;

$L__BB18_12:
	or.b64  	%rd72, %rd117, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB18_14;

	rem.u64 	%rd119, %rd117, %rd52;
	bra.uni 	$L__BB18_15;

$L__BB18_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd117;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd119, %r30;

$L__BB18_15:
	shl.b64 	%rd74, %rd119, 2;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u32 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd116, %rd51;
	add.s64 	%rd78, %rd77, %rd76;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd118;
	shl.b64 	%rd81, %rd80, 3;
	and.b64  	%rd82, %rd81, 34359738360;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.u64 	%rd84, [%rd83];
	shl.b64 	%rd85, %rd115, 3;
	add.s64 	%rd86, %rd1, %rd85;
	st.global.u64 	[%rd86], %rd84;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd115, %r53;
	setp.lt.u64 	%p9, %rd115, %rd49;
	@%p9 bra 	$L__BB18_6;
	bra.uni 	$L__BB18_32;

$L__BB18_16:
	and.b64  	%rd87, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB18_17:
	setp.eq.s64 	%p10, %rd87, 0;
	@%p10 bra 	$L__BB18_19;

	div.u64 	%rd121, %rd115, %rd9;
	bra.uni 	$L__BB18_20;

$L__BB18_19:
	cvt.u32.u64 	%r32, %rd115;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd121, %r33;

$L__BB18_20:
	and.b64  	%rd88, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd88, 0;
	@%p11 bra 	$L__BB18_22;

	div.u64 	%rd122, %rd115, %rd53;
	mul.lo.s64 	%rd89, %rd122, %rd53;
	sub.s64 	%rd123, %rd115, %rd89;
	bra.uni 	$L__BB18_23;

$L__BB18_22:
	cvt.u32.u64 	%r35, %rd115;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd122, %r36;
	cvt.u64.u32 	%rd123, %r38;

$L__BB18_23:
	or.b64  	%rd90, %rd122, %rd52;
	and.b64  	%rd91, %rd90, -4294967296;
	setp.eq.s64 	%p12, %rd91, 0;
	@%p12 bra 	$L__BB18_25;

	rem.u64 	%rd124, %rd122, %rd52;
	bra.uni 	$L__BB18_26;

$L__BB18_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd122;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd124, %r41;

$L__BB18_26:
	shl.b64 	%rd92, %rd124, 2;
	add.s64 	%rd93, %rd3, %rd92;
	ld.global.u32 	%rd94, [%rd93];
	mul.lo.s64 	%rd95, %rd121, %rd51;
	add.s64 	%rd96, %rd95, %rd94;
	mul.lo.s64 	%rd97, %rd96, %rd53;
	add.s64 	%rd125, %rd97, %rd123;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB18_31;

$L__BB18_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd98, %r45;
	add.s64 	%rd99, %rd98, %rd50;
	and.b64  	%rd39, %rd125, 4294967295;
	shl.b64 	%rd100, %rd99, 3;
	and.b64  	%rd101, %rd100, 34359738360;
	add.s64 	%rd40, %rd4, %rd101;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd102, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd102, 0;
	@%p14 bra 	$L__BB18_29;

	div.u64 	%rd125, %rd39, %rd41;
	mul.lo.s64 	%rd103, %rd125, %rd41;
	sub.s64 	%rd127, %rd39, %rd103;
	bra.uni 	$L__BB18_30;

$L__BB18_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd125, %r48;
	cvt.u64.u32 	%rd127, %r50;

$L__BB18_30:
	shl.b64 	%rd104, %rd50, 3;
	add.s64 	%rd105, %rd40, %rd104;
	ld.global.u64 	%rd106, [%rd105];
	mul.lo.s64 	%rd107, %rd106, %rd127;
	cvt.u32.u64 	%r51, %rd107;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd108, %r55;
	setp.lt.u64 	%p15, %rd108, %rd50;
	@%p15 bra 	$L__BB18_27;

$L__BB18_31:
	mul.wide.u32 	%rd109, %r56, 8;
	add.s64 	%rd110, %rd2, %rd109;
	ld.global.u64 	%rd111, [%rd110];
	shl.b64 	%rd112, %rd115, 3;
	add.s64 	%rd113, %rd1, %rd112;
	st.global.u64 	[%rd113], %rd111;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd115, %r53;
	setp.lt.u64 	%p16, %rd115, %rd49;
	@%p16 bra 	$L__BB18_17;

$L__BB18_32:
	ret;

}
	// .globl	is_u32_u32
.visible .entry is_u32_u32(
	.param .u64 is_u32_u32_param_0,
	.param .u64 is_u32_u32_param_1,
	.param .u64 is_u32_u32_param_2,
	.param .u64 is_u32_u32_param_3,
	.param .u64 is_u32_u32_param_4,
	.param .u64 is_u32_u32_param_5,
	.param .u64 is_u32_u32_param_6,
	.param .u64 is_u32_u32_param_7,
	.param .u64 is_u32_u32_param_8,
	.param .u64 is_u32_u32_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_u32_u32_param_0];
	ld.param.u64 	%rd50, [is_u32_u32_param_1];
	ld.param.u64 	%rd54, [is_u32_u32_param_2];
	ld.param.u64 	%rd55, [is_u32_u32_param_3];
	ld.param.u64 	%rd56, [is_u32_u32_param_4];
	ld.param.u64 	%rd57, [is_u32_u32_param_5];
	ld.param.u64 	%rd51, [is_u32_u32_param_7];
	ld.param.u64 	%rd52, [is_u32_u32_param_8];
	ld.param.u64 	%rd53, [is_u32_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB19_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r54, 0;

$L__BB19_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB19_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd68, %r54;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB19_2;

$L__BB19_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r55;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB19_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB19_16;

$L__BB19_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB19_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB19_9;

$L__BB19_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB19_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB19_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB19_12;

$L__BB19_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB19_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB19_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB19_15;

$L__BB19_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB19_15:
	shl.b64 	%rd74, %rd117, 2;
	add.s64 	%rd75, %rd3, %rd74;
	ld.global.u32 	%rd76, [%rd75];
	mul.lo.s64 	%rd77, %rd114, %rd51;
	add.s64 	%rd78, %rd77, %rd76;
	mul.lo.s64 	%rd79, %rd78, %rd53;
	add.s64 	%rd80, %rd79, %rd116;
	shl.b64 	%rd81, %rd80, 2;
	and.b64  	%rd82, %rd81, 17179869180;
	add.s64 	%rd83, %rd2, %rd82;
	ld.global.u32 	%r31, [%rd83];
	shl.b64 	%rd84, %rd113, 2;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.u32 	[%rd85], %r31;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd113, %r55;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB19_6;
	bra.uni 	$L__BB19_32;

$L__BB19_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r32, %rd9;
	cvt.u32.u64 	%r35, %rd53;

$L__BB19_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB19_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB19_20;

$L__BB19_19:
	cvt.u32.u64 	%r33, %rd113;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd119, %r34;

$L__BB19_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB19_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB19_23;

$L__BB19_22:
	cvt.u32.u64 	%r36, %rd113;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd120, %r37;
	cvt.u64.u32 	%rd121, %r39;

$L__BB19_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB19_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB19_26;

$L__BB19_25:
	cvt.u32.u64 	%r40, %rd52;
	cvt.u32.u64 	%r41, %rd120;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd122, %r42;

$L__BB19_26:
	shl.b64 	%rd91, %rd122, 2;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u32 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd119, %rd51;
	add.s64 	%rd95, %rd94, %rd93;
	mul.lo.s64 	%rd96, %rd95, %rd53;
	add.s64 	%rd123, %rd96, %rd121;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB19_31;

$L__BB19_27:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd97, %r46;
	add.s64 	%rd98, %rd97, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd40, %rd4, %rd100;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd101, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd101, 0;
	@%p14 bra 	$L__BB19_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd102, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd102;
	bra.uni 	$L__BB19_30;

$L__BB19_29:
	cvt.u32.u64 	%r47, %rd41;
	cvt.u32.u64 	%r48, %rd39;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd123, %r49;
	cvt.u64.u32 	%rd125, %r51;

$L__BB19_30:
	shl.b64 	%rd103, %rd50, 3;
	add.s64 	%rd104, %rd40, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd125;
	cvt.u32.u64 	%r52, %rd106;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd107, %r57;
	setp.lt.u64 	%p15, %rd107, %rd50;
	@%p15 bra 	$L__BB19_27;

$L__BB19_31:
	mul.wide.u32 	%rd108, %r58, 4;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.u32 	%r53, [%rd109];
	shl.b64 	%rd110, %rd113, 2;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.u32 	[%rd111], %r53;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd113, %r55;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB19_17;

$L__BB19_32:
	ret;

}
	// .globl	is_u8_f32
.visible .entry is_u8_f32(
	.param .u64 is_u8_f32_param_0,
	.param .u64 is_u8_f32_param_1,
	.param .u64 is_u8_f32_param_2,
	.param .u64 is_u8_f32_param_3,
	.param .u64 is_u8_f32_param_4,
	.param .u64 is_u8_f32_param_5,
	.param .u64 is_u8_f32_param_6,
	.param .u64 is_u8_f32_param_7,
	.param .u64 is_u8_f32_param_8,
	.param .u64 is_u8_f32_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<124>;


	ld.param.u64 	%rd49, [is_u8_f32_param_0];
	ld.param.u64 	%rd50, [is_u8_f32_param_1];
	ld.param.u64 	%rd54, [is_u8_f32_param_2];
	ld.param.u64 	%rd55, [is_u8_f32_param_3];
	ld.param.u64 	%rd56, [is_u8_f32_param_4];
	ld.param.u64 	%rd57, [is_u8_f32_param_5];
	ld.param.u64 	%rd51, [is_u8_f32_param_7];
	ld.param.u64 	%rd52, [is_u8_f32_param_8];
	ld.param.u64 	%rd53, [is_u8_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB20_4;

	mov.u64 	%rd110, 1;
	mov.u32 	%r52, 0;

$L__BB20_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd110, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB20_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd110, %rd67, %rd110;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB20_2;

$L__BB20_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd111, %r53;
	setp.ge.u64 	%p4, %rd111, %rd49;
	@%p4 bra 	$L__BB20_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB20_16;

$L__BB20_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB20_8;

	div.u64 	%rd112, %rd111, %rd9;
	bra.uni 	$L__BB20_9;

$L__BB20_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd111;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd112, %r22;

$L__BB20_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB20_11;

	div.u64 	%rd113, %rd111, %rd53;
	mul.lo.s64 	%rd71, %rd113, %rd53;
	sub.s64 	%rd114, %rd111, %rd71;
	bra.uni 	$L__BB20_12;

$L__BB20_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd111;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd113, %r25;
	cvt.u64.u32 	%rd114, %r27;

$L__BB20_12:
	or.b64  	%rd72, %rd113, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB20_14;

	rem.u64 	%rd115, %rd113, %rd52;
	bra.uni 	$L__BB20_15;

$L__BB20_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd113;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd115, %r30;

$L__BB20_15:
	add.s64 	%rd74, %rd3, %rd115;
	ld.global.u8 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd112, %rd51;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd53;
	add.s64 	%rd79, %rd78, %rd114;
	shl.b64 	%rd80, %rd79, 2;
	and.b64  	%rd81, %rd80, 17179869180;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.f32 	%f1, [%rd82];
	shl.b64 	%rd83, %rd111, 2;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.f32 	[%rd84], %f1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd111, %r53;
	setp.lt.u64 	%p9, %rd111, %rd49;
	@%p9 bra 	$L__BB20_6;
	bra.uni 	$L__BB20_32;

$L__BB20_16:
	and.b64  	%rd85, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB20_17:
	setp.eq.s64 	%p10, %rd85, 0;
	@%p10 bra 	$L__BB20_19;

	div.u64 	%rd117, %rd111, %rd9;
	bra.uni 	$L__BB20_20;

$L__BB20_19:
	cvt.u32.u64 	%r32, %rd111;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd117, %r33;

$L__BB20_20:
	and.b64  	%rd86, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd86, 0;
	@%p11 bra 	$L__BB20_22;

	div.u64 	%rd118, %rd111, %rd53;
	mul.lo.s64 	%rd87, %rd118, %rd53;
	sub.s64 	%rd119, %rd111, %rd87;
	bra.uni 	$L__BB20_23;

$L__BB20_22:
	cvt.u32.u64 	%r35, %rd111;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd118, %r36;
	cvt.u64.u32 	%rd119, %r38;

$L__BB20_23:
	or.b64  	%rd88, %rd118, %rd52;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p12, %rd89, 0;
	@%p12 bra 	$L__BB20_25;

	rem.u64 	%rd120, %rd118, %rd52;
	bra.uni 	$L__BB20_26;

$L__BB20_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd118;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd120, %r41;

$L__BB20_26:
	add.s64 	%rd90, %rd3, %rd120;
	ld.global.u8 	%rd91, [%rd90];
	mul.lo.s64 	%rd92, %rd117, %rd51;
	add.s64 	%rd93, %rd92, %rd91;
	mul.lo.s64 	%rd94, %rd93, %rd53;
	add.s64 	%rd121, %rd94, %rd119;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB20_31;

$L__BB20_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd95, %r45;
	add.s64 	%rd96, %rd95, %rd50;
	and.b64  	%rd39, %rd121, 4294967295;
	shl.b64 	%rd97, %rd96, 3;
	and.b64  	%rd98, %rd97, 34359738360;
	add.s64 	%rd40, %rd4, %rd98;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd99, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB20_29;

	div.u64 	%rd121, %rd39, %rd41;
	mul.lo.s64 	%rd100, %rd121, %rd41;
	sub.s64 	%rd123, %rd39, %rd100;
	bra.uni 	$L__BB20_30;

$L__BB20_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd121, %r48;
	cvt.u64.u32 	%rd123, %r50;

$L__BB20_30:
	shl.b64 	%rd101, %rd50, 3;
	add.s64 	%rd102, %rd40, %rd101;
	ld.global.u64 	%rd103, [%rd102];
	mul.lo.s64 	%rd104, %rd103, %rd123;
	cvt.u32.u64 	%r51, %rd104;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd105, %r55;
	setp.lt.u64 	%p15, %rd105, %rd50;
	@%p15 bra 	$L__BB20_27;

$L__BB20_31:
	mul.wide.u32 	%rd106, %r56, 4;
	add.s64 	%rd107, %rd2, %rd106;
	ld.global.f32 	%f2, [%rd107];
	shl.b64 	%rd108, %rd111, 2;
	add.s64 	%rd109, %rd1, %rd108;
	st.global.f32 	[%rd109], %f2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd111, %r53;
	setp.lt.u64 	%p16, %rd111, %rd49;
	@%p16 bra 	$L__BB20_17;

$L__BB20_32:
	ret;

}
	// .globl	is_u8_f64
.visible .entry is_u8_f64(
	.param .u64 is_u8_f64_param_0,
	.param .u64 is_u8_f64_param_1,
	.param .u64 is_u8_f64_param_2,
	.param .u64 is_u8_f64_param_3,
	.param .u64 is_u8_f64_param_4,
	.param .u64 is_u8_f64_param_5,
	.param .u64 is_u8_f64_param_6,
	.param .u64 is_u8_f64_param_7,
	.param .u64 is_u8_f64_param_8,
	.param .u64 is_u8_f64_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<124>;


	ld.param.u64 	%rd49, [is_u8_f64_param_0];
	ld.param.u64 	%rd50, [is_u8_f64_param_1];
	ld.param.u64 	%rd54, [is_u8_f64_param_2];
	ld.param.u64 	%rd55, [is_u8_f64_param_3];
	ld.param.u64 	%rd56, [is_u8_f64_param_4];
	ld.param.u64 	%rd57, [is_u8_f64_param_5];
	ld.param.u64 	%rd51, [is_u8_f64_param_7];
	ld.param.u64 	%rd52, [is_u8_f64_param_8];
	ld.param.u64 	%rd53, [is_u8_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB21_4;

	mov.u64 	%rd110, 1;
	mov.u32 	%r52, 0;

$L__BB21_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd110, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB21_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd110, %rd67, %rd110;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB21_2;

$L__BB21_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd111, %r53;
	setp.ge.u64 	%p4, %rd111, %rd49;
	@%p4 bra 	$L__BB21_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB21_16;

$L__BB21_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB21_8;

	div.u64 	%rd112, %rd111, %rd9;
	bra.uni 	$L__BB21_9;

$L__BB21_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd111;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd112, %r22;

$L__BB21_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB21_11;

	div.u64 	%rd113, %rd111, %rd53;
	mul.lo.s64 	%rd71, %rd113, %rd53;
	sub.s64 	%rd114, %rd111, %rd71;
	bra.uni 	$L__BB21_12;

$L__BB21_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd111;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd113, %r25;
	cvt.u64.u32 	%rd114, %r27;

$L__BB21_12:
	or.b64  	%rd72, %rd113, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB21_14;

	rem.u64 	%rd115, %rd113, %rd52;
	bra.uni 	$L__BB21_15;

$L__BB21_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd113;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd115, %r30;

$L__BB21_15:
	add.s64 	%rd74, %rd3, %rd115;
	ld.global.u8 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd112, %rd51;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd53;
	add.s64 	%rd79, %rd78, %rd114;
	shl.b64 	%rd80, %rd79, 3;
	and.b64  	%rd81, %rd80, 34359738360;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.f64 	%fd1, [%rd82];
	shl.b64 	%rd83, %rd111, 3;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.f64 	[%rd84], %fd1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd111, %r53;
	setp.lt.u64 	%p9, %rd111, %rd49;
	@%p9 bra 	$L__BB21_6;
	bra.uni 	$L__BB21_32;

$L__BB21_16:
	and.b64  	%rd85, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB21_17:
	setp.eq.s64 	%p10, %rd85, 0;
	@%p10 bra 	$L__BB21_19;

	div.u64 	%rd117, %rd111, %rd9;
	bra.uni 	$L__BB21_20;

$L__BB21_19:
	cvt.u32.u64 	%r32, %rd111;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd117, %r33;

$L__BB21_20:
	and.b64  	%rd86, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd86, 0;
	@%p11 bra 	$L__BB21_22;

	div.u64 	%rd118, %rd111, %rd53;
	mul.lo.s64 	%rd87, %rd118, %rd53;
	sub.s64 	%rd119, %rd111, %rd87;
	bra.uni 	$L__BB21_23;

$L__BB21_22:
	cvt.u32.u64 	%r35, %rd111;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd118, %r36;
	cvt.u64.u32 	%rd119, %r38;

$L__BB21_23:
	or.b64  	%rd88, %rd118, %rd52;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p12, %rd89, 0;
	@%p12 bra 	$L__BB21_25;

	rem.u64 	%rd120, %rd118, %rd52;
	bra.uni 	$L__BB21_26;

$L__BB21_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd118;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd120, %r41;

$L__BB21_26:
	add.s64 	%rd90, %rd3, %rd120;
	ld.global.u8 	%rd91, [%rd90];
	mul.lo.s64 	%rd92, %rd117, %rd51;
	add.s64 	%rd93, %rd92, %rd91;
	mul.lo.s64 	%rd94, %rd93, %rd53;
	add.s64 	%rd121, %rd94, %rd119;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB21_31;

$L__BB21_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd95, %r45;
	add.s64 	%rd96, %rd95, %rd50;
	and.b64  	%rd39, %rd121, 4294967295;
	shl.b64 	%rd97, %rd96, 3;
	and.b64  	%rd98, %rd97, 34359738360;
	add.s64 	%rd40, %rd4, %rd98;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd99, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB21_29;

	div.u64 	%rd121, %rd39, %rd41;
	mul.lo.s64 	%rd100, %rd121, %rd41;
	sub.s64 	%rd123, %rd39, %rd100;
	bra.uni 	$L__BB21_30;

$L__BB21_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd121, %r48;
	cvt.u64.u32 	%rd123, %r50;

$L__BB21_30:
	shl.b64 	%rd101, %rd50, 3;
	add.s64 	%rd102, %rd40, %rd101;
	ld.global.u64 	%rd103, [%rd102];
	mul.lo.s64 	%rd104, %rd103, %rd123;
	cvt.u32.u64 	%r51, %rd104;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd105, %r55;
	setp.lt.u64 	%p15, %rd105, %rd50;
	@%p15 bra 	$L__BB21_27;

$L__BB21_31:
	mul.wide.u32 	%rd106, %r56, 8;
	add.s64 	%rd107, %rd2, %rd106;
	ld.global.f64 	%fd2, [%rd107];
	shl.b64 	%rd108, %rd111, 3;
	add.s64 	%rd109, %rd1, %rd108;
	st.global.f64 	[%rd109], %fd2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd111, %r53;
	setp.lt.u64 	%p16, %rd111, %rd49;
	@%p16 bra 	$L__BB21_17;

$L__BB21_32:
	ret;

}
	// .globl	is_u8_u8
.visible .entry is_u8_u8(
	.param .u64 is_u8_u8_param_0,
	.param .u64 is_u8_u8_param_1,
	.param .u64 is_u8_u8_param_2,
	.param .u64 is_u8_u8_param_3,
	.param .u64 is_u8_u8_param_4,
	.param .u64 is_u8_u8_param_5,
	.param .u64 is_u8_u8_param_6,
	.param .u64 is_u8_u8_param_7,
	.param .u64 is_u8_u8_param_8,
	.param .u64 is_u8_u8_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<121>;


	ld.param.u64 	%rd49, [is_u8_u8_param_0];
	ld.param.u64 	%rd50, [is_u8_u8_param_1];
	ld.param.u64 	%rd54, [is_u8_u8_param_2];
	ld.param.u64 	%rd55, [is_u8_u8_param_3];
	ld.param.u64 	%rd56, [is_u8_u8_param_4];
	ld.param.u64 	%rd57, [is_u8_u8_param_5];
	ld.param.u64 	%rd51, [is_u8_u8_param_7];
	ld.param.u64 	%rd52, [is_u8_u8_param_8];
	ld.param.u64 	%rd53, [is_u8_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB22_4;

	mov.u64 	%rd107, 1;
	mov.u32 	%r52, 0;

$L__BB22_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd107, %rd64;
	mov.u16 	%rs7, 0;
	@%p2 bra 	$L__BB22_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd107, %rd67, %rd107;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs7, %rs2;
	@%p3 bra 	$L__BB22_2;

$L__BB22_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd108, %r53;
	setp.ge.u64 	%p4, %rd108, %rd49;
	@%p4 bra 	$L__BB22_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs7, 0;
	@%p5 bra 	$L__BB22_16;

$L__BB22_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB22_8;

	div.u64 	%rd109, %rd108, %rd9;
	bra.uni 	$L__BB22_9;

$L__BB22_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd108;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd109, %r22;

$L__BB22_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB22_11;

	div.u64 	%rd110, %rd108, %rd53;
	mul.lo.s64 	%rd71, %rd110, %rd53;
	sub.s64 	%rd111, %rd108, %rd71;
	bra.uni 	$L__BB22_12;

$L__BB22_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd108;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd110, %r25;
	cvt.u64.u32 	%rd111, %r27;

$L__BB22_12:
	or.b64  	%rd72, %rd110, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB22_14;

	rem.u64 	%rd112, %rd110, %rd52;
	bra.uni 	$L__BB22_15;

$L__BB22_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd110;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd112, %r30;

$L__BB22_15:
	add.s64 	%rd74, %rd3, %rd112;
	ld.global.u8 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd109, %rd51;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd53;
	add.s64 	%rd79, %rd78, %rd111;
	and.b64  	%rd80, %rd79, 4294967295;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.u8 	%rs5, [%rd81];
	add.s64 	%rd82, %rd1, %rd108;
	st.global.u8 	[%rd82], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd108, %r53;
	setp.lt.u64 	%p9, %rd108, %rd49;
	@%p9 bra 	$L__BB22_6;
	bra.uni 	$L__BB22_32;

$L__BB22_16:
	and.b64  	%rd83, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB22_17:
	setp.eq.s64 	%p10, %rd83, 0;
	@%p10 bra 	$L__BB22_19;

	div.u64 	%rd114, %rd108, %rd9;
	bra.uni 	$L__BB22_20;

$L__BB22_19:
	cvt.u32.u64 	%r32, %rd108;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd114, %r33;

$L__BB22_20:
	and.b64  	%rd84, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd84, 0;
	@%p11 bra 	$L__BB22_22;

	div.u64 	%rd115, %rd108, %rd53;
	mul.lo.s64 	%rd85, %rd115, %rd53;
	sub.s64 	%rd116, %rd108, %rd85;
	bra.uni 	$L__BB22_23;

$L__BB22_22:
	cvt.u32.u64 	%r35, %rd108;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd115, %r36;
	cvt.u64.u32 	%rd116, %r38;

$L__BB22_23:
	or.b64  	%rd86, %rd115, %rd52;
	and.b64  	%rd87, %rd86, -4294967296;
	setp.eq.s64 	%p12, %rd87, 0;
	@%p12 bra 	$L__BB22_25;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB22_26;

$L__BB22_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd115;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd117, %r41;

$L__BB22_26:
	add.s64 	%rd88, %rd3, %rd117;
	ld.global.u8 	%rd89, [%rd88];
	mul.lo.s64 	%rd90, %rd114, %rd51;
	add.s64 	%rd91, %rd90, %rd89;
	mul.lo.s64 	%rd92, %rd91, %rd53;
	add.s64 	%rd118, %rd92, %rd116;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB22_31;

$L__BB22_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd93, %r45;
	add.s64 	%rd94, %rd93, %rd50;
	and.b64  	%rd39, %rd118, 4294967295;
	shl.b64 	%rd95, %rd94, 3;
	and.b64  	%rd96, %rd95, 34359738360;
	add.s64 	%rd40, %rd4, %rd96;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd97, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd97, 0;
	@%p14 bra 	$L__BB22_29;

	div.u64 	%rd118, %rd39, %rd41;
	mul.lo.s64 	%rd98, %rd118, %rd41;
	sub.s64 	%rd120, %rd39, %rd98;
	bra.uni 	$L__BB22_30;

$L__BB22_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd118, %r48;
	cvt.u64.u32 	%rd120, %r50;

$L__BB22_30:
	shl.b64 	%rd99, %rd50, 3;
	add.s64 	%rd100, %rd40, %rd99;
	ld.global.u64 	%rd101, [%rd100];
	mul.lo.s64 	%rd102, %rd101, %rd120;
	cvt.u32.u64 	%r51, %rd102;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd103, %r55;
	setp.lt.u64 	%p15, %rd103, %rd50;
	@%p15 bra 	$L__BB22_27;

$L__BB22_31:
	cvt.u64.u32 	%rd104, %r56;
	add.s64 	%rd105, %rd2, %rd104;
	ld.global.u8 	%rs6, [%rd105];
	add.s64 	%rd106, %rd1, %rd108;
	st.global.u8 	[%rd106], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd108, %r53;
	setp.lt.u64 	%p16, %rd108, %rd49;
	@%p16 bra 	$L__BB22_17;

$L__BB22_32:
	ret;

}
	// .globl	is_u8_u32
.visible .entry is_u8_u32(
	.param .u64 is_u8_u32_param_0,
	.param .u64 is_u8_u32_param_1,
	.param .u64 is_u8_u32_param_2,
	.param .u64 is_u8_u32_param_3,
	.param .u64 is_u8_u32_param_4,
	.param .u64 is_u8_u32_param_5,
	.param .u64 is_u8_u32_param_6,
	.param .u64 is_u8_u32_param_7,
	.param .u64 is_u8_u32_param_8,
	.param .u64 is_u8_u32_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<124>;


	ld.param.u64 	%rd49, [is_u8_u32_param_0];
	ld.param.u64 	%rd50, [is_u8_u32_param_1];
	ld.param.u64 	%rd54, [is_u8_u32_param_2];
	ld.param.u64 	%rd55, [is_u8_u32_param_3];
	ld.param.u64 	%rd56, [is_u8_u32_param_4];
	ld.param.u64 	%rd57, [is_u8_u32_param_5];
	ld.param.u64 	%rd51, [is_u8_u32_param_7];
	ld.param.u64 	%rd52, [is_u8_u32_param_8];
	ld.param.u64 	%rd53, [is_u8_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB23_4;

	mov.u64 	%rd110, 1;
	mov.u32 	%r54, 0;

$L__BB23_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd110, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB23_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd110, %rd67, %rd110;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd68, %r54;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB23_2;

$L__BB23_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd111, %r55;
	setp.ge.u64 	%p4, %rd111, %rd49;
	@%p4 bra 	$L__BB23_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB23_16;

$L__BB23_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB23_8;

	div.u64 	%rd112, %rd111, %rd9;
	bra.uni 	$L__BB23_9;

$L__BB23_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd111;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd112, %r22;

$L__BB23_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB23_11;

	div.u64 	%rd113, %rd111, %rd53;
	mul.lo.s64 	%rd71, %rd113, %rd53;
	sub.s64 	%rd114, %rd111, %rd71;
	bra.uni 	$L__BB23_12;

$L__BB23_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd111;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd113, %r25;
	cvt.u64.u32 	%rd114, %r27;

$L__BB23_12:
	or.b64  	%rd72, %rd113, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB23_14;

	rem.u64 	%rd115, %rd113, %rd52;
	bra.uni 	$L__BB23_15;

$L__BB23_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd113;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd115, %r30;

$L__BB23_15:
	add.s64 	%rd74, %rd3, %rd115;
	ld.global.u8 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd112, %rd51;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd53;
	add.s64 	%rd79, %rd78, %rd114;
	shl.b64 	%rd80, %rd79, 2;
	and.b64  	%rd81, %rd80, 17179869180;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u32 	%r31, [%rd82];
	shl.b64 	%rd83, %rd111, 2;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.u32 	[%rd84], %r31;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd111, %r55;
	setp.lt.u64 	%p9, %rd111, %rd49;
	@%p9 bra 	$L__BB23_6;
	bra.uni 	$L__BB23_32;

$L__BB23_16:
	and.b64  	%rd85, %rd9, -4294967296;
	cvt.u32.u64 	%r32, %rd9;
	cvt.u32.u64 	%r35, %rd53;

$L__BB23_17:
	setp.eq.s64 	%p10, %rd85, 0;
	@%p10 bra 	$L__BB23_19;

	div.u64 	%rd117, %rd111, %rd9;
	bra.uni 	$L__BB23_20;

$L__BB23_19:
	cvt.u32.u64 	%r33, %rd111;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd117, %r34;

$L__BB23_20:
	and.b64  	%rd86, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd86, 0;
	@%p11 bra 	$L__BB23_22;

	div.u64 	%rd118, %rd111, %rd53;
	mul.lo.s64 	%rd87, %rd118, %rd53;
	sub.s64 	%rd119, %rd111, %rd87;
	bra.uni 	$L__BB23_23;

$L__BB23_22:
	cvt.u32.u64 	%r36, %rd111;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd118, %r37;
	cvt.u64.u32 	%rd119, %r39;

$L__BB23_23:
	or.b64  	%rd88, %rd118, %rd52;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p12, %rd89, 0;
	@%p12 bra 	$L__BB23_25;

	rem.u64 	%rd120, %rd118, %rd52;
	bra.uni 	$L__BB23_26;

$L__BB23_25:
	cvt.u32.u64 	%r40, %rd52;
	cvt.u32.u64 	%r41, %rd118;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd120, %r42;

$L__BB23_26:
	add.s64 	%rd90, %rd3, %rd120;
	ld.global.u8 	%rd91, [%rd90];
	mul.lo.s64 	%rd92, %rd117, %rd51;
	add.s64 	%rd93, %rd92, %rd91;
	mul.lo.s64 	%rd94, %rd93, %rd53;
	add.s64 	%rd121, %rd94, %rd119;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB23_31;

$L__BB23_27:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd95, %r46;
	add.s64 	%rd96, %rd95, %rd50;
	and.b64  	%rd39, %rd121, 4294967295;
	shl.b64 	%rd97, %rd96, 3;
	and.b64  	%rd98, %rd97, 34359738360;
	add.s64 	%rd40, %rd4, %rd98;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd99, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd99, 0;
	@%p14 bra 	$L__BB23_29;

	div.u64 	%rd121, %rd39, %rd41;
	mul.lo.s64 	%rd100, %rd121, %rd41;
	sub.s64 	%rd123, %rd39, %rd100;
	bra.uni 	$L__BB23_30;

$L__BB23_29:
	cvt.u32.u64 	%r47, %rd41;
	cvt.u32.u64 	%r48, %rd39;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd121, %r49;
	cvt.u64.u32 	%rd123, %r51;

$L__BB23_30:
	shl.b64 	%rd101, %rd50, 3;
	add.s64 	%rd102, %rd40, %rd101;
	ld.global.u64 	%rd103, [%rd102];
	mul.lo.s64 	%rd104, %rd103, %rd123;
	cvt.u32.u64 	%r52, %rd104;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd105, %r57;
	setp.lt.u64 	%p15, %rd105, %rd50;
	@%p15 bra 	$L__BB23_27;

$L__BB23_31:
	mul.wide.u32 	%rd106, %r58, 4;
	add.s64 	%rd107, %rd2, %rd106;
	ld.global.u32 	%r53, [%rd107];
	shl.b64 	%rd108, %rd111, 2;
	add.s64 	%rd109, %rd1, %rd108;
	st.global.u32 	[%rd109], %r53;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd111, %r55;
	setp.lt.u64 	%p16, %rd111, %rd49;
	@%p16 bra 	$L__BB23_17;

$L__BB23_32:
	ret;

}
	// .globl	is_u8_i64
.visible .entry is_u8_i64(
	.param .u64 is_u8_i64_param_0,
	.param .u64 is_u8_i64_param_1,
	.param .u64 is_u8_i64_param_2,
	.param .u64 is_u8_i64_param_3,
	.param .u64 is_u8_i64_param_4,
	.param .u64 is_u8_i64_param_5,
	.param .u64 is_u8_i64_param_6,
	.param .u64 is_u8_i64_param_7,
	.param .u64 is_u8_i64_param_8,
	.param .u64 is_u8_i64_param_9
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<126>;


	ld.param.u64 	%rd49, [is_u8_i64_param_0];
	ld.param.u64 	%rd50, [is_u8_i64_param_1];
	ld.param.u64 	%rd54, [is_u8_i64_param_2];
	ld.param.u64 	%rd55, [is_u8_i64_param_3];
	ld.param.u64 	%rd56, [is_u8_i64_param_4];
	ld.param.u64 	%rd57, [is_u8_i64_param_5];
	ld.param.u64 	%rd51, [is_u8_i64_param_7];
	ld.param.u64 	%rd52, [is_u8_i64_param_8];
	ld.param.u64 	%rd53, [is_u8_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd57;
	cvta.to.global.u64 	%rd2, %rd56;
	cvta.to.global.u64 	%rd3, %rd55;
	cvta.to.global.u64 	%rd4, %rd54;
	setp.eq.s64 	%p1, %rd50, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB24_4;

	mov.u64 	%rd112, 1;
	mov.u32 	%r52, 0;

$L__BB24_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd59, %r16;
	add.s64 	%rd60, %rd59, %rd50;
	and.b64  	%rd6, %rd60, 4294967295;
	add.s64 	%rd61, %rd6, %rd50;
	shl.b64 	%rd62, %rd61, 3;
	add.s64 	%rd63, %rd4, %rd62;
	ld.global.u64 	%rd64, [%rd63];
	setp.ne.s64 	%p2, %rd112, %rd64;
	mov.u16 	%rs5, 0;
	@%p2 bra 	$L__BB24_4;

	shl.b64 	%rd65, %rd6, 3;
	add.s64 	%rd66, %rd4, %rd65;
	ld.global.u64 	%rd67, [%rd66];
	mul.lo.s64 	%rd112, %rd67, %rd112;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd68, %r52;
	setp.lt.u64 	%p3, %rd68, %rd50;
	mov.u16 	%rs5, %rs2;
	@%p3 bra 	$L__BB24_2;

$L__BB24_4:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd113, %r53;
	setp.ge.u64 	%p4, %rd113, %rd49;
	@%p4 bra 	$L__BB24_32;

	mul.lo.s64 	%rd9, %rd53, %rd52;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p5, %rs5, 0;
	@%p5 bra 	$L__BB24_16;

$L__BB24_6:
	and.b64  	%rd69, %rd9, -4294967296;
	setp.eq.s64 	%p6, %rd69, 0;
	@%p6 bra 	$L__BB24_8;

	div.u64 	%rd114, %rd113, %rd9;
	bra.uni 	$L__BB24_9;

$L__BB24_8:
	cvt.u32.u64 	%r20, %rd9;
	cvt.u32.u64 	%r21, %rd113;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd114, %r22;

$L__BB24_9:
	and.b64  	%rd70, %rd53, -4294967296;
	setp.eq.s64 	%p7, %rd70, 0;
	@%p7 bra 	$L__BB24_11;

	div.u64 	%rd115, %rd113, %rd53;
	mul.lo.s64 	%rd71, %rd115, %rd53;
	sub.s64 	%rd116, %rd113, %rd71;
	bra.uni 	$L__BB24_12;

$L__BB24_11:
	cvt.u32.u64 	%r23, %rd53;
	cvt.u32.u64 	%r24, %rd113;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd115, %r25;
	cvt.u64.u32 	%rd116, %r27;

$L__BB24_12:
	or.b64  	%rd72, %rd115, %rd52;
	and.b64  	%rd73, %rd72, -4294967296;
	setp.eq.s64 	%p8, %rd73, 0;
	@%p8 bra 	$L__BB24_14;

	rem.u64 	%rd117, %rd115, %rd52;
	bra.uni 	$L__BB24_15;

$L__BB24_14:
	cvt.u32.u64 	%r28, %rd52;
	cvt.u32.u64 	%r29, %rd115;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd117, %r30;

$L__BB24_15:
	add.s64 	%rd74, %rd3, %rd117;
	ld.global.u8 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd114, %rd51;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd53;
	add.s64 	%rd79, %rd78, %rd116;
	shl.b64 	%rd80, %rd79, 3;
	and.b64  	%rd81, %rd80, 34359738360;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u64 	%rd83, [%rd82];
	shl.b64 	%rd84, %rd113, 3;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.u64 	[%rd85], %rd83;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p9, %rd113, %rd49;
	@%p9 bra 	$L__BB24_6;
	bra.uni 	$L__BB24_32;

$L__BB24_16:
	and.b64  	%rd86, %rd9, -4294967296;
	cvt.u32.u64 	%r31, %rd9;
	cvt.u32.u64 	%r34, %rd53;

$L__BB24_17:
	setp.eq.s64 	%p10, %rd86, 0;
	@%p10 bra 	$L__BB24_19;

	div.u64 	%rd119, %rd113, %rd9;
	bra.uni 	$L__BB24_20;

$L__BB24_19:
	cvt.u32.u64 	%r32, %rd113;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd119, %r33;

$L__BB24_20:
	and.b64  	%rd87, %rd53, -4294967296;
	setp.eq.s64 	%p11, %rd87, 0;
	@%p11 bra 	$L__BB24_22;

	div.u64 	%rd120, %rd113, %rd53;
	mul.lo.s64 	%rd88, %rd120, %rd53;
	sub.s64 	%rd121, %rd113, %rd88;
	bra.uni 	$L__BB24_23;

$L__BB24_22:
	cvt.u32.u64 	%r35, %rd113;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd120, %r36;
	cvt.u64.u32 	%rd121, %r38;

$L__BB24_23:
	or.b64  	%rd89, %rd120, %rd52;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p12, %rd90, 0;
	@%p12 bra 	$L__BB24_25;

	rem.u64 	%rd122, %rd120, %rd52;
	bra.uni 	$L__BB24_26;

$L__BB24_25:
	cvt.u32.u64 	%r39, %rd52;
	cvt.u32.u64 	%r40, %rd120;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd122, %r41;

$L__BB24_26:
	add.s64 	%rd91, %rd3, %rd122;
	ld.global.u8 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd119, %rd51;
	add.s64 	%rd94, %rd93, %rd92;
	mul.lo.s64 	%rd95, %rd94, %rd53;
	add.s64 	%rd123, %rd95, %rd121;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB24_31;

$L__BB24_27:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd96, %r45;
	add.s64 	%rd97, %rd96, %rd50;
	and.b64  	%rd39, %rd123, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd40, %rd4, %rd99;
	ld.global.u64 	%rd41, [%rd40];
	and.b64  	%rd100, %rd41, -4294967296;
	setp.eq.s64 	%p14, %rd100, 0;
	@%p14 bra 	$L__BB24_29;

	div.u64 	%rd123, %rd39, %rd41;
	mul.lo.s64 	%rd101, %rd123, %rd41;
	sub.s64 	%rd125, %rd39, %rd101;
	bra.uni 	$L__BB24_30;

$L__BB24_29:
	cvt.u32.u64 	%r46, %rd41;
	cvt.u32.u64 	%r47, %rd39;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd123, %r48;
	cvt.u64.u32 	%rd125, %r50;

$L__BB24_30:
	shl.b64 	%rd102, %rd50, 3;
	add.s64 	%rd103, %rd40, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd125;
	cvt.u32.u64 	%r51, %rd105;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd106, %r55;
	setp.lt.u64 	%p15, %rd106, %rd50;
	@%p15 bra 	$L__BB24_27;

$L__BB24_31:
	mul.wide.u32 	%rd107, %r56, 8;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.u64 	%rd109, [%rd108];
	shl.b64 	%rd110, %rd113, 3;
	add.s64 	%rd111, %rd1, %rd110;
	st.global.u64 	[%rd111], %rd109;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd113, %r53;
	setp.lt.u64 	%p16, %rd113, %rd49;
	@%p16 bra 	$L__BB24_17;

$L__BB24_32:
	ret;

}
	// .globl	gather_i64_f32
.visible .entry gather_i64_f32(
	.param .u64 gather_i64_f32_param_0,
	.param .u64 gather_i64_f32_param_1,
	.param .u64 gather_i64_f32_param_2,
	.param .u64 gather_i64_f32_param_3,
	.param .u64 gather_i64_f32_param_4,
	.param .u64 gather_i64_f32_param_5,
	.param .u64 gather_i64_f32_param_6,
	.param .u64 gather_i64_f32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_f32_param_0];
	ld.param.u64 	%rd16, [gather_i64_f32_param_1];
	ld.param.u64 	%rd17, [gather_i64_f32_param_2];
	ld.param.u64 	%rd18, [gather_i64_f32_param_3];
	ld.param.u64 	%rd19, [gather_i64_f32_param_5];
	ld.param.u64 	%rd20, [gather_i64_f32_param_6];
	ld.param.u64 	%rd21, [gather_i64_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB25_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB25_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB25_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB25_5;

$L__BB25_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB25_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB25_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB25_8;

$L__BB25_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB25_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f32 	%f1, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f32 	[%rd33], %f1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB25_2;

$L__BB25_9:
	ret;

}
	// .globl	gather_i64_f64
.visible .entry gather_i64_f64(
	.param .u64 gather_i64_f64_param_0,
	.param .u64 gather_i64_f64_param_1,
	.param .u64 gather_i64_f64_param_2,
	.param .u64 gather_i64_f64_param_3,
	.param .u64 gather_i64_f64_param_4,
	.param .u64 gather_i64_f64_param_5,
	.param .u64 gather_i64_f64_param_6,
	.param .u64 gather_i64_f64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_f64_param_0];
	ld.param.u64 	%rd16, [gather_i64_f64_param_1];
	ld.param.u64 	%rd17, [gather_i64_f64_param_2];
	ld.param.u64 	%rd18, [gather_i64_f64_param_3];
	ld.param.u64 	%rd19, [gather_i64_f64_param_5];
	ld.param.u64 	%rd20, [gather_i64_f64_param_6];
	ld.param.u64 	%rd21, [gather_i64_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB26_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB26_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB26_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB26_5;

$L__BB26_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB26_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB26_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB26_8;

$L__BB26_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB26_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f64 	%fd1, [%rd31];
	add.s64 	%rd33, %rd5, %rd23;
	st.global.f64 	[%rd33], %fd1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB26_2;

$L__BB26_9:
	ret;

}
	// .globl	gather_i64_u8
.visible .entry gather_i64_u8(
	.param .u64 gather_i64_u8_param_0,
	.param .u64 gather_i64_u8_param_1,
	.param .u64 gather_i64_u8_param_2,
	.param .u64 gather_i64_u8_param_3,
	.param .u64 gather_i64_u8_param_4,
	.param .u64 gather_i64_u8_param_5,
	.param .u64 gather_i64_u8_param_6,
	.param .u64 gather_i64_u8_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd15, [gather_i64_u8_param_0];
	ld.param.u64 	%rd16, [gather_i64_u8_param_1];
	ld.param.u64 	%rd17, [gather_i64_u8_param_2];
	ld.param.u64 	%rd18, [gather_i64_u8_param_3];
	ld.param.u64 	%rd19, [gather_i64_u8_param_5];
	ld.param.u64 	%rd20, [gather_i64_u8_param_6];
	ld.param.u64 	%rd21, [gather_i64_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd32, %r15;
	setp.ge.u64 	%p1, %rd32, %rd15;
	@%p1 bra 	$L__BB27_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB27_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB27_4;

	rem.u64 	%rd33, %rd32, %rd21;
	bra.uni 	$L__BB27_5;

$L__BB27_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd32;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd33, %r11;

$L__BB27_5:
	shl.b64 	%rd23, %rd32, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB27_7;

	div.u64 	%rd34, %rd32, %rd2;
	bra.uni 	$L__BB27_8;

$L__BB27_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd32;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd34, %r14;

$L__BB27_8:
	mul.lo.s64 	%rd26, %rd34, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd33;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.u8 	%rs1, [%rd30];
	add.s64 	%rd31, %rd5, %rd32;
	st.global.u8 	[%rd31], %rs1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd32, %r15;
	setp.lt.u64 	%p4, %rd32, %rd15;
	@%p4 bra 	$L__BB27_2;

$L__BB27_9:
	ret;

}
	// .globl	gather_i64_u32
.visible .entry gather_i64_u32(
	.param .u64 gather_i64_u32_param_0,
	.param .u64 gather_i64_u32_param_1,
	.param .u64 gather_i64_u32_param_2,
	.param .u64 gather_i64_u32_param_3,
	.param .u64 gather_i64_u32_param_4,
	.param .u64 gather_i64_u32_param_5,
	.param .u64 gather_i64_u32_param_6,
	.param .u64 gather_i64_u32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_u32_param_0];
	ld.param.u64 	%rd16, [gather_i64_u32_param_1];
	ld.param.u64 	%rd17, [gather_i64_u32_param_2];
	ld.param.u64 	%rd18, [gather_i64_u32_param_3];
	ld.param.u64 	%rd19, [gather_i64_u32_param_5];
	ld.param.u64 	%rd20, [gather_i64_u32_param_6];
	ld.param.u64 	%rd21, [gather_i64_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r16, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB28_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB28_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB28_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB28_5;

$L__BB28_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB28_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB28_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB28_8;

$L__BB28_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB28_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u32 	%r15, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u32 	[%rd33], %r15;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB28_2;

$L__BB28_9:
	ret;

}
	// .globl	gather_i64_i64
.visible .entry gather_i64_i64(
	.param .u64 gather_i64_i64_param_0,
	.param .u64 gather_i64_i64_param_1,
	.param .u64 gather_i64_i64_param_2,
	.param .u64 gather_i64_i64_param_3,
	.param .u64 gather_i64_i64_param_4,
	.param .u64 gather_i64_i64_param_5,
	.param .u64 gather_i64_i64_param_6,
	.param .u64 gather_i64_i64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd15, [gather_i64_i64_param_0];
	ld.param.u64 	%rd16, [gather_i64_i64_param_1];
	ld.param.u64 	%rd17, [gather_i64_i64_param_2];
	ld.param.u64 	%rd18, [gather_i64_i64_param_3];
	ld.param.u64 	%rd19, [gather_i64_i64_param_5];
	ld.param.u64 	%rd20, [gather_i64_i64_param_6];
	ld.param.u64 	%rd21, [gather_i64_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd35, %r15;
	setp.ge.u64 	%p1, %rd35, %rd15;
	@%p1 bra 	$L__BB29_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB29_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB29_4;

	rem.u64 	%rd36, %rd35, %rd21;
	bra.uni 	$L__BB29_5;

$L__BB29_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd35;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd36, %r11;

$L__BB29_5:
	shl.b64 	%rd23, %rd35, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB29_7;

	div.u64 	%rd37, %rd35, %rd2;
	bra.uni 	$L__BB29_8;

$L__BB29_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd35;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd37, %r14;

$L__BB29_8:
	mul.lo.s64 	%rd26, %rd37, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd36;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u64 	%rd32, [%rd31];
	add.s64 	%rd34, %rd5, %rd23;
	st.global.u64 	[%rd34], %rd32;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd35, %r15;
	setp.lt.u64 	%p4, %rd35, %rd15;
	@%p4 bra 	$L__BB29_2;

$L__BB29_9:
	ret;

}
	// .globl	gather_u32_f32
.visible .entry gather_u32_f32(
	.param .u64 gather_u32_f32_param_0,
	.param .u64 gather_u32_f32_param_1,
	.param .u64 gather_u32_f32_param_2,
	.param .u64 gather_u32_f32_param_3,
	.param .u64 gather_u32_f32_param_4,
	.param .u64 gather_u32_f32_param_5,
	.param .u64 gather_u32_f32_param_6,
	.param .u64 gather_u32_f32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_f32_param_0];
	ld.param.u64 	%rd15, [gather_u32_f32_param_1];
	ld.param.u64 	%rd16, [gather_u32_f32_param_2];
	ld.param.u64 	%rd17, [gather_u32_f32_param_3];
	ld.param.u64 	%rd18, [gather_u32_f32_param_5];
	ld.param.u64 	%rd19, [gather_u32_f32_param_6];
	ld.param.u64 	%rd20, [gather_u32_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB30_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB30_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB30_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB30_5;

$L__BB30_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB30_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB30_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB30_8;

$L__BB30_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB30_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f32 	%f1, [%rd31];
	add.s64 	%rd33, %rd5, %rd22;
	st.global.f32 	[%rd33], %f1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB30_2;

$L__BB30_9:
	ret;

}
	// .globl	gather_u32_f64
.visible .entry gather_u32_f64(
	.param .u64 gather_u32_f64_param_0,
	.param .u64 gather_u32_f64_param_1,
	.param .u64 gather_u32_f64_param_2,
	.param .u64 gather_u32_f64_param_3,
	.param .u64 gather_u32_f64_param_4,
	.param .u64 gather_u32_f64_param_5,
	.param .u64 gather_u32_f64_param_6,
	.param .u64 gather_u32_f64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<17>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_f64_param_0];
	ld.param.u64 	%rd15, [gather_u32_f64_param_1];
	ld.param.u64 	%rd16, [gather_u32_f64_param_2];
	ld.param.u64 	%rd17, [gather_u32_f64_param_3];
	ld.param.u64 	%rd18, [gather_u32_f64_param_5];
	ld.param.u64 	%rd19, [gather_u32_f64_param_6];
	ld.param.u64 	%rd20, [gather_u32_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB31_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB31_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB31_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB31_5;

$L__BB31_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB31_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB31_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB31_8;

$L__BB31_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB31_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f64 	%fd1, [%rd31];
	shl.b64 	%rd32, %rd34, 3;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f64 	[%rd33], %fd1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB31_2;

$L__BB31_9:
	ret;

}
	// .globl	gather_u32_u8
.visible .entry gather_u32_u8(
	.param .u64 gather_u32_u8_param_0,
	.param .u64 gather_u32_u8_param_1,
	.param .u64 gather_u32_u8_param_2,
	.param .u64 gather_u32_u8_param_3,
	.param .u64 gather_u32_u8_param_4,
	.param .u64 gather_u32_u8_param_5,
	.param .u64 gather_u32_u8_param_6,
	.param .u64 gather_u32_u8_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd14, [gather_u32_u8_param_0];
	ld.param.u64 	%rd15, [gather_u32_u8_param_1];
	ld.param.u64 	%rd16, [gather_u32_u8_param_2];
	ld.param.u64 	%rd17, [gather_u32_u8_param_3];
	ld.param.u64 	%rd18, [gather_u32_u8_param_5];
	ld.param.u64 	%rd19, [gather_u32_u8_param_6];
	ld.param.u64 	%rd20, [gather_u32_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd32, %r16;
	setp.ge.u64 	%p1, %rd32, %rd14;
	@%p1 bra 	$L__BB32_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB32_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB32_4;

	rem.u64 	%rd33, %rd32, %rd20;
	bra.uni 	$L__BB32_5;

$L__BB32_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd32;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd33, %r12;

$L__BB32_5:
	shl.b64 	%rd22, %rd32, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB32_7;

	div.u64 	%rd34, %rd32, %rd2;
	bra.uni 	$L__BB32_8;

$L__BB32_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd32;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd34, %r15;

$L__BB32_8:
	mul.lo.s64 	%rd25, %rd34, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd33;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.u8 	%rs1, [%rd30];
	add.s64 	%rd31, %rd5, %rd32;
	st.global.u8 	[%rd31], %rs1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd32, %r16;
	setp.lt.u64 	%p4, %rd32, %rd14;
	@%p4 bra 	$L__BB32_2;

$L__BB32_9:
	ret;

}
	// .globl	gather_u32_i64
.visible .entry gather_u32_i64(
	.param .u64 gather_u32_i64_param_0,
	.param .u64 gather_u32_i64_param_1,
	.param .u64 gather_u32_i64_param_2,
	.param .u64 gather_u32_i64_param_3,
	.param .u64 gather_u32_i64_param_4,
	.param .u64 gather_u32_i64_param_5,
	.param .u64 gather_u32_i64_param_6,
	.param .u64 gather_u32_i64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd14, [gather_u32_i64_param_0];
	ld.param.u64 	%rd15, [gather_u32_i64_param_1];
	ld.param.u64 	%rd16, [gather_u32_i64_param_2];
	ld.param.u64 	%rd17, [gather_u32_i64_param_3];
	ld.param.u64 	%rd18, [gather_u32_i64_param_5];
	ld.param.u64 	%rd19, [gather_u32_i64_param_6];
	ld.param.u64 	%rd20, [gather_u32_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd35, %r16;
	setp.ge.u64 	%p1, %rd35, %rd14;
	@%p1 bra 	$L__BB33_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB33_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB33_4;

	rem.u64 	%rd36, %rd35, %rd20;
	bra.uni 	$L__BB33_5;

$L__BB33_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd35;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd36, %r12;

$L__BB33_5:
	shl.b64 	%rd22, %rd35, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB33_7;

	div.u64 	%rd37, %rd35, %rd2;
	bra.uni 	$L__BB33_8;

$L__BB33_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd35;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd37, %r15;

$L__BB33_8:
	mul.lo.s64 	%rd25, %rd37, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd36;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u64 	%rd32, [%rd31];
	shl.b64 	%rd33, %rd35, 3;
	add.s64 	%rd34, %rd5, %rd33;
	st.global.u64 	[%rd34], %rd32;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd35, %r16;
	setp.lt.u64 	%p4, %rd35, %rd14;
	@%p4 bra 	$L__BB33_2;

$L__BB33_9:
	ret;

}
	// .globl	gather_u32_u32
.visible .entry gather_u32_u32(
	.param .u64 gather_u32_u32_param_0,
	.param .u64 gather_u32_u32_param_1,
	.param .u64 gather_u32_u32_param_2,
	.param .u64 gather_u32_u32_param_3,
	.param .u64 gather_u32_u32_param_4,
	.param .u64 gather_u32_u32_param_5,
	.param .u64 gather_u32_u32_param_6,
	.param .u64 gather_u32_u32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_u32_param_0];
	ld.param.u64 	%rd15, [gather_u32_u32_param_1];
	ld.param.u64 	%rd16, [gather_u32_u32_param_2];
	ld.param.u64 	%rd17, [gather_u32_u32_param_3];
	ld.param.u64 	%rd18, [gather_u32_u32_param_5];
	ld.param.u64 	%rd19, [gather_u32_u32_param_6];
	ld.param.u64 	%rd20, [gather_u32_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r17, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r17;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB34_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB34_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB34_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB34_5;

$L__BB34_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB34_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB34_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB34_8;

$L__BB34_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB34_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u32 	%r16, [%rd31];
	add.s64 	%rd33, %rd5, %rd22;
	st.global.u32 	[%rd33], %r16;
	add.s32 	%r17, %r17, %r3;
	cvt.u64.u32 	%rd34, %r17;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB34_2;

$L__BB34_9:
	ret;

}
	// .globl	gather_u8_f32
.visible .entry gather_u8_f32(
	.param .u64 gather_u8_f32_param_0,
	.param .u64 gather_u8_f32_param_1,
	.param .u64 gather_u8_f32_param_2,
	.param .u64 gather_u8_f32_param_3,
	.param .u64 gather_u8_f32_param_4,
	.param .u64 gather_u8_f32_param_5,
	.param .u64 gather_u8_f32_param_6,
	.param .u64 gather_u8_f32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_f32_param_0];
	ld.param.u64 	%rd15, [gather_u8_f32_param_1];
	ld.param.u64 	%rd16, [gather_u8_f32_param_2];
	ld.param.u64 	%rd17, [gather_u8_f32_param_3];
	ld.param.u64 	%rd18, [gather_u8_f32_param_5];
	ld.param.u64 	%rd19, [gather_u8_f32_param_6];
	ld.param.u64 	%rd20, [gather_u8_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB35_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB35_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB35_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB35_5;

$L__BB35_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB35_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB35_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB35_8;

$L__BB35_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB35_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f32 	%f1, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f32 	[%rd33], %f1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB35_2;

$L__BB35_9:
	ret;

}
	// .globl	gather_u8_f64
.visible .entry gather_u8_f64(
	.param .u64 gather_u8_f64_param_0,
	.param .u64 gather_u8_f64_param_1,
	.param .u64 gather_u8_f64_param_2,
	.param .u64 gather_u8_f64_param_3,
	.param .u64 gather_u8_f64_param_4,
	.param .u64 gather_u8_f64_param_5,
	.param .u64 gather_u8_f64_param_6,
	.param .u64 gather_u8_f64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_f64_param_0];
	ld.param.u64 	%rd15, [gather_u8_f64_param_1];
	ld.param.u64 	%rd16, [gather_u8_f64_param_2];
	ld.param.u64 	%rd17, [gather_u8_f64_param_3];
	ld.param.u64 	%rd18, [gather_u8_f64_param_5];
	ld.param.u64 	%rd19, [gather_u8_f64_param_6];
	ld.param.u64 	%rd20, [gather_u8_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB36_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB36_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB36_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB36_5;

$L__BB36_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB36_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB36_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB36_8;

$L__BB36_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB36_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f64 	%fd1, [%rd31];
	shl.b64 	%rd32, %rd34, 3;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f64 	[%rd33], %fd1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB36_2;

$L__BB36_9:
	ret;

}
	// .globl	gather_u8_u8
.visible .entry gather_u8_u8(
	.param .u64 gather_u8_u8_param_0,
	.param .u64 gather_u8_u8_param_1,
	.param .u64 gather_u8_u8_param_2,
	.param .u64 gather_u8_u8_param_3,
	.param .u64 gather_u8_u8_param_4,
	.param .u64 gather_u8_u8_param_5,
	.param .u64 gather_u8_u8_param_6,
	.param .u64 gather_u8_u8_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd14, [gather_u8_u8_param_0];
	ld.param.u64 	%rd15, [gather_u8_u8_param_1];
	ld.param.u64 	%rd16, [gather_u8_u8_param_2];
	ld.param.u64 	%rd17, [gather_u8_u8_param_3];
	ld.param.u64 	%rd18, [gather_u8_u8_param_5];
	ld.param.u64 	%rd19, [gather_u8_u8_param_6];
	ld.param.u64 	%rd20, [gather_u8_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd32, %r15;
	setp.ge.u64 	%p1, %rd32, %rd14;
	@%p1 bra 	$L__BB37_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB37_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB37_4;

	rem.u64 	%rd33, %rd32, %rd20;
	bra.uni 	$L__BB37_5;

$L__BB37_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd32;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd33, %r11;

$L__BB37_5:
	add.s64 	%rd22, %rd3, %rd32;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB37_7;

	div.u64 	%rd34, %rd32, %rd2;
	bra.uni 	$L__BB37_8;

$L__BB37_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd32;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd34, %r14;

$L__BB37_8:
	mul.lo.s64 	%rd24, %rd34, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd33;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.u8 	%rs2, [%rd30];
	add.s64 	%rd31, %rd5, %rd32;
	st.global.u8 	[%rd31], %rs2;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd32, %r15;
	setp.lt.u64 	%p4, %rd32, %rd14;
	@%p4 bra 	$L__BB37_2;

$L__BB37_9:
	ret;

}
	// .globl	gather_u8_u32
.visible .entry gather_u8_u32(
	.param .u64 gather_u8_u32_param_0,
	.param .u64 gather_u8_u32_param_1,
	.param .u64 gather_u8_u32_param_2,
	.param .u64 gather_u8_u32_param_3,
	.param .u64 gather_u8_u32_param_4,
	.param .u64 gather_u8_u32_param_5,
	.param .u64 gather_u8_u32_param_6,
	.param .u64 gather_u8_u32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_u32_param_0];
	ld.param.u64 	%rd15, [gather_u8_u32_param_1];
	ld.param.u64 	%rd16, [gather_u8_u32_param_2];
	ld.param.u64 	%rd17, [gather_u8_u32_param_3];
	ld.param.u64 	%rd18, [gather_u8_u32_param_5];
	ld.param.u64 	%rd19, [gather_u8_u32_param_6];
	ld.param.u64 	%rd20, [gather_u8_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r16, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB38_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB38_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB38_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB38_5;

$L__BB38_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB38_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB38_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB38_8;

$L__BB38_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB38_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u32 	%r15, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u32 	[%rd33], %r15;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB38_2;

$L__BB38_9:
	ret;

}
	// .globl	gather_u8_i64
.visible .entry gather_u8_i64(
	.param .u64 gather_u8_i64_param_0,
	.param .u64 gather_u8_i64_param_1,
	.param .u64 gather_u8_i64_param_2,
	.param .u64 gather_u8_i64_param_3,
	.param .u64 gather_u8_i64_param_4,
	.param .u64 gather_u8_i64_param_5,
	.param .u64 gather_u8_i64_param_6,
	.param .u64 gather_u8_i64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd14, [gather_u8_i64_param_0];
	ld.param.u64 	%rd15, [gather_u8_i64_param_1];
	ld.param.u64 	%rd16, [gather_u8_i64_param_2];
	ld.param.u64 	%rd17, [gather_u8_i64_param_3];
	ld.param.u64 	%rd18, [gather_u8_i64_param_5];
	ld.param.u64 	%rd19, [gather_u8_i64_param_6];
	ld.param.u64 	%rd20, [gather_u8_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd35, %r15;
	setp.ge.u64 	%p1, %rd35, %rd14;
	@%p1 bra 	$L__BB39_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB39_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB39_4;

	rem.u64 	%rd36, %rd35, %rd20;
	bra.uni 	$L__BB39_5;

$L__BB39_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd35;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd36, %r11;

$L__BB39_5:
	add.s64 	%rd22, %rd3, %rd35;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB39_7;

	div.u64 	%rd37, %rd35, %rd2;
	bra.uni 	$L__BB39_8;

$L__BB39_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd35;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd37, %r14;

$L__BB39_8:
	mul.lo.s64 	%rd24, %rd37, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd36;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u64 	%rd32, [%rd31];
	shl.b64 	%rd33, %rd35, 3;
	add.s64 	%rd34, %rd5, %rd33;
	st.global.u64 	[%rd34], %rd32;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd35, %r15;
	setp.lt.u64 	%p4, %rd35, %rd14;
	@%p4 bra 	$L__BB39_2;

$L__BB39_9:
	ret;

}
	// .globl	ia_i64_f32
.visible .entry ia_i64_f32(
	.param .u64 ia_i64_f32_param_0,
	.param .u64 ia_i64_f32_param_1,
	.param .u64 ia_i64_f32_param_2,
	.param .u64 ia_i64_f32_param_3,
	.param .u64 ia_i64_f32_param_4,
	.param .u64 ia_i64_f32_param_5,
	.param .u64 ia_i64_f32_param_6,
	.param .u64 ia_i64_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_i64_f32_param_0];
	ld.param.u64 	%rd19, [ia_i64_f32_param_1];
	ld.param.u64 	%rd20, [ia_i64_f32_param_2];
	ld.param.u64 	%rd21, [ia_i64_f32_param_3];
	ld.param.u64 	%rd24, [ia_i64_f32_param_4];
	ld.param.u64 	%rd22, [ia_i64_f32_param_6];
	ld.param.u64 	%rd23, [ia_i64_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB40_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB40_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB40_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB40_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB40_6;

$L__BB40_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB40_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB40_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd45, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f32 	%f1, [%rd40];
	ld.global.f32 	%f2, [%rd38];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd40], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB40_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB40_3;
	bra.uni 	$L__BB40_10;

$L__BB40_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB40_9;

$L__BB40_10:
	ret;

}
	// .globl	ia_i64_f64
.visible .entry ia_i64_f64(
	.param .u64 ia_i64_f64_param_0,
	.param .u64 ia_i64_f64_param_1,
	.param .u64 ia_i64_f64_param_2,
	.param .u64 ia_i64_f64_param_3,
	.param .u64 ia_i64_f64_param_4,
	.param .u64 ia_i64_f64_param_5,
	.param .u64 ia_i64_f64_param_6,
	.param .u64 ia_i64_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_i64_f64_param_0];
	ld.param.u64 	%rd19, [ia_i64_f64_param_1];
	ld.param.u64 	%rd20, [ia_i64_f64_param_2];
	ld.param.u64 	%rd21, [ia_i64_f64_param_3];
	ld.param.u64 	%rd24, [ia_i64_f64_param_4];
	ld.param.u64 	%rd22, [ia_i64_f64_param_6];
	ld.param.u64 	%rd23, [ia_i64_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB41_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB41_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB41_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB41_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB41_6;

$L__BB41_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB41_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB41_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd45, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f64 	%fd1, [%rd40];
	ld.global.f64 	%fd2, [%rd38];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd40], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB41_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB41_3;
	bra.uni 	$L__BB41_10;

$L__BB41_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB41_9;

$L__BB41_10:
	ret;

}
	// .globl	ia_i64_u8
.visible .entry ia_i64_u8(
	.param .u64 ia_i64_u8_param_0,
	.param .u64 ia_i64_u8_param_1,
	.param .u64 ia_i64_u8_param_2,
	.param .u64 ia_i64_u8_param_3,
	.param .u64 ia_i64_u8_param_4,
	.param .u64 ia_i64_u8_param_5,
	.param .u64 ia_i64_u8_param_6,
	.param .u64 ia_i64_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [ia_i64_u8_param_0];
	ld.param.u64 	%rd19, [ia_i64_u8_param_1];
	ld.param.u64 	%rd20, [ia_i64_u8_param_2];
	ld.param.u64 	%rd21, [ia_i64_u8_param_3];
	ld.param.u64 	%rd24, [ia_i64_u8_param_4];
	ld.param.u64 	%rd22, [ia_i64_u8_param_6];
	ld.param.u64 	%rd23, [ia_i64_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB42_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB42_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB42_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB42_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB42_6;

$L__BB42_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB42_6:
	mul.lo.s64 	%rd13, %rd41, %rd19;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB42_7:
	add.s64 	%rd28, %rd43, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd42;
	shl.b64 	%rd31, %rd43, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd30;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd19;
	@%p4 bra 	$L__BB42_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB42_3;
	bra.uni 	$L__BB42_10;

$L__BB42_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB42_9;

$L__BB42_10:
	ret;

}
	// .globl	ia_i64_i64
.visible .entry ia_i64_i64(
	.param .u64 ia_i64_i64_param_0,
	.param .u64 ia_i64_i64_param_1,
	.param .u64 ia_i64_i64_param_2,
	.param .u64 ia_i64_i64_param_3,
	.param .u64 ia_i64_i64_param_4,
	.param .u64 ia_i64_i64_param_5,
	.param .u64 ia_i64_i64_param_6,
	.param .u64 ia_i64_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd18, [ia_i64_i64_param_0];
	ld.param.u64 	%rd19, [ia_i64_i64_param_1];
	ld.param.u64 	%rd20, [ia_i64_i64_param_2];
	ld.param.u64 	%rd21, [ia_i64_i64_param_3];
	ld.param.u64 	%rd24, [ia_i64_i64_param_4];
	ld.param.u64 	%rd22, [ia_i64_i64_param_6];
	ld.param.u64 	%rd23, [ia_i64_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB43_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB43_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB43_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB43_5;

	div.u64 	%rd46, %rd45, %rd23;
	mul.lo.s64 	%rd26, %rd46, %rd23;
	sub.s64 	%rd47, %rd45, %rd26;
	bra.uni 	$L__BB43_6;

$L__BB43_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB43_6:
	mul.lo.s64 	%rd13, %rd46, %rd19;
	mul.lo.s64 	%rd14, %rd46, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB43_7:
	add.s64 	%rd28, %rd48, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd47;
	shl.b64 	%rd31, %rd48, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u64 	%rd41, [%rd40];
	ld.global.u64 	%rd42, [%rd38];
	add.s64 	%rd43, %rd41, %rd42;
	st.global.u64 	[%rd40], %rd43;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p4, %rd48, %rd19;
	@%p4 bra 	$L__BB43_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p5, %rd2, %rd45;
	@%p5 bra 	$L__BB43_3;
	bra.uni 	$L__BB43_10;

$L__BB43_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p6, %rd2, %rd44;
	@%p6 bra 	$L__BB43_9;

$L__BB43_10:
	ret;

}
	// .globl	ia_i64_u32
.visible .entry ia_i64_u32(
	.param .u64 ia_i64_u32_param_0,
	.param .u64 ia_i64_u32_param_1,
	.param .u64 ia_i64_u32_param_2,
	.param .u64 ia_i64_u32_param_3,
	.param .u64 ia_i64_u32_param_4,
	.param .u64 ia_i64_u32_param_5,
	.param .u64 ia_i64_u32_param_6,
	.param .u64 ia_i64_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_i64_u32_param_0];
	ld.param.u64 	%rd19, [ia_i64_u32_param_1];
	ld.param.u64 	%rd20, [ia_i64_u32_param_2];
	ld.param.u64 	%rd21, [ia_i64_u32_param_3];
	ld.param.u64 	%rd24, [ia_i64_u32_param_4];
	ld.param.u64 	%rd22, [ia_i64_u32_param_6];
	ld.param.u64 	%rd23, [ia_i64_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB44_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB44_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB44_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB44_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB44_6;

$L__BB44_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB44_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd45, 0;

$L__BB44_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd45, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u32 	%r19, [%rd40];
	ld.global.u32 	%r20, [%rd38];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd40], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd45, %r23;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB44_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd42, %r22;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB44_3;
	bra.uni 	$L__BB44_10;

$L__BB44_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB44_9;

$L__BB44_10:
	ret;

}
	// .globl	ia_u32_f32
.visible .entry ia_u32_f32(
	.param .u64 ia_u32_f32_param_0,
	.param .u64 ia_u32_f32_param_1,
	.param .u64 ia_u32_f32_param_2,
	.param .u64 ia_u32_f32_param_3,
	.param .u64 ia_u32_f32_param_4,
	.param .u64 ia_u32_f32_param_5,
	.param .u64 ia_u32_f32_param_6,
	.param .u64 ia_u32_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_f32_param_0];
	ld.param.u64 	%rd19, [ia_u32_f32_param_1];
	ld.param.u64 	%rd20, [ia_u32_f32_param_2];
	ld.param.u64 	%rd21, [ia_u32_f32_param_3];
	ld.param.u64 	%rd24, [ia_u32_f32_param_4];
	ld.param.u64 	%rd22, [ia_u32_f32_param_6];
	ld.param.u64 	%rd23, [ia_u32_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB45_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB45_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB45_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB45_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB45_6;

$L__BB45_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB45_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB45_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd33, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f32 	%f1, [%rd40];
	ld.global.f32 	%f2, [%rd38];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd40], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB45_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB45_3;
	bra.uni 	$L__BB45_10;

$L__BB45_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB45_9;

$L__BB45_10:
	ret;

}
	// .globl	ia_u32_f64
.visible .entry ia_u32_f64(
	.param .u64 ia_u32_f64_param_0,
	.param .u64 ia_u32_f64_param_1,
	.param .u64 ia_u32_f64_param_2,
	.param .u64 ia_u32_f64_param_3,
	.param .u64 ia_u32_f64_param_4,
	.param .u64 ia_u32_f64_param_5,
	.param .u64 ia_u32_f64_param_6,
	.param .u64 ia_u32_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_f64_param_0];
	ld.param.u64 	%rd19, [ia_u32_f64_param_1];
	ld.param.u64 	%rd20, [ia_u32_f64_param_2];
	ld.param.u64 	%rd21, [ia_u32_f64_param_3];
	ld.param.u64 	%rd24, [ia_u32_f64_param_4];
	ld.param.u64 	%rd22, [ia_u32_f64_param_6];
	ld.param.u64 	%rd23, [ia_u32_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB46_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB46_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB46_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB46_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB46_6;

$L__BB46_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB46_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB46_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd33, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f64 	%fd1, [%rd40];
	ld.global.f64 	%fd2, [%rd38];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd40], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB46_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB46_3;
	bra.uni 	$L__BB46_10;

$L__BB46_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB46_9;

$L__BB46_10:
	ret;

}
	// .globl	ia_u32_u8
.visible .entry ia_u32_u8(
	.param .u64 ia_u32_u8_param_0,
	.param .u64 ia_u32_u8_param_1,
	.param .u64 ia_u32_u8_param_2,
	.param .u64 ia_u32_u8_param_3,
	.param .u64 ia_u32_u8_param_4,
	.param .u64 ia_u32_u8_param_5,
	.param .u64 ia_u32_u8_param_6,
	.param .u64 ia_u32_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [ia_u32_u8_param_0];
	ld.param.u64 	%rd19, [ia_u32_u8_param_1];
	ld.param.u64 	%rd20, [ia_u32_u8_param_2];
	ld.param.u64 	%rd21, [ia_u32_u8_param_3];
	ld.param.u64 	%rd24, [ia_u32_u8_param_4];
	ld.param.u64 	%rd22, [ia_u32_u8_param_6];
	ld.param.u64 	%rd23, [ia_u32_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB47_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB47_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB47_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB47_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB47_6;

$L__BB47_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB47_6:
	mul.lo.s64 	%rd13, %rd41, %rd19;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB47_7:
	shl.b64 	%rd28, %rd43, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd43, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd42;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd33;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd19;
	@%p4 bra 	$L__BB47_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB47_3;
	bra.uni 	$L__BB47_10;

$L__BB47_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB47_9;

$L__BB47_10:
	ret;

}
	// .globl	ia_u32_i64
.visible .entry ia_u32_i64(
	.param .u64 ia_u32_i64_param_0,
	.param .u64 ia_u32_i64_param_1,
	.param .u64 ia_u32_i64_param_2,
	.param .u64 ia_u32_i64_param_3,
	.param .u64 ia_u32_i64_param_4,
	.param .u64 ia_u32_i64_param_5,
	.param .u64 ia_u32_i64_param_6,
	.param .u64 ia_u32_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd18, [ia_u32_i64_param_0];
	ld.param.u64 	%rd19, [ia_u32_i64_param_1];
	ld.param.u64 	%rd20, [ia_u32_i64_param_2];
	ld.param.u64 	%rd21, [ia_u32_i64_param_3];
	ld.param.u64 	%rd24, [ia_u32_i64_param_4];
	ld.param.u64 	%rd22, [ia_u32_i64_param_6];
	ld.param.u64 	%rd23, [ia_u32_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB48_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB48_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB48_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB48_5;

	div.u64 	%rd46, %rd45, %rd23;
	mul.lo.s64 	%rd26, %rd46, %rd23;
	sub.s64 	%rd47, %rd45, %rd26;
	bra.uni 	$L__BB48_6;

$L__BB48_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB48_6:
	mul.lo.s64 	%rd13, %rd46, %rd19;
	mul.lo.s64 	%rd14, %rd46, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB48_7:
	shl.b64 	%rd28, %rd48, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd48, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd47;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd33, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u64 	%rd41, [%rd40];
	ld.global.u64 	%rd42, [%rd38];
	add.s64 	%rd43, %rd41, %rd42;
	st.global.u64 	[%rd40], %rd43;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p4, %rd48, %rd19;
	@%p4 bra 	$L__BB48_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p5, %rd2, %rd45;
	@%p5 bra 	$L__BB48_3;
	bra.uni 	$L__BB48_10;

$L__BB48_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p6, %rd2, %rd44;
	@%p6 bra 	$L__BB48_9;

$L__BB48_10:
	ret;

}
	// .globl	ia_u32_u32
.visible .entry ia_u32_u32(
	.param .u64 ia_u32_u32_param_0,
	.param .u64 ia_u32_u32_param_1,
	.param .u64 ia_u32_u32_param_2,
	.param .u64 ia_u32_u32_param_3,
	.param .u64 ia_u32_u32_param_4,
	.param .u64 ia_u32_u32_param_5,
	.param .u64 ia_u32_u32_param_6,
	.param .u64 ia_u32_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_u32_param_0];
	ld.param.u64 	%rd19, [ia_u32_u32_param_1];
	ld.param.u64 	%rd20, [ia_u32_u32_param_2];
	ld.param.u64 	%rd21, [ia_u32_u32_param_3];
	ld.param.u64 	%rd24, [ia_u32_u32_param_4];
	ld.param.u64 	%rd22, [ia_u32_u32_param_6];
	ld.param.u64 	%rd23, [ia_u32_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB49_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB49_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB49_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB49_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB49_6;

$L__BB49_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB49_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd45, 0;

$L__BB49_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd33, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u32 	%r19, [%rd40];
	ld.global.u32 	%r20, [%rd38];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd40], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd45, %r23;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB49_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd42, %r22;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB49_3;
	bra.uni 	$L__BB49_10;

$L__BB49_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB49_9;

$L__BB49_10:
	ret;

}
	// .globl	ia_u8_f32
.visible .entry ia_u8_f32(
	.param .u64 ia_u8_f32_param_0,
	.param .u64 ia_u8_f32_param_1,
	.param .u64 ia_u8_f32_param_2,
	.param .u64 ia_u8_f32_param_3,
	.param .u64 ia_u8_f32_param_4,
	.param .u64 ia_u8_f32_param_5,
	.param .u64 ia_u8_f32_param_6,
	.param .u64 ia_u8_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_f32_param_0];
	ld.param.u64 	%rd19, [ia_u8_f32_param_1];
	ld.param.u64 	%rd20, [ia_u8_f32_param_2];
	ld.param.u64 	%rd21, [ia_u8_f32_param_3];
	ld.param.u64 	%rd24, [ia_u8_f32_param_4];
	ld.param.u64 	%rd22, [ia_u8_f32_param_6];
	ld.param.u64 	%rd23, [ia_u8_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB50_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB50_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB50_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB50_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB50_6;

$L__BB50_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB50_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB50_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd32, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	ld.global.f32 	%f2, [%rd37];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB50_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB50_3;
	bra.uni 	$L__BB50_10;

$L__BB50_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB50_9;

$L__BB50_10:
	ret;

}
	// .globl	ia_u8_f64
.visible .entry ia_u8_f64(
	.param .u64 ia_u8_f64_param_0,
	.param .u64 ia_u8_f64_param_1,
	.param .u64 ia_u8_f64_param_2,
	.param .u64 ia_u8_f64_param_3,
	.param .u64 ia_u8_f64_param_4,
	.param .u64 ia_u8_f64_param_5,
	.param .u64 ia_u8_f64_param_6,
	.param .u64 ia_u8_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_f64_param_0];
	ld.param.u64 	%rd19, [ia_u8_f64_param_1];
	ld.param.u64 	%rd20, [ia_u8_f64_param_2];
	ld.param.u64 	%rd21, [ia_u8_f64_param_3];
	ld.param.u64 	%rd24, [ia_u8_f64_param_4];
	ld.param.u64 	%rd22, [ia_u8_f64_param_6];
	ld.param.u64 	%rd23, [ia_u8_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB51_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB51_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB51_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB51_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB51_6;

$L__BB51_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB51_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB51_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd32, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	ld.global.f64 	%fd2, [%rd37];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB51_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB51_3;
	bra.uni 	$L__BB51_10;

$L__BB51_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB51_9;

$L__BB51_10:
	ret;

}
	// .globl	ia_u8_u8
.visible .entry ia_u8_u8(
	.param .u64 ia_u8_u8_param_0,
	.param .u64 ia_u8_u8_param_1,
	.param .u64 ia_u8_u8_param_2,
	.param .u64 ia_u8_u8_param_3,
	.param .u64 ia_u8_u8_param_4,
	.param .u64 ia_u8_u8_param_5,
	.param .u64 ia_u8_u8_param_6,
	.param .u64 ia_u8_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd18, [ia_u8_u8_param_0];
	ld.param.u64 	%rd19, [ia_u8_u8_param_1];
	ld.param.u64 	%rd20, [ia_u8_u8_param_2];
	ld.param.u64 	%rd21, [ia_u8_u8_param_3];
	ld.param.u64 	%rd24, [ia_u8_u8_param_4];
	ld.param.u64 	%rd22, [ia_u8_u8_param_6];
	ld.param.u64 	%rd23, [ia_u8_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd39, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd39;
	@%p1 bra 	$L__BB52_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB52_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB52_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB52_5;

	div.u64 	%rd40, %rd39, %rd23;
	mul.lo.s64 	%rd26, %rd40, %rd23;
	sub.s64 	%rd41, %rd39, %rd26;
	bra.uni 	$L__BB52_6;

$L__BB52_5:
	cvt.u32.u64 	%r14, %rd39;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd40, %r15;
	cvt.u64.u32 	%rd41, %r17;

$L__BB52_6:
	mul.lo.s64 	%rd13, %rd40, %rd19;
	mul.lo.s64 	%rd14, %rd40, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd42, 0;

$L__BB52_7:
	add.s64 	%rd28, %rd5, %rd42;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd42, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd41;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd41;
	add.s64 	%rd36, %rd4, %rd32;
	add.s64 	%rd37, %rd3, %rd35;
	ld.global.u8 	%rs1, [%rd37];
	ld.global.u8 	%rs2, [%rd36];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd37], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd42, %r20;
	setp.lt.u64 	%p4, %rd42, %rd19;
	@%p4 bra 	$L__BB52_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p5, %rd2, %rd39;
	@%p5 bra 	$L__BB52_3;
	bra.uni 	$L__BB52_10;

$L__BB52_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd38, %r19;
	setp.gt.u64 	%p6, %rd2, %rd38;
	@%p6 bra 	$L__BB52_9;

$L__BB52_10:
	ret;

}
	// .globl	ia_u8_u32
.visible .entry ia_u8_u32(
	.param .u64 ia_u8_u32_param_0,
	.param .u64 ia_u8_u32_param_1,
	.param .u64 ia_u8_u32_param_2,
	.param .u64 ia_u8_u32_param_3,
	.param .u64 ia_u8_u32_param_4,
	.param .u64 ia_u8_u32_param_5,
	.param .u64 ia_u8_u32_param_6,
	.param .u64 ia_u8_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_u32_param_0];
	ld.param.u64 	%rd19, [ia_u8_u32_param_1];
	ld.param.u64 	%rd20, [ia_u8_u32_param_2];
	ld.param.u64 	%rd21, [ia_u8_u32_param_3];
	ld.param.u64 	%rd24, [ia_u8_u32_param_4];
	ld.param.u64 	%rd22, [ia_u8_u32_param_6];
	ld.param.u64 	%rd23, [ia_u8_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB53_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB53_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB53_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB53_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB53_6;

$L__BB53_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB53_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd44, 0;

$L__BB53_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd32, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	ld.global.u32 	%r20, [%rd37];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd44, %r23;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB53_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB53_3;
	bra.uni 	$L__BB53_10;

$L__BB53_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd40, %r22;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB53_9;

$L__BB53_10:
	ret;

}
	// .globl	ia_u8_i64
.visible .entry ia_u8_i64(
	.param .u64 ia_u8_i64_param_0,
	.param .u64 ia_u8_i64_param_1,
	.param .u64 ia_u8_i64_param_2,
	.param .u64 ia_u8_i64_param_3,
	.param .u64 ia_u8_i64_param_4,
	.param .u64 ia_u8_i64_param_5,
	.param .u64 ia_u8_i64_param_6,
	.param .u64 ia_u8_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd18, [ia_u8_i64_param_0];
	ld.param.u64 	%rd19, [ia_u8_i64_param_1];
	ld.param.u64 	%rd20, [ia_u8_i64_param_2];
	ld.param.u64 	%rd21, [ia_u8_i64_param_3];
	ld.param.u64 	%rd24, [ia_u8_i64_param_4];
	ld.param.u64 	%rd22, [ia_u8_i64_param_6];
	ld.param.u64 	%rd23, [ia_u8_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB54_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB54_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB54_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB54_5;

	div.u64 	%rd45, %rd44, %rd23;
	mul.lo.s64 	%rd26, %rd45, %rd23;
	sub.s64 	%rd46, %rd44, %rd26;
	bra.uni 	$L__BB54_6;

$L__BB54_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB54_6:
	mul.lo.s64 	%rd13, %rd45, %rd19;
	mul.lo.s64 	%rd14, %rd45, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB54_7:
	add.s64 	%rd28, %rd5, %rd47;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd47, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd46;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd46;
	shl.b64 	%rd36, %rd32, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	ld.global.u64 	%rd41, [%rd37];
	add.s64 	%rd42, %rd40, %rd41;
	st.global.u64 	[%rd39], %rd42;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p4, %rd47, %rd19;
	@%p4 bra 	$L__BB54_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p5, %rd2, %rd44;
	@%p5 bra 	$L__BB54_3;
	bra.uni 	$L__BB54_10;

$L__BB54_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p6, %rd2, %rd43;
	@%p6 bra 	$L__BB54_9;

$L__BB54_10:
	ret;

}
	// .globl	sa_i64_f32
.visible .entry sa_i64_f32(
	.param .u64 sa_i64_f32_param_0,
	.param .u64 sa_i64_f32_param_1,
	.param .u64 sa_i64_f32_param_2,
	.param .u64 sa_i64_f32_param_3,
	.param .u64 sa_i64_f32_param_4,
	.param .u64 sa_i64_f32_param_5,
	.param .u64 sa_i64_f32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_i64_f32_param_0];
	ld.param.u64 	%rd19, [sa_i64_f32_param_1];
	ld.param.u64 	%rd20, [sa_i64_f32_param_2];
	ld.param.u64 	%rd24, [sa_i64_f32_param_3];
	ld.param.u64 	%rd21, [sa_i64_f32_param_4];
	ld.param.u64 	%rd22, [sa_i64_f32_param_5];
	ld.param.u64 	%rd23, [sa_i64_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB55_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB55_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB55_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB55_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB55_6;

$L__BB55_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB55_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB55_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f32 	%f1, [%rd40];
	ld.global.f32 	%f2, [%rd38];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd40], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB55_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB55_3;
	bra.uni 	$L__BB55_10;

$L__BB55_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB55_9;

$L__BB55_10:
	ret;

}
	// .globl	sa_i64_f64
.visible .entry sa_i64_f64(
	.param .u64 sa_i64_f64_param_0,
	.param .u64 sa_i64_f64_param_1,
	.param .u64 sa_i64_f64_param_2,
	.param .u64 sa_i64_f64_param_3,
	.param .u64 sa_i64_f64_param_4,
	.param .u64 sa_i64_f64_param_5,
	.param .u64 sa_i64_f64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_i64_f64_param_0];
	ld.param.u64 	%rd19, [sa_i64_f64_param_1];
	ld.param.u64 	%rd20, [sa_i64_f64_param_2];
	ld.param.u64 	%rd24, [sa_i64_f64_param_3];
	ld.param.u64 	%rd21, [sa_i64_f64_param_4];
	ld.param.u64 	%rd22, [sa_i64_f64_param_5];
	ld.param.u64 	%rd23, [sa_i64_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB56_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB56_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB56_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB56_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB56_6;

$L__BB56_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB56_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB56_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd43;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	ld.global.f64 	%fd2, [%rd37];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB56_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB56_3;
	bra.uni 	$L__BB56_10;

$L__BB56_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB56_9;

$L__BB56_10:
	ret;

}
	// .globl	sa_i64_u8
.visible .entry sa_i64_u8(
	.param .u64 sa_i64_u8_param_0,
	.param .u64 sa_i64_u8_param_1,
	.param .u64 sa_i64_u8_param_2,
	.param .u64 sa_i64_u8_param_3,
	.param .u64 sa_i64_u8_param_4,
	.param .u64 sa_i64_u8_param_5,
	.param .u64 sa_i64_u8_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [sa_i64_u8_param_0];
	ld.param.u64 	%rd19, [sa_i64_u8_param_1];
	ld.param.u64 	%rd20, [sa_i64_u8_param_2];
	ld.param.u64 	%rd24, [sa_i64_u8_param_3];
	ld.param.u64 	%rd21, [sa_i64_u8_param_4];
	ld.param.u64 	%rd22, [sa_i64_u8_param_5];
	ld.param.u64 	%rd23, [sa_i64_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB57_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB57_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB57_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB57_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB57_6;

$L__BB57_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB57_6:
	mul.lo.s64 	%rd13, %rd41, %rd21;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB57_7:
	add.s64 	%rd28, %rd43, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd42;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd30;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd21;
	@%p4 bra 	$L__BB57_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB57_3;
	bra.uni 	$L__BB57_10;

$L__BB57_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB57_9;

$L__BB57_10:
	ret;

}
	// .globl	sa_i64_i64
.visible .entry sa_i64_i64(
	.param .u64 sa_i64_i64_param_0,
	.param .u64 sa_i64_i64_param_1,
	.param .u64 sa_i64_i64_param_2,
	.param .u64 sa_i64_i64_param_3,
	.param .u64 sa_i64_i64_param_4,
	.param .u64 sa_i64_i64_param_5,
	.param .u64 sa_i64_i64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd18, [sa_i64_i64_param_0];
	ld.param.u64 	%rd19, [sa_i64_i64_param_1];
	ld.param.u64 	%rd20, [sa_i64_i64_param_2];
	ld.param.u64 	%rd24, [sa_i64_i64_param_3];
	ld.param.u64 	%rd21, [sa_i64_i64_param_4];
	ld.param.u64 	%rd22, [sa_i64_i64_param_5];
	ld.param.u64 	%rd23, [sa_i64_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB58_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB58_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB58_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB58_5;

	div.u64 	%rd45, %rd44, %rd23;
	mul.lo.s64 	%rd26, %rd45, %rd23;
	sub.s64 	%rd46, %rd44, %rd26;
	bra.uni 	$L__BB58_6;

$L__BB58_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB58_6:
	mul.lo.s64 	%rd13, %rd45, %rd21;
	mul.lo.s64 	%rd14, %rd45, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB58_7:
	add.s64 	%rd28, %rd47, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd46;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd46;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	ld.global.u64 	%rd41, [%rd37];
	add.s64 	%rd42, %rd40, %rd41;
	st.global.u64 	[%rd39], %rd42;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p4, %rd47, %rd21;
	@%p4 bra 	$L__BB58_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p5, %rd2, %rd44;
	@%p5 bra 	$L__BB58_3;
	bra.uni 	$L__BB58_10;

$L__BB58_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p6, %rd2, %rd43;
	@%p6 bra 	$L__BB58_9;

$L__BB58_10:
	ret;

}
	// .globl	sa_i64_u32
.visible .entry sa_i64_u32(
	.param .u64 sa_i64_u32_param_0,
	.param .u64 sa_i64_u32_param_1,
	.param .u64 sa_i64_u32_param_2,
	.param .u64 sa_i64_u32_param_3,
	.param .u64 sa_i64_u32_param_4,
	.param .u64 sa_i64_u32_param_5,
	.param .u64 sa_i64_u32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_i64_u32_param_0];
	ld.param.u64 	%rd19, [sa_i64_u32_param_1];
	ld.param.u64 	%rd20, [sa_i64_u32_param_2];
	ld.param.u64 	%rd24, [sa_i64_u32_param_3];
	ld.param.u64 	%rd21, [sa_i64_u32_param_4];
	ld.param.u64 	%rd22, [sa_i64_u32_param_5];
	ld.param.u64 	%rd23, [sa_i64_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB59_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB59_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB59_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB59_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB59_6;

$L__BB59_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB59_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd45, 0;

$L__BB59_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u32 	%r19, [%rd40];
	ld.global.u32 	%r20, [%rd38];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd40], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd45, %r23;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB59_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd42, %r22;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB59_3;
	bra.uni 	$L__BB59_10;

$L__BB59_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB59_9;

$L__BB59_10:
	ret;

}
	// .globl	sa_u32_f32
.visible .entry sa_u32_f32(
	.param .u64 sa_u32_f32_param_0,
	.param .u64 sa_u32_f32_param_1,
	.param .u64 sa_u32_f32_param_2,
	.param .u64 sa_u32_f32_param_3,
	.param .u64 sa_u32_f32_param_4,
	.param .u64 sa_u32_f32_param_5,
	.param .u64 sa_u32_f32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u32_f32_param_0];
	ld.param.u64 	%rd19, [sa_u32_f32_param_1];
	ld.param.u64 	%rd20, [sa_u32_f32_param_2];
	ld.param.u64 	%rd24, [sa_u32_f32_param_3];
	ld.param.u64 	%rd21, [sa_u32_f32_param_4];
	ld.param.u64 	%rd22, [sa_u32_f32_param_5];
	ld.param.u64 	%rd23, [sa_u32_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB60_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB60_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB60_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB60_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB60_6;

$L__BB60_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB60_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB60_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd43;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	ld.global.f32 	%f2, [%rd37];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB60_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB60_3;
	bra.uni 	$L__BB60_10;

$L__BB60_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB60_9;

$L__BB60_10:
	ret;

}
	// .globl	sa_u32_f64
.visible .entry sa_u32_f64(
	.param .u64 sa_u32_f64_param_0,
	.param .u64 sa_u32_f64_param_1,
	.param .u64 sa_u32_f64_param_2,
	.param .u64 sa_u32_f64_param_3,
	.param .u64 sa_u32_f64_param_4,
	.param .u64 sa_u32_f64_param_5,
	.param .u64 sa_u32_f64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_u32_f64_param_0];
	ld.param.u64 	%rd19, [sa_u32_f64_param_1];
	ld.param.u64 	%rd20, [sa_u32_f64_param_2];
	ld.param.u64 	%rd24, [sa_u32_f64_param_3];
	ld.param.u64 	%rd21, [sa_u32_f64_param_4];
	ld.param.u64 	%rd22, [sa_u32_f64_param_5];
	ld.param.u64 	%rd23, [sa_u32_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB61_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB61_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB61_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB61_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB61_6;

$L__BB61_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB61_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB61_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f64 	%fd1, [%rd40];
	ld.global.f64 	%fd2, [%rd38];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd40], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB61_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB61_3;
	bra.uni 	$L__BB61_10;

$L__BB61_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB61_9;

$L__BB61_10:
	ret;

}
	// .globl	sa_u32_u8
.visible .entry sa_u32_u8(
	.param .u64 sa_u32_u8_param_0,
	.param .u64 sa_u32_u8_param_1,
	.param .u64 sa_u32_u8_param_2,
	.param .u64 sa_u32_u8_param_3,
	.param .u64 sa_u32_u8_param_4,
	.param .u64 sa_u32_u8_param_5,
	.param .u64 sa_u32_u8_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [sa_u32_u8_param_0];
	ld.param.u64 	%rd19, [sa_u32_u8_param_1];
	ld.param.u64 	%rd20, [sa_u32_u8_param_2];
	ld.param.u64 	%rd24, [sa_u32_u8_param_3];
	ld.param.u64 	%rd21, [sa_u32_u8_param_4];
	ld.param.u64 	%rd22, [sa_u32_u8_param_5];
	ld.param.u64 	%rd23, [sa_u32_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB62_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB62_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB62_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB62_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB62_6;

$L__BB62_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB62_6:
	mul.lo.s64 	%rd13, %rd41, %rd21;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB62_7:
	add.s64 	%rd28, %rd43, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd42;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd30;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd21;
	@%p4 bra 	$L__BB62_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB62_3;
	bra.uni 	$L__BB62_10;

$L__BB62_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB62_9;

$L__BB62_10:
	ret;

}
	// .globl	sa_u32_i64
.visible .entry sa_u32_i64(
	.param .u64 sa_u32_i64_param_0,
	.param .u64 sa_u32_i64_param_1,
	.param .u64 sa_u32_i64_param_2,
	.param .u64 sa_u32_i64_param_3,
	.param .u64 sa_u32_i64_param_4,
	.param .u64 sa_u32_i64_param_5,
	.param .u64 sa_u32_i64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd18, [sa_u32_i64_param_0];
	ld.param.u64 	%rd19, [sa_u32_i64_param_1];
	ld.param.u64 	%rd20, [sa_u32_i64_param_2];
	ld.param.u64 	%rd24, [sa_u32_i64_param_3];
	ld.param.u64 	%rd21, [sa_u32_i64_param_4];
	ld.param.u64 	%rd22, [sa_u32_i64_param_5];
	ld.param.u64 	%rd23, [sa_u32_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB63_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB63_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB63_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB63_5;

	div.u64 	%rd46, %rd45, %rd23;
	mul.lo.s64 	%rd26, %rd46, %rd23;
	sub.s64 	%rd47, %rd45, %rd26;
	bra.uni 	$L__BB63_6;

$L__BB63_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB63_6:
	mul.lo.s64 	%rd13, %rd46, %rd21;
	mul.lo.s64 	%rd14, %rd46, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB63_7:
	add.s64 	%rd28, %rd48, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd47;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u64 	%rd41, [%rd40];
	ld.global.u64 	%rd42, [%rd38];
	add.s64 	%rd43, %rd41, %rd42;
	st.global.u64 	[%rd40], %rd43;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p4, %rd48, %rd21;
	@%p4 bra 	$L__BB63_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p5, %rd2, %rd45;
	@%p5 bra 	$L__BB63_3;
	bra.uni 	$L__BB63_10;

$L__BB63_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p6, %rd2, %rd44;
	@%p6 bra 	$L__BB63_9;

$L__BB63_10:
	ret;

}
	// .globl	sa_u32_u32
.visible .entry sa_u32_u32(
	.param .u64 sa_u32_u32_param_0,
	.param .u64 sa_u32_u32_param_1,
	.param .u64 sa_u32_u32_param_2,
	.param .u64 sa_u32_u32_param_3,
	.param .u64 sa_u32_u32_param_4,
	.param .u64 sa_u32_u32_param_5,
	.param .u64 sa_u32_u32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u32_u32_param_0];
	ld.param.u64 	%rd19, [sa_u32_u32_param_1];
	ld.param.u64 	%rd20, [sa_u32_u32_param_2];
	ld.param.u64 	%rd24, [sa_u32_u32_param_3];
	ld.param.u64 	%rd21, [sa_u32_u32_param_4];
	ld.param.u64 	%rd22, [sa_u32_u32_param_5];
	ld.param.u64 	%rd23, [sa_u32_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB64_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB64_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB64_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB64_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB64_6;

$L__BB64_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB64_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd44, 0;

$L__BB64_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd43;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	ld.global.u32 	%r20, [%rd37];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd44, %r23;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB64_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB64_3;
	bra.uni 	$L__BB64_10;

$L__BB64_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd40, %r22;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB64_9;

$L__BB64_10:
	ret;

}
	// .globl	sa_u8_f32
.visible .entry sa_u8_f32(
	.param .u64 sa_u8_f32_param_0,
	.param .u64 sa_u8_f32_param_1,
	.param .u64 sa_u8_f32_param_2,
	.param .u64 sa_u8_f32_param_3,
	.param .u64 sa_u8_f32_param_4,
	.param .u64 sa_u8_f32_param_5,
	.param .u64 sa_u8_f32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_f32_param_0];
	ld.param.u64 	%rd19, [sa_u8_f32_param_1];
	ld.param.u64 	%rd20, [sa_u8_f32_param_2];
	ld.param.u64 	%rd24, [sa_u8_f32_param_3];
	ld.param.u64 	%rd21, [sa_u8_f32_param_4];
	ld.param.u64 	%rd22, [sa_u8_f32_param_5];
	ld.param.u64 	%rd23, [sa_u8_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB65_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB65_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB65_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB65_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB65_6;

$L__BB65_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB65_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB65_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd30, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	ld.global.f32 	%f2, [%rd37];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB65_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB65_3;
	bra.uni 	$L__BB65_10;

$L__BB65_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB65_9;

$L__BB65_10:
	ret;

}
	// .globl	sa_u8_f64
.visible .entry sa_u8_f64(
	.param .u64 sa_u8_f64_param_0,
	.param .u64 sa_u8_f64_param_1,
	.param .u64 sa_u8_f64_param_2,
	.param .u64 sa_u8_f64_param_3,
	.param .u64 sa_u8_f64_param_4,
	.param .u64 sa_u8_f64_param_5,
	.param .u64 sa_u8_f64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_f64_param_0];
	ld.param.u64 	%rd19, [sa_u8_f64_param_1];
	ld.param.u64 	%rd20, [sa_u8_f64_param_2];
	ld.param.u64 	%rd24, [sa_u8_f64_param_3];
	ld.param.u64 	%rd21, [sa_u8_f64_param_4];
	ld.param.u64 	%rd22, [sa_u8_f64_param_5];
	ld.param.u64 	%rd23, [sa_u8_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB66_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB66_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB66_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB66_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB66_6;

$L__BB66_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB66_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB66_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd30, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	ld.global.f64 	%fd2, [%rd37];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB66_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB66_3;
	bra.uni 	$L__BB66_10;

$L__BB66_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB66_9;

$L__BB66_10:
	ret;

}
	// .globl	sa_u8_u8
.visible .entry sa_u8_u8(
	.param .u64 sa_u8_u8_param_0,
	.param .u64 sa_u8_u8_param_1,
	.param .u64 sa_u8_u8_param_2,
	.param .u64 sa_u8_u8_param_3,
	.param .u64 sa_u8_u8_param_4,
	.param .u64 sa_u8_u8_param_5,
	.param .u64 sa_u8_u8_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd18, [sa_u8_u8_param_0];
	ld.param.u64 	%rd19, [sa_u8_u8_param_1];
	ld.param.u64 	%rd20, [sa_u8_u8_param_2];
	ld.param.u64 	%rd24, [sa_u8_u8_param_3];
	ld.param.u64 	%rd21, [sa_u8_u8_param_4];
	ld.param.u64 	%rd22, [sa_u8_u8_param_5];
	ld.param.u64 	%rd23, [sa_u8_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd39, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd39;
	@%p1 bra 	$L__BB67_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB67_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB67_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB67_5;

	div.u64 	%rd40, %rd39, %rd23;
	mul.lo.s64 	%rd26, %rd40, %rd23;
	sub.s64 	%rd41, %rd39, %rd26;
	bra.uni 	$L__BB67_6;

$L__BB67_5:
	cvt.u32.u64 	%r14, %rd39;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd40, %r15;
	cvt.u64.u32 	%rd41, %r17;

$L__BB67_6:
	mul.lo.s64 	%rd13, %rd40, %rd21;
	mul.lo.s64 	%rd14, %rd40, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd42, 0;

$L__BB67_7:
	add.s64 	%rd28, %rd42, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd41;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd41;
	add.s64 	%rd36, %rd4, %rd30;
	add.s64 	%rd37, %rd3, %rd35;
	ld.global.u8 	%rs1, [%rd37];
	ld.global.u8 	%rs2, [%rd36];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd37], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd42, %r20;
	setp.lt.u64 	%p4, %rd42, %rd21;
	@%p4 bra 	$L__BB67_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p5, %rd2, %rd39;
	@%p5 bra 	$L__BB67_3;
	bra.uni 	$L__BB67_10;

$L__BB67_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd38, %r19;
	setp.gt.u64 	%p6, %rd2, %rd38;
	@%p6 bra 	$L__BB67_9;

$L__BB67_10:
	ret;

}
	// .globl	sa_u8_u32
.visible .entry sa_u8_u32(
	.param .u64 sa_u8_u32_param_0,
	.param .u64 sa_u8_u32_param_1,
	.param .u64 sa_u8_u32_param_2,
	.param .u64 sa_u8_u32_param_3,
	.param .u64 sa_u8_u32_param_4,
	.param .u64 sa_u8_u32_param_5,
	.param .u64 sa_u8_u32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_u32_param_0];
	ld.param.u64 	%rd19, [sa_u8_u32_param_1];
	ld.param.u64 	%rd20, [sa_u8_u32_param_2];
	ld.param.u64 	%rd24, [sa_u8_u32_param_3];
	ld.param.u64 	%rd21, [sa_u8_u32_param_4];
	ld.param.u64 	%rd22, [sa_u8_u32_param_5];
	ld.param.u64 	%rd23, [sa_u8_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB68_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB68_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB68_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB68_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB68_6;

$L__BB68_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB68_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd44, 0;

$L__BB68_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd30, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	ld.global.u32 	%r20, [%rd37];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd44, %r23;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB68_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB68_3;
	bra.uni 	$L__BB68_10;

$L__BB68_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd40, %r22;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB68_9;

$L__BB68_10:
	ret;

}
	// .globl	sa_u8_i64
.visible .entry sa_u8_i64(
	.param .u64 sa_u8_i64_param_0,
	.param .u64 sa_u8_i64_param_1,
	.param .u64 sa_u8_i64_param_2,
	.param .u64 sa_u8_i64_param_3,
	.param .u64 sa_u8_i64_param_4,
	.param .u64 sa_u8_i64_param_5,
	.param .u64 sa_u8_i64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd18, [sa_u8_i64_param_0];
	ld.param.u64 	%rd19, [sa_u8_i64_param_1];
	ld.param.u64 	%rd20, [sa_u8_i64_param_2];
	ld.param.u64 	%rd24, [sa_u8_i64_param_3];
	ld.param.u64 	%rd21, [sa_u8_i64_param_4];
	ld.param.u64 	%rd22, [sa_u8_i64_param_5];
	ld.param.u64 	%rd23, [sa_u8_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB69_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB69_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB69_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB69_5;

	div.u64 	%rd45, %rd44, %rd23;
	mul.lo.s64 	%rd26, %rd45, %rd23;
	sub.s64 	%rd46, %rd44, %rd26;
	bra.uni 	$L__BB69_6;

$L__BB69_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB69_6:
	mul.lo.s64 	%rd13, %rd45, %rd21;
	mul.lo.s64 	%rd14, %rd45, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB69_7:
	add.s64 	%rd28, %rd47, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd46;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd46;
	shl.b64 	%rd36, %rd30, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	ld.global.u64 	%rd41, [%rd37];
	add.s64 	%rd42, %rd40, %rd41;
	st.global.u64 	[%rd39], %rd42;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p4, %rd47, %rd21;
	@%p4 bra 	$L__BB69_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p5, %rd2, %rd44;
	@%p5 bra 	$L__BB69_3;
	bra.uni 	$L__BB69_10;

$L__BB69_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p6, %rd2, %rd43;
	@%p6 bra 	$L__BB69_9;

$L__BB69_10:
	ret;

}

